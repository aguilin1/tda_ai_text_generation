title,label,text,word_count
Study of coupling loss on bi-columnar BSCCO/Ag tapes by a.c. susceptibility measurements,0,"Coupling losses were studied in composite tapes containing superconducting material in the form of two separate stacks of densely packed filaments embedded in a metallic matrix of Ag or Ag alloy. This kind of sample geometry is quite favorable for studying the coupling currents and in particular the role of superconducting bridges between filaments. By using a.c. susceptibility technique, the electromagnetic losses as function of a.c. magnetic field amplitude and frequency were measured at the temperature T = 77 K for two tapes with different matrix composition. The length of samples was varied by subsequent cutting in order to investigate its influence on the dynamics of magnetic flux penetration. The geometrical factor $\chi_0$ which takes into account the demagnetizing effects was established from a.c. susceptibility data at low amplitudes. Losses vs frequency dependencies have been found to agree nicely with the theoretical model developed for round multifilamentary wires.

Applying this model, the effective resistivity of the matrix was determined for each tape, by using only measured quantities. For the tape with pure silver matrix its value was found to be larger than what predicted by the theory for given metal resistivity and filamentary architecture. On the contrary, in the sample with a Ag/Mg alloy matrix, an effective resistivity much lower than expected was determined. We explain these discrepancies by taking into account the properties of the electrical contact of the interface between the superconducting filaments and the normal matrix. In the case of soft matrix of pure Ag, this is of poor quality, while the properties of alloy matrix seem to provoke an extensive creation of intergrowths which can be actually observed in this kind of samples.",280
Study of coupling loss on bi-columnar BSCCO/Ag tapes by a.c. susceptibility measurements,1,"In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements. The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances. However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood. Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field. Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields. We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes. Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation. Finally, we use numerical simulations to confirm the validity of our experimental results. Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.",215
Weighted Solyanik estimates for the strong maximal function,0,"Let $\mathsf M_{\mathsf S}$ denote the strong maximal operator on $\mathbb R^n$ and let $w$ be a non-negative, locally integrable function. For $\alpha\in(0,1)$ we define the weighted sharp Tauberian constant $\mathsf C_{\mathsf S}$ associated with $\mathsf M_{\mathsf S}$ by $$ \mathsf C_{\mathsf S} (\alpha):= \sup_{\substack {E\subset \mathbb R^n \\ 0<w(E)<+\infty}}\frac{1}{w(E)}w(\{x\in\mathbb R^n:\, \mathsf M_{\mathsf S}(\mathbf{1}_E)(x)>\alpha\}). $$ We show that $\lim_{\alpha\to 1^-} \mathsf C_{\mathsf S} (\alpha)=1$ if and only if $w\in A_\infty ^*$, that is if and only if $w$ is a strong Muckenhoupt weight. This is quantified by the estimate $\mathsf C_{\mathsf S}(\alpha)-1\lesssim_{n} (1-\alpha)^{(cn [w]_{A_\infty ^*})^{-1}}$ as $\alpha\to 1^-$, where $c>0$ is a numerical constant; this estimate is sharp in the sense that the exponent $1/(cn[w]_{A_\infty ^*})$ can not be improved in terms of $[w]_{A_\infty ^*}$. As corollaries, we obtain a sharp reverse H\""older inequality for strong Muckenhoupt weights in $\mathbb R^n$ as well as a quantitative imbedding of $A_\infty^*$ into $A_{p}^*$. We also consider the strong maximal operator on $\mathbb R^n$ associated with the weight $w$ and denoted by $\mathsf M_{\mathsf S} ^w$. In this case the corresponding sharp Tauberian constant $\mathsf C_{\mathsf S} ^w$ is defined by $$ \mathsf C_{\mathsf S} ^w \alpha) := \sup_{\substack {E\subset \mathbb R^n \\ 0<w(E)<+\infty}}\frac{1}{w(E)}w(\{x\in\mathbb R^n:\, \mathsf M_{\mathsf S} ^w (\mathbf{1}_E)(x)>\alpha\}).$$ We show that there exists some constant $c_{w,n}>0$ depending only on $w$ and the dimension $n$ such that $\mathsf C_{\mathsf S} ^w (\alpha)-1 \lesssim_{w,n} (1-\alpha)^{c_{w,n}}$ as $\alpha\to 1^-$ whenever $w\in A_\infty ^*$ is a strong Muckenhoupt weight.",332
Weighted Solyanik estimates for the strong maximal function,1,"In this paper, we investigate Weighted Solyanik Estimates for the Strong Maximal Function. The purpose of this study is to determine the optimal range of weights for which the Solyanik estimates hold true for the strong maximal function in both dyadic and non-dyadic contexts. Our work is motivated by recent developments in the area of harmonic analysis and Fourier analysis, which have demonstrated the importance of the strong maximal function in many areas of mathematics. We begin our investigation by defining the strong maximal function and introducing the weighted Solyanik estimates. We then analyze the properties of the strong maximal function and its relationship to weighted estimates. Our findings demonstrate that the range of suitable weights for the Solyanik estimates is significantly larger in the dyadic context than in the non-dyadic context. Moreover, we establish new estimates for the strong maximal function in the dyadic context, which improve upon existing results. Our study contributes to the development of more precise and accurate techniques for analyzing the strong maximal function, and may have potential applications in other areas of mathematics as well. In conclusion, our investigation of Weighted Solyanik Estimates for the Strong Maximal Function provides new insights into this important topic in harmonic analysis, and we expect our results to be of interest to researchers in this field and related areas of study.",225
SOFIA-EXES Observations of Betelgeuse during the Great Dimming of 2019/2020,0,"In 2019 October Betelgeuse began a decline in V-band brightness that went beyond the minimum expected from its quasi-periodic ~420 day cycle, becoming the faintest in recorded photometric history. Observations obtained in 2019 December with VLT/SPHERE (Montarges 2020) have shown that the southern half of the star has become markedly fainter than in 2019 January indicating that a major change has occurred in, or near, the photosphere.

We present SOFIA-EXES high spectral-resolution observations of [Fe II] 25.99 mic and [S I] 25.25 mic emission lines from Betelgeuse obtained during the unprecedented 2020 February V-band brightness minimum to investigate potential changes in the circumstellar flow. These spectra are compared to observations obtained in 2015 and 2017 when the V magnitude was typical of brighter phases.

We find only very small changes in the gas velocities reflected by either of the line profiles, no significant changes in the flux to continuum ratios, and hence no significant changes in the [Fe II]/[S I] flux ratios. There is evidence that absorption features have appeared in the 2020 continuum.

The Alfven wave-crossing time from the upper-photosphere is sufficiently long that one would not expect a change in the large scale magnetic field to reach the circumstellar [Fe II] and [S I] line forming regions, 3 < R(R*) < 20.

However, the light-crossing time is of order a few hours and a reduction in luminosity may reduce the dust-gas heating rate and [O I] 63.19 mic emission which has contributions from R > 20R*, where significant circumstellar oxygen-rich dust is observed.",268
SOFIA-EXES Observations of Betelgeuse during the Great Dimming of 2019/2020,1,"SOFIA-EXES Observations of Betelgeuse During the Great Dimming of 2019/2020

Betelgeuse, a red supergiant star in the constellation Orion, exhibited a significant dimming event starting in late 2019 to early 2020. This phenomenon captured the attention of both amateur and professional astronomers alike, leading to numerous studies utilizing various observation techniques.

In this paper, we present the findings from the Stratospheric Observatory for Infrared Astronomy (SOFIA) - Echelon-Cross-Echelle Spectrograph (EXES) observations of Betelgeuse during the great dimming event. We utilized a high-resolution mid-infrared spectrometer that allowed us to study the star’s atmosphere in detail and monitor its evolution over time.

Our analysis indicates that the dimming event was caused by the formation of a large cloud of dust in Betelgeuse’s atmosphere, with the specific trigger mechanism still under investigation. The cloud reached its maximum size and opacity in February 2020 before dissipating in April of the same year. We also observed variations in temperature and apparent size of the star, which may be related to the dimming event.

These SOFIA-EXES observations provide valuable insight into the mechanisms driving Betelgeuse’s complex atmosphere and offer a detailed look into its behavior during the great dimming event. Our findings contribute to the ongoing effort to understand the life cycle of massive stars and their role in the evolution of our universe.",227
Forward Modelling of Standing Kink Modes in Coronal Loops I. Synthetic Views,0,"Kink magnetohydrodynamic (MHD) waves are frequently observed in various magnetic structures of the solar atmosphere. They may contribute significantly to coronal heating and could be used as a tool to diagnose the solar plasma. In this study, we synthesise the \ion{Fe}{9} $\lambda171.073$ emission of a coronal loop supporting a standing kink MHD mode. The kink MHD wave solution of a plasma cylinder is mapped into a semi-torus structure to simulate a curved coronal loop. We decompose the solution into a quasi-rigid kink motion and a quadrupole term, which dominate the plasma inside and outside the flux tube, respectively. At the loop edges, the line-of-sight integrates relatively more ambient plasma, and the background emission becomes significant. The plasma motion associated with the quadrupole term causes spectral line broadening and emission suppression. The periodic intensity suppression will modulate the integrated intensity and the effective loop width, which both exhibit oscillatory variations at half of the kink period. The quadrupole term can be directly observed as a pendular motion at front view.",176
Forward Modelling of Standing Kink Modes in Coronal Loops I. Synthetic Views,1,"This paper presents an investigation of standing kink modes in coronal loops using forward modelling techniques. The study is focused on generating synthetic views of these modes by using numerical simulations that take into account the plasma's physical properties, including density, temperature, and magnetic field strength. A detailed analysis of the generated synthetic views is performed, revealing the spatial and temporal behavior of the standing kink modes in coronal loops. The results show the importance of considering the plasma's properties when modeling these modes, as well as the potential of using synthetic views to interpret observational data. Additionally, the study explores the influence of the energy distribution on the stability and evolution of these modes, shedding light on the physical mechanisms underlying their dynamics. Overall, the paper reveals new insights into the behavior of standing kink modes in coronal loops through the use of forward modelling techniques.",149
Prevailing dust-transport directions on comet 67P/Churyumov-Gerasimenko,0,"Dust transport and deposition behind larger boulders on the comet 67P/Churyumov-Gerasimenko (67P/C-G) have been observed by the Rosetta mission.

We present a mechanism for dust transport vectors based on a homogenous surface activity model incorporating in detail the topography of 67P/C-G. The combination of gravitation, gas drag, and Coriolis force leads to specific dust transfer pathways, which for higher dust velocities fuel the near nucleus coma.

By distributing dust sources homogeneously across the whole cometary surface, we derive a global dust-transport map of 67P/C-G. The transport vectors are in agreement with the reported wind-tail directions in the Philae descent area.",110
Prevailing dust-transport directions on comet 67P/Churyumov-Gerasimenko,1,"This study investigates the prevailing dust-transport directions on comet 67P/Churyumov-Gerasimenko. We analyzed images taken by the Rosetta spacecraft's OSIRIS camera during the comet's closest approach to the sun. We find that most of the dust transported from the comet's surface follows two general directions, which are correlated with the local topography. The first direction is related to the steep, bright cliffs in the Imhotep region. The second direction is associated with the flatter terrains in the Anhur and Atum regions. Our findings enhance our understanding of the dust dynamics on comets and provide insights into the evolution of comet surfaces.",106
Full-Wave Feasibility Study of Anti-Radar Diagnostic of Magnetic Field Based on O-X Mode Conversion and Oblique Reflectometry Imaging,0,"An innovative millimeter wave diagnostic is proposed to measure the local magnetic field and edge current as a function of the minor radius in the tokamak pedestal region. The idea is to identify the direction of minimum reflectivity at the O-mode cutoff layer. Correspondingly, the transmissivity due to O-X mode conversion is maximum. That direction, and the angular map of reflectivity around it, contain information on the magnetic field vector B at the cutoff layer. Probing the plasma with different wave frequencies provides the radial profile of B. Full-wave finite-element simulations are presented here in 2D slab geometry. Modeling confirms the existence of a minimum in reflectivity that depends on the magnetic field at the cutoff, as expected from mode conversion physics, giving confidence in the feasibility of the diagnostic. The proposed reflectometric approach is expected to yield superior signal-to-noise ratio and to access wider ranges of density and magnetic field, compared with related radiometric techniques that require the plasma to emit Electron Bernstein Waves. Due to computational limitations, frequencies of 10-20 GHz were considered in this initial study. Frequencies above the edge electron-cyclotron frequency (f>28 GHz here) would be preferable for the experiment, because the upper hybrid resonance and right cutoff would lie in the plasma, and would help separate the O-mode of interest from spurious X-waves.",229
Full-Wave Feasibility Study of Anti-Radar Diagnostic of Magnetic Field Based on O-X Mode Conversion and Oblique Reflectometry Imaging,1,"This paper presents a feasibility study of an anti-radar diagnostic of magnetic fields through a combination of O-X mode conversion and oblique reflectometry imaging. The proposed method relies on the conversion of the ordinary (O) mode of a probing electromagnetic wave into an extraordinary (X) mode, which interacts with the magnetic field and generates a secondary wave. This secondary wave is then detected and analyzed through oblique reflectometry imaging, which provides additional information about the spatial distribution and temporal evolution of the field. A full-wave approach, based on a numerical simulation of the electromagnetic waves and their interaction with the plasma, is used to investigate the feasibility and performance of the method. The simulation results show that the proposed technique is capable of detecting magnetic fields in various plasma environments, including fusion plasmas, with high accuracy and spatial resolution. The study also includes an analysis of the sensitivity of the method to different plasma parameters and experimental conditions, as well as a comparison with other diagnostic techniques. The results demonstrate the potential of the proposed method as a valuable tool for magnetic field diagnostics in diverse plasma physics research applications.",193
Time-Dependent Models for Blazar Emissions with the Second-Order Fermi Acceleration,0,"The second-order Fermi acceleration (Fermi-II) driven by turbulence may be responsible for the electron acceleration in blazar jets. We test this model with time-dependent simulations. The hard electron spectrum predicted by the Fermi-II process agrees with the hard photon spectrum of 1ES 1101-232. For other blazars that show softer spectra, the Fermi-II model requires radial evolution of the electron injection rate and/or diffusion coefficient in the outflow. Such evolutions can yield a curved electron spectrum, which can reproduce the synchrotron spectrum of Mrk 421 from the radio to the X-ray regime.The photon spectrum in the GeV energy range of Mrk 421 is hard to fit with a synchrotron self-Compton model. However, if we introduce an external radio photon field with a luminosity of $4.9 \times 10^{38}~\mbox{erg}~\mbox{s}^{-1}$, GeV photons are successfully produced via inverse Compton scattering. The temporal variability of the diffusion coefficient or injection rate causes flare emission. The observed synchronicity of X-ray and TeV flares implies a decrease of the magnetic field in the flaring source region.",186
Time-Dependent Models for Blazar Emissions with the Second-Order Fermi Acceleration,1,"Blazars display a distinct, often extreme variability in their luminosities, indicating that the particles responsible for their emissions are being accelerated. A possible mechanism for such acceleration is the second-order Fermi acceleration. Here we present time-dependent models for blazar emissions based on this mechanism. We employ a kinetic approach, taking into account the injection, acceleration, and eventual cooling of particles in the plasma, and use numerical simulations to predict the resulting radiation output. Our findings suggest that the second-order Fermi acceleration plays an important role in shaping the variability of blazar emissions. In particular, our models can reproduce the observed spectral energy distributions and light curves well. We also investigate the dependence of the emission properties on various parameters, such as the particle injection rate, magnetic field strength, and the efficiency of turbulent mixing. These models have implications for our understanding of particle acceleration in extreme astrophysical environments and can guide future observations of blazar emissions.",159
"Lithium in the Intermediate-Age Open Cluster, NGC 3680",0,"High-dispersion spectra centered on the Li 6708 A line have been obtained for 70 potential members of the open cluster NGC 3680, with an emphasis on stars in the turnoff region. A measurable Li abundance has been derived for 53 stars, 39 of which have radial velocities and proper motions consistent with cluster membership. After being transferred to common temperature and abundance scales, previous Li estimates have been combined to generate a sample of 49 members, 40 of which bracket the cluster Li-dip. Spectroscopic elemental analysis of 8 giants and 5 turnoff stars produces [Fe/H] = -0.17 +/- 0.07 (sd) and -0.07 +/- 0.02 (sd), respectively. We also report measurements of Ca, Si and Ni which are consistent with scaled-solar ratios within the errors. Adopting [Fe/H] = -0.08 (Sect. 3.6), Y^2 isochrone comparisons lead to an age of 1.75 +/- 0.10 Gyr and an apparent modulus of (m-M) = 10.30 +/- 0.15 for the cluster, placing the center of the Li-dip at 1.35 +/- 0.03 solar masses. Among the giants, 5 of 9 cluster members are now known to have measurable Li with A(Li) near 1.0. A combined sample of dwarfs in the Hyades and Praesepe is used to delineate the Li-dip profile at 0.7 Gyr and [Fe/H] = +0.15, establishing its center at 1.42 +/- 0.02 solar masses and noting the possible existence of secondary dip on its red boundary. When evolved to the typical age of the clusters NGC 752, IC 4651 and NGC 3680, the Hyades/Praesepe Li-dip profile reproduces the observed morphology of the combined Li-dip within the CMD's of the intermediate-age clusters while implying a metallicity dependence for the central mass of the Li-dip given by Mass = (1.38 +/-0.04) + (0.4 +/- 0.2)[Fe/H]. The implications of the similarity of the Li-dichotomy among giants in NGC 752 and IC 4651 and the disagreement with the pattern among NGC 3680 giants are discussed.",344
"Lithium in the Intermediate-Age Open Cluster, NGC 3680",1,"The open cluster, NGC 3680, has been of interest to many astronomers due to its intermediate age and proximity to the Sun. Recently, lithium has also emerged as a topic of great interest within the cluster. Here, we present a detailed analysis of the lithium abundance of NGC 3680 stars using high-resolution spectra obtained with the Fibre-fed Extended Range Optical Spectrograph (FEROS) at the La Silla Observatory.

Our sample comprises 80 stars within the cluster, with effective temperatures ranging from 4900 K to 6800 K and atmospheric pressures of 1.5 to 4.0 dex. We find no significant correlation between the effective temperature and the lithium abundance of the stars. However, we do observe a negative correlation between the lithium abundance and the stellar age, which indicates that the depletion of lithium is due to post-main sequence depletion. Furthermore, we find that the number of lithium-rich stars is lower than expected, which may be attributed to the disk destruction and mixing caused by the Galactic tide.

We also compare our NGC 3680 results to other open clusters with similar metallicities. Our findings suggest that the lithium-rich stars in NGC 3680 are relatively younger than those in other open clusters. This result has important implications for the development of lithium depletion models, especially since the depletion process is extremely dependent on the age of the open cluster. Additionally, this study uncovers a new perspective on the lithium abundance of intermediate-age open clusters and sheds light on the cosmic evolutionary history of the Milky Way.

In conclusion, our study provides an in-depth analysis of the lithium abundance of the intermediate-age open cluster, NGC 3680. Our findings offer new insights into the formation and evolution of open clusters, as well as the depletion of lithium during post-main sequence stars. Further research in this field is crucial for understanding the origin of the elements in our universe and the chemical evolution of galaxies.",329
GSP-spec line list for the parametrisation of Gaia -RVS stellar spectra,0,"The Gaia mission is a magnitude-limited whole-sky survey that collects an impressive quantity of astrometric, spectro-photometric and spectroscopic data.

Among all the on-board instruments, the Radial Velocity Spectrometer (RVS) produces millions of spectra up to a magnitude of G$_{RVS} \sim 16$. For the brightest RVS targets, stellar atmospheric parameters and individual chemical abundances are automatically estimated by the Generalized Stellar Parametriser - spectroscopy group (GSP-Spec). These data will be published with the third Gaia Data Release. Some major ingredients of the determination of these stellar parameters include the atomic and molecular line lists that are adopted to compute reference synthetic spectra, on which the parametrisation methods rely.

We aim to build such a specific line list optimised for the analysis of RVS late-type star spectra. Starting from the Gaia-ESO line lists, we first compared the observed and synthetic spectra of six well-known reference late-type stars in the wavelength range covered by the RVS instrument. We then improved the quality of the atomic data for the transitions presenting the largest mismatches. The new line list is found to produce very high-quality synthetic spectra for the tested reference stars and has thus been adopted within GSP-Spec.",206
GSP-spec line list for the parametrisation of Gaia -RVS stellar spectra,1,"In this study, a GSP-spec line list has been created to facilitate the parametrization of stellar spectra obtained by Gaia-RVS. This line list is based on the latest atomic and molecular data, and includes approximately 61,000 spectral lines covering the wavelength range of Gaia-RVS (845-872 nm). The line list has been optimised to improve the accuracy and precision of elemental abundances derived from Gaia-RVS spectra, and includes corrections for departures from local thermodynamic equilibrium (LTE). The parametrization method has also been refined, using a combination of spectral synthesis and statistical techniques, to improve the precision of stellar atmospheric parameters such as effective temperature, surface gravity, and metallicity. The accuracy of the GSP-spec line list and the parametrization method has been tested using synthetic spectra, and the results indicate that this approach yields precise and accurate determination of stellar atmospheric parameters for stars with signal-to-noise ratios above 30. This line list and parametrization method have significant applications in large-scale spectroscopic surveys such as Gaia, which aims to measure the kinematic and chemical properties of more than one billion stars in the Milky Way.",192
Online Recovery Guarantees and Analytical Results for OMP,0,"Orthogonal Matching Pursuit (OMP) is a simple, yet empirically competitive algorithm for sparse recovery. Recent developments have shown that OMP guarantees exact recovery of K-sparse signals with K or more than K iterations if the observation matrix satisfies the restricted isometry property (RIP) with some conditions. We develop RIP-based online guarantees for recovery of a K-sparse signal with more than K OMP iterations. Though these guarantees cannot be generalized to all sparse signals a priori, we show that they can still hold online when the state-of-the-art K-step recovery guarantees fail. In addition, we present bounds on the number of correct and false indices in the support estimate for the derived condition to be less restrictive than the K-step guarantees. Under these bounds, this condition guarantees exact recovery of a K-sparse signal within 3K/2 iterations, which is much less than the number of steps required for the state-of-the-art exact recovery guarantees with more than K steps. Moreover, we present phase transitions of OMP in comparison to basis pursuit and subspace pursuit, which are obtained after extensive recovery simulations involving different sparse signal types. Finally, we empirically analyse the number of false indices in the support estimate, which indicates that these do not violate the developed upper bound in practice.",221
Online Recovery Guarantees and Analytical Results for OMP,1,"This paper presents a comprehensive study of online recovery guarantees and analytical results for Orthogonal Matching Pursuit (OMP). We begin by examining the asymptotic analysis of OMP- a well-known greedy algorithm used in sparse signal recovery. Specifically, we investigate the precise conditions under which OMP successfully recovers a sparse signal and derive the corresponding lower bounds on the sparsity level. In addition, we establish concentration inequalities that control the deviation of OMP's estimate from the true signal. Building on these theoretical results, we present the online recovery guarantees for OMP in a non-adaptive setting where the signal is drawn from a fixed distribution. We study the performance of OMP under different levels of sparsity and noise and demonstrate that online OMP attains a desirable trade-off between accuracy and computational complexity. Finally, we validate our analytical results through numerical experiments and showcase the effectiveness of OMP in practical sparse recovery applications. Overall, our theoretical and experimental analysis demonstrates the robustness and versatility of OMP, making it a potential tool for a wide range of signal processing tasks.",180
4d Gauge Theory and Gravity Generated from 3d Ones at High Energy,0,"Dynamical generation of 4d gauge theories and gravity at low energy from the 3d ones at high energy is studied, based on the fermion condensation mechanism recently proposed by Arkani-Hamed, Cohen and Georgi. For gravity, 4d Einstein gravity is generated from the multiple copy of the 3d ones, by referring to the two form gravity. Since the 3d Einstein action without matter coupling is topological, ultraviolet divergences are less singular in our model. In the gauge model, matter fermions are introduced on the discrete lattice following Wilson. Then, the 4d gauge interactions are correctly generated from the 3d theories even in the left-right asymmetric theories of the standard model. In order for this to occur, the Higgs fields as well as the gauge fields of the extra dimension should be generated by the fermion condensates. Therefore, the generation of the 4d standard model from the multiple copy of the 3d ones is quite promising. To solve the doubling problem in the weak interaction sector, two kinds of discrete lattices have to be introduced separately for L- and R-handed sectors, and the two types of Higgs fields should be generated.",192
4d Gauge Theory and Gravity Generated from 3d Ones at High Energy,1,"In this paper, we investigate the relationship between 4d gauge theory and gravity that arises from 3d ones at high energy. We explore the dualities between these theories and their implications for our understanding of fundamental physics. Using tools from holography and quantum field theory, we provide evidence for these dualities and show that they are crucial for describing the behavior of strongly coupled systems. Our results suggest a new perspective on the nature of gravity and its connection to gauge theory, potentially opening new avenues for research in theoretical physics. We also discuss the role played by the holographic principle in this context and its connection to the emergence of spacetime geometry. Our work sheds light on the deep connections between seemingly disparate theories and provides a framework for studying the behavior of high-energy systems. Overall, this paper represents a significant contribution to the ongoing efforts to unify the fundamental forces of nature.",155
Cooperative Binning for Semi-deterministic Channels with Non-causal State Information,0,"The capacity of the semi-deterministic relay channel (SD-RC) with non-causal channel state information (CSI) only at the encoder and decoder is characterized. The capacity is achieved by a scheme based on cooperative-bin-forward. This scheme allows cooperation between the transmitter and the relay without the need to decode a part of the message by the relay.

The transmission is divided into blocks and each deterministic output of the channel (observed by the relay) is mapped to a bin. The bin index is used by the encoder and the relay to choose the cooperation codeword in the next transmission block. In causal settings the cooperation is independent of the state. In \emph{non-causal} settings dependency between the relay's transmission and the state can increase the transmission rates. The encoder implicitly conveys partial state information to the relay. In particular, it uses the states of the next block and selects a cooperation codeword accordingly and the relay transmission depends on the cooperation codeword and therefore also on the states. We also consider the multiple access channel with partial cribbing as a semi-deterministic channel. The capacity region of this channel with non-causal CSI is achieved by the new scheme. Examining the result in several cases, we introduce a new problem of a point-to-point (PTP) channel where the state is provided to the transmitter by a state encoder.

Interestingly, even though the CSI is also available at the receiver, we provide an example which shows that the capacity with non-causal CSI at the state encoder is strictly larger than the capacity with causal CSI.",271
Cooperative Binning for Semi-deterministic Channels with Non-causal State Information,1,"The problem of channel coding in cooperative communication systems is well studied in the literature, but most of the existing work assumes that the channel state information (CSI) is known at the transmitter in a causal fashion. However, in many practical situations, the CSI is only available non-causally, which is a more challenging scenario for cooperative communication. In this paper, we address the issue of cooperative binning for semi-deterministic channels with non-causal state information (NCSI). 

Our approach is based on the idea of ""CSI binning,"" which is a technique for organizing the CSI at the receivers by dividing it into multiple bins. Each bin contains a subset of CSI values that are associated with a particular decoding outcome. We propose a new scheme for cooperative binning that is specifically designed to exploit the NCSI at the receivers. Our scheme is based on a two-phase protocol that involves a preliminary calibration phase, followed by a data transmission phase. During the calibration phase, the receivers cooperate to estimate the NCSI, and use it to construct the CSI bins. In the transmission phase, the transmitter sends information to the receivers by using a combination of binning and superposition coding. 

We analyze the performance of our scheme in terms of the achievable rates and the error probabilities. We show that, under certain conditions, our scheme achieves rates that approach the capacity of the semi-deterministic channel with NCSI. Our results suggest that cooperative binning is an effective approach for dealing with the challenging scenario of NCSI, and provides new insights into the design of cooperative communication systems.",267
Efficiently Approximating Edit Distance Between Pseudorandom Strings,0,"We present an algorithm for approximating the edit distance $\operatorname{ed}(x, y)$ between two strings $x$ and $y$ in time parameterized by the degree to which one of the strings $x$ satisfies a natural pseudorandomness property. The pseudorandomness model is asymmetric in that no requirements are placed on the second string $y$, which may be constructed by an adversary with full knowledge of $x$.

We say that $x$ is \emph{$(p, B)$-pseudorandom} if all pairs $a$ and $b$ of disjoint $B$-letter substrings of $x$ satisfy $\operatorname{ed}(a, b) \ge pB$.

Given parameters $p$ and $B$, our algorithm computes the edit distance between a $(p, B)$-pseudorandom string $x$ and an arbitrary string $y$ within a factor of $O(1/p)$ in time $\tilde{O}(nB)$, with high probability.

Our algorithm is robust in the sense that it can handle a small portion of $x$ being adversarial (i.e., not satisfying the pseudorandomness property). In this case, the algorithm incurs an additive approximation error proportional to the fraction of $x$ which behaves maliciously.

The asymmetry of our pseudorandomness model has particular appeal for the case where $x$ is a \emph{source string}, meaning that $\operatorname{ed}(x, y)$ will be computed for many strings $y$. Suppose that one wishes to achieve an $O(\alpha)$-approximation for each $\operatorname{ed}(x, y)$ computation, and that $B$ is the smallest block-size for which the string $x$ is $(1/\alpha, B)$-pseudorandom. We show that without knowing $B$ beforehand, $x$ may be preprocessed in time $\tilde{O}(n^{1.5}\sqrt{B})$, so that all future computations of the form $\operatorname{ed}(x, y)$ may be $O(\alpha)$-approximated in time $\tilde{O}(nB)$. Furthermore, for the special case where only a single $\operatorname{ed}(x, y)$ computation will be performed, we show how to achieve an $O(\alpha)$-approximation in time $\tilde{O}(n^{4/3}B^{2/3})$.",321
Efficiently Approximating Edit Distance Between Pseudorandom Strings,1,"Given the ubiquity of text data and the need to match or compare strings, the problem of efficiently approximating the edit distance between pseudorandom strings is of considerable importance. The edit distance between two strings is the minimum number of edit operations (insertions, deletions, and replacements) required to transform one string into another.

In many applications, strings are generated randomly and have a large alphabet, making exact computation of the edit distance computationally expensive. In this paper, we present a novel approach for approximating the edit distance between two pseudorandom strings with high probability. Our algorithm is based on sketching the strings into small, easily computable summaries, and then applying a pairwise hashing scheme to estimate the edit distance.

Our theoretical analysis shows that our algorithm achieves a constant approximation factor with high probability, and the runtime of our algorithm is linear in the length of the strings. Experimentally, we demonstrate that our algorithm outperforms existing state-of-the-art algorithms for approximating edit distance on a variety of random and real-world data sets.

Furthermore, we show that our algorithm scales well for multi-string similarity search, where the goal is to find all pairs of strings in a collection with edit distance below a given threshold. Our approach leverages the properties of pseudorandomness to design compact sketches that are preserved under edit operations, allowing us to perform efficient pairwise comparisons and filtering.

In conclusion, our proposed algorithm provides an efficient and effective method for approximating the edit distance between pseudorandom strings. We believe that our work contributes towards the development of fast and accurate string matching techniques, which are essential for many applications in information retrieval, natural language processing, and computational biology.",284
Influential Node Ranking in Complex Networks Using A Randomized DynamicsSensitive Approach,0,"Identifying the most influential nodes in information networks has been the focus of many research studies. This problem has crucial applications in various contexts including biology, medicine, and social science, such as controlling the propagation of viruses or rumours in real world networks. While existing methods mostly employ local neighbourhood features which heavily rely on the network structure and disregard the underlying diffusion dynamics, in this work we present a randomized sampling algorithm that not only takes into account the local and global structural features of the network but also considers the underlying diffusion dynamics and its parameters. The main idea is to compute the influentiality of a node through reachability from that node in a set of random graphs. We use a hyper-graph to capture the reachability from nodes in the original network, and theoretically argue that the hypergraph can be used to approximate the theoretical influentiality of nodes in the original graph with a factor of 1 - epsilon. The performance of the proposed model is also evaluated empirically by measuring the correlation between the ranking generated by the proposed method and the ground truth ranking. Our results show that the proposed method substantially outperforms state of the art methods and achieves the highest correlation with the ground-truth ranking, while the generated ranking has a high level of uniqueness and uniformity.

Theoretical and practical analysis of the running time of the algorithm also confirms that the proposed method maintains a competitive running time in comparison to the state of the art methods.",255
Influential Node Ranking in Complex Networks Using A Randomized DynamicsSensitive Approach,1,"The analysis of complex networks is a crucial factor in the understanding and exploration of various systems, from social networks to biological and technological systems. In this study, we present a new approach to measure the influential node ranking in such networks using a dynamic-sensitive method. Our proposed method employs a randomized algorithm that not only takes into account the graph topology but also considers the history of the network's evolution to measure node influence. We show that our method is consistent and able to overcome the limitations of the existing methods that are only concerned with the static properties of the network. Furthermore, we demonstrate the effectiveness of our method on a variety of moderate-to-large scale networks, including social networks and biological networks. The proposed approach provides a more accurate representation of the importance of a node in a complex network and can aid in the analysis of these networks. The results also emphasize the importance of the temporal dimension in measuring node importance, particularly in dynamic systems where the structure and behavior of the network are affected by the past and current state. Overall, our study showcases the importance of adopting a dynamic-sensitive approach to investigate influential node ranking in complex networks.",209
"From magnetic order to quantum disorder: a $\mu$SR study of the Zn-barlowite series of $S={\frac{1}{2}}$ kagom\'e antiferromagnets, Zn$_{x}$Cu$_{4-x}$(OH)$_{6}$FBr",0,"We report a comprehensive muon spectroscopy study of the Zn-barlowite series of $S={\frac{1}{2}}$ kagom\'e antiferromagnets, Zn$_x$Cu$_{4-x}$(OH)$_{6}$FBr, for $x=0.00$ to $0.99(1)$. By combining muon spin relaxation and rotation measurements with state-of-the-art density-functional theory muon-site calculations, we observe the formation of both $\mu$--F and $\mu$--OH complexes in Zn-barlowite. From these stopping sites, implanted muon spins reveal the suppression of long-range magnetic order into a possible quantum spin liquid state upon increasing concentration of Zn-substitution. In the parent compound ($x=0$), static long-range magnetic order below $T_{\mathsf{N}}=15$ K manifests itself in the form of spontaneous oscillations in the time-dependent muon asymmetry signal consistent with the dipolar fields expected from the calculated muon stopping sites and the previously determined magnetic structure of barlowite. Meanwhile, in the $x=1.0$ end-member of the series---in which antiferromagnetic kagom\'e layers of Cu$^{2+}$ $S={\frac{1}{2}}$ moments are decoupled by diamagnetic Zn$^{2+}$ ions---we observe that dynamic magnetic moment fluctuations persist down to at least 50 mK, indicative of a quantum disordered ground state. We demonstrate that this crossover from a static to dynamic magnetic ground state occurs for compositions of Zn-barlowite with $x>0.5$, which bears resemblance to dynamical behaviour of the widely studied Zn-paratacamite series that contains the quantum spin liquid candidate herbertsmithite.",249
"From magnetic order to quantum disorder: a $\mu$SR study of the Zn-barlowite series of $S={\frac{1}{2}}$ kagom\'e antiferromagnets, Zn$_{x}$Cu$_{4-x}$(OH)$_{6}$FBr",1,"This paper presents a study of the Zn-barlowite series, a class of kagom\'e antiferromagnets with spin $S = {\frac{1}{2}}$, using muon spin relaxation spectroscopy ($\mu$SR). By systematically substituting Cu ions with Zn ions in Zn$_x$Cu$_{4-x}$(OH)$_6$FBr, the effect on magnetic order and the evolution toward quantum disorder was examined. In the parent compound Cu$_4$(OH)$_6$FBr, long-range order of the spins is observed down to low temperatures, implying the absence of a spin liquid state. Upon Zn substitution, this order is gradually lost, and at higher Zn concentrations, the system exhibits characteristics reminiscent of a quantum spin liquid. Our $\mu$SR results suggest that the substitution of Cu with Zn strongly perturbs the local magnetic environment, and alters the magnetic couplings within the kagom\'e planes. Moreover, we observe a dramatic broadening of the Kubo-Toyabe relaxation function, which indicates the emergence of electronic inhomogeneity and the presence of magnetic fluctuations over a wide range of temperatures. Overall, the observed evolution in magnetic behavior warrants further investigation of the Zn-barlowite series as a candidate for hosting a quantum spin liquid.",195
Organometallic Wires Constructed from Transitional Metals and Anthracene: A Theoretical Study,0,"The properties of organometallic wires [TM2(Ant)] constructed with transitional metals (TM = Sc, Ti, V, Cr, Mn and Fe) and anthracene (Ant) are investigated by first-principles calculations. As the gap between HOMO (Highest Occupied Molecular Orbital) and LUMO (Lowest Unoccupied Molecular Orbital) of Ant is much smaller than that of benzene (Bz), much larger charge transfer (CT) occurs between TMs and Ant, which results in much more diverse magnetic properties in [TM2(Ant)] than in [TM2(Ant)]. Particularly, [V2(Ant)] and [Cr2(Ant)] are found to be half-metallic ferromagnets. As a result of this and the better structural stability, compared with [TM(Bz)], [TM2(Ant)] (like [V2(Ant)] and [Cr2(Ant)]) may be better candidates of spintronic devices.

Furthermore, as the HOMO-LUMO gap of small pieces of graphene (SPG), such as pentacene and coronene, decreases with the increase of polycyclic number, the CT effects may also fit for the TM-SPG sandwich polymers which can also act as good spintronic materials.",164
Organometallic Wires Constructed from Transitional Metals and Anthracene: A Theoretical Study,1,"The development of organometallic wires has been an important area of research in recent years, due to their potential applications in molecular electronics and nanotechnology. In this study, we aimed to investigate the electronic and optical properties of transitional metal-based organometallic wires constructed using anthracene as a bridging ligand. Our theoretical calculations were carried out using a density functional theory approach, and our results highlight the important role that the metal center plays in determining the electronic structure and transport properties of these wires. We found that wires constructed from transition metals with partially occupied d orbitals exhibit strong spin polarization due to the presence of localized magnetic moments. Additionally, our calculations suggest that the use of anthracene as a bridging ligand is advantageous due to the extended pi-conjugation it provides, which leads to enhanced electronic coupling between metal centers. Our findings provide valuable insights into the design and functioning of organometallic wires, which could pave the way for new advances in molecular electronics.",166
"On the interplay between hypergeometric series, Fourier-Legendre expansions and Euler sums",0,"In this work we continue the investigation about the interplay between hypergeometric functions and Fourier-Legendre ($\textrm{FL}$) series expansions. In the section ""Hypergeometric series related to $\pi,\pi^2$ and the lemniscate constant"", through the FL-expansion of $\left[x(1-x)\right]^\mu$ (with $\mu+1\in\frac{1}{4}\mathbb{N}$) we prove that all the hypergeometric series $$ \sum_{n\geq 0}\frac{(-1)^n(4n+1)}{p(n)}\left[\frac{1}{4^n}\binom{2n}{n}\right]^3,\quad \sum_{n\geq 0}\frac{(4n+1)}{p(n)}\left[\frac{1}{4^n}\binom{2n}{n}\right]^4,$$ $$\quad \sum_{n\geq 0}\frac{(4n+1)}{p(n)^2}\left[\frac{1}{4^n}\binom{2n}{n}\right]^4,\; \sum_{n\geq 0}\frac{1}{p(n)}\left[\frac{1}{4^n}\binom{2n}{n}\right]^3,\; \sum_{n\geq 0}\frac{1}{p(n)}\left[\frac{1}{4^n}\binom{2n}{n}\right]^2 $$ return rational multiples of $\frac{1}{\pi},\frac{1}{\pi^2}$ or the lemniscate constant, as soon as $p(x)$ is a polynomial fulfilling suitable symmetry constraints.

Additionally, by computing the FL-expansions of $\frac{\log x}{\sqrt{x}}$ and related functions, we show that in many cases the hypergeometric $\phantom{}_{p+1} F_{p}(\ldots , z)$ function evaluated at $z=\pm 1$ can be converted into a combination of Euler sums. In particular we perform an explicit evaluation of $$ \sum_{n\geq 0}\frac{1}{(2n+1)^2}\left[\frac{1}{4^n}\binom{2n}{n}\right]^2,\quad \sum_{n\geq 0}\frac{1}{(2n+1)^3}\left[\frac{1}{4^n}\binom{2n}{n}\right]^2. $$ In the section ""Twisted hypergeometric series"" we show that the conversion of some $\phantom{}_{p+1} F_{p}(\ldots,\pm 1)$ values into combinations of Euler sums, driven by FL-expansions, applies equally well to some twisted hypergeometric series, i.e. series of the form $\sum_{n\geq 0} a_n b_n$ where $a_n$ is a Stirling number of the first kind and $\sum_{n\geq 0}b_n z^n = \phantom{}_{p+1} F_{p}(\ldots;z)$.",357
"On the interplay between hypergeometric series, Fourier-Legendre expansions and Euler sums",1,"This paper investigates the intricate interplay between hypergeometric series, Fourier-Legendre expansions, and Euler sums, revealing unexpected and fascinating connections between these three prominent areas of mathematical analysis.

Hypergeometric series are a central tool in mathematical analysis and have played a pivotal role in a diverse range of areas, from combinatorics to number theory, and physics to computer science.

Fourier-Legendre expansions, on the other hand, are an essential tool for approximating functions on the interval [-1, 1], and are central to the study of partial differential equations and harmonic analysis. The interplay between hypergeometric series and Fourier-Legendre expansions has been widely studied, leading to numerous connections between these two fields.

Euler sums are a particularly intriguing object in number theory and have been studied for many years. They are defined as the alternating sum of the reciprocals of the kth powers of the integers, and their properties have been extensively studied by mathematicians.

In this paper, we explore the surprising links between these three areas of mathematical analysis. We investigate the role of Euler sums in the evaluation of certain hypergeometric series, and show how Fourier-Legendre expansions can be used to provide alternative proofs of known results in the theory of Euler sums.

Moreover, we present new results on the convergence of certain hypergeometric series, and show how these results can be used to derive new and interesting identities involving Euler sums.

Overall, this paper sheds new light on the deep connections between hypergeometric series, Fourier-Legendre expansions, and Euler sums, revealing a rich and fascinating interplay between these three areas of mathematical analysis.",267
On the kernel of the projection map $T(V)\to S(V)$,0,"If $V$ is a vector space over a field $F$, then we consider the projection from the tensor algebra to the symmetric algebra, $\rho_{T,S}:T(V)\to S(V)$.

Our main result, in $\S$1, gives a description of $\ker\rho_{T,S}$. Explicitly, we consider the ${\mathbb Z}_{\geq 2}$-graded $T(V)$-bimodule $T(V)\otimes\Lambda^2(V)\otimes T(V)$ and we define $M(V)=(T(V)\otimes\Lambda^2(V)\otimes T(V))/W_M(V)$, where $W_M(V)$ is the subbimodule of $T(V)\otimes\Lambda^2(V)\otimes T(V)$ generated by $[x,y]\otimes\xi\otimes z\wedge t-x\wedge y\otimes\xi\otimes [z,t]$, with $x,y,z,t\in V$ and $\xi\in T(V)$. $[x,y\wedge z]+[y,z\wedge x]+[z,x\wedge y]$, with $x,y,z\in V$. (If $\eta\in T(V)$ and $\xi\in T(V)\otimes\Lambda^2(V)\otimes T(V)$ (or vice-versa) then $[\eta,\xi ]:=\eta\otimes\xi -\xi\otimes\eta\in T(V)\otimes\Lambda^2(V)\otimes T(V)$.) Then $M(V)$ is a ${\mathbb Z}_{\geq 2}$-graded $T(V)$-bimodule. If $\eta\in T(V)\otimes\Lambda^2(V)\otimes T(V)$ the we denote by $[\eta ]$ its class in $M(V)$. ${\bf Theorem}$ We have an exact sequence $$0\to M(V)\xrightarrow{\rho_{M,T}}T(V)\xrightarrow{\rho_{T,S}}S(V)\to 0,$$ where $\rho_{M,T}$ is given by $[\eta\otimes x\wedge y\otimes \xi ]\mapsto\eta\otimes [x,y]\otimes\xi$ $\forall x,y\in V$, $\eta,\xi\in T(V)$. In $\S$2 we define the graded algebra $S'(V)=T(V)/W_{S'}(V)$, where $S'(V)\subseteq T(V)$ is the ideal generated by $x\otimes y\otimes z- y\otimes z\otimes x$, $x,y,z\in V$, and we prove that there is a n exact sequence $$0\to\Lambda^{\geq 2}(V)\xrightarrow{\rho_{\Lambda^{\geq 2},S'}}S'(V)\xrightarrow{\rho_{S',S}}S(V)\to 0.$$ When we consider the homogeneous parts of degree $2$ we have $M^2(V)=\Lambda^2(V)$ and $S'^2(V)=T^2(V)$. Then both short exact sequences above become $0\to\Lambda^2(V)\to T^2(V)\to S^2(V)\to 0$ where the first morphism is given by $x\wedge y\mapsto [x,y]=x\otimes y-y\otimes x$, a well known result.",420
On the kernel of the projection map $T(V)\to S(V)$,1,"In this paper, we investigate the kernel of the projection map $T(V)\to S(V)$, where $V$ is a finite-dimensional vector space over a field of characteristic not equal to 2. We show that the kernel is precisely the subspace of $T(V)$ consisting of those tensors which are symmetric in each pair of indices. Moreover, we interpret this result in terms of the geometry of the Grassmannian of $r$-planes in $V$, where $r$ is the rank of the symmetric bilinear form associated to $V$.

Our approach relies on a careful analysis of the eigenvalues of an operator $L: T(V)\to T(V)$ defined by $L(T)=\operatorname{Sym}(T)-\operatorname{Alt}(T)$, where $\operatorname{Sym}$ and $\operatorname{Alt}$ denote the symmetrization and alternation operations, respectively. We use the theory of exterior algebra and linear algebra to show that $L$ is a diagonalizable operator, with eigenvalues $1$ and $-1$ occurring with multiplicity equal to the dimension of the spaces of symmetric and skew-symmetric tensors, respectively. This allows us to derive a decomposition of $T(V)$ into eigenspaces of $L$, which leads to our characterization of the kernel of the projection map.

We then turn to the Grassmannian, which is a geometric object that parametrizes $r$-dimensional subspaces of $V$. We introduce a natural symmetric bilinear form on each tangent space of the Grassmannian, which is induced by the restriction of the bilinear form associated to $V$. It turns out that the rank of this bilinear form is precisely $r$. We show that the kernel of the projection map corresponds to the set of tangent spaces at points in the Grassmannian that correspond to isotropic $r$-planes, that is, planes on which the bilinear form vanishes.

We conclude by discussing the implications of our results for the study of symmetric tensors and their applications in physics and engineering. We also outline some open questions and directions for future research, which include the study of the kernel of other projection maps in tensor algebra, and the investigation of the geometry of the Grassmannian in the presence of more general bilinear forms.",354
Downlink and Uplink Energy Minimization Through User Association and Beamforming in Cloud RAN,0,"The cloud radio access network (C-RAN) concept, in which densely deployed access points (APs) are empowered by cloud computing to cooperatively support mobile users (MUs), to improve mobile data rates, has been recently proposed.

However, the high density of active (""on"") APs results in severe interference and also inefficient energy consumption. Moreover, the growing popularity of highly interactive applications with stringent uplink (UL) requirements, e.g.

network gaming and real-time broadcasting by wireless users, means that the UL transmission is becoming more crucial and requires special attention. Therefore in this paper, we propose a joint downlink (DL) and UL MU-AP association and beamforming design to coordinate interference in the C-RAN for energy minimization, a problem which is shown to be NP hard. Due to the new consideration of UL transmission, it is shown that the two state-of-the-art approaches for finding computationally efficient solutions of joint MU-AP association and beamforming considering only the DL, i.e., group-sparse optimization and relaxed-integer programming, cannot be modified in a straightforward way to solve our problem. Leveraging on the celebrated UL-DL duality result, we show that by establishing a virtual DL transmission for the original UL transmission, the joint DL and UL optimization problem can be converted to an equivalent DL problem in C-RAN with two inter-related subproblems for the original and virtual DL transmissions, respectively. Based on this transformation, two efficient algorithms for joint DL and UL MU-AP association and beamforming design are proposed, whose performances are evaluated and compared with other benchmarking schemes through extensive simulations.",267
Downlink and Uplink Energy Minimization Through User Association and Beamforming in Cloud RAN,1,"Cloud Radio Access Network (C-RAN) is an innovative architecture for wireless communication systems that leverages cloud computing techniques to optimize network performance. A fundamental aspect of C-RAN design is energy efficiency, as it is necessary to reduce energy consumption while maintaining network quality. In this paper, we propose a user association and beamforming methodology to minimize downlink and uplink energy consumption in C-RAN systems.

The proposed approach includes a two-stage optimization process for user association and beamforming. First, a user grouping algorithm is employed to form groups of users that share the same base station (BS) connection. Second, a beamforming optimization method based on the group formation is used to minimize energy consumption. This approach is beneficial as it exploits the spatial domain of the wireless channel to direct the transmission power towards the desired users, thus resulting in reduced energy consumption and improved network performance.

Simulation results show that the proposed methodology outperforms existing approaches in terms of energy efficiency and meets the required network performance. Furthermore, the results demonstrate the effectiveness of the proposed approach in balancing the energy consumption between BSs, reducing the total energy consumption of the network, and increasing the data rate of the users. Our findings indicate that the proposed user association and beamforming methodology is a promising solution for improving energy efficiency in C-RAN systems while maintaining a high-quality network performance.

In conclusion, the proposed approach can significantly contribute to the development of energy-efficient C-RAN systems and enable the implementation of sustainable and cost-effective 5G networks.",262
On the density of states in a free CFT and finite volume corrections,0,Results from spectral geometry such as Weyl's formula can be used to relate the thermodynamic properties of a free massless field to the spatial manifold on which it is defined. We begin by calculating the free energy in two cases: manifolds posessing a boundary and spheres. The subextensive contributions allow us to test the Cardy-Verlinde formula and offer a new perspective on why it only holds in a free theory if one allows for a change in the overall coefficient. After this we derive an expression for the density of states that takes the form of a Taylor series. This series leads to an improvement over known results when the area of the manifold's boundary is nonzero but much less than the appropriate power of its volume.,130
On the density of states in a free CFT and finite volume corrections,1,"This paper investigates the density of states of a free conformal field theory (CFT) and the finite volume corrections associated with such a system. Our approach involves analyzing the spectrum of operators and their correlation functions, utilizing both analytical and numerical methods. We find that the conformal symmetry in free CFT governs the behavior of the density of states, both in the high and low energy regimes. Furthermore, we demonstrate that, in finite volumes, the density of states is corrected by spatial dependence. Specifically, we show that the spectral density oscillations around the central value and their amplitude depend on the system's size and boundary conditions. Our results provide important insights into the properties of conformal field theories and their behavior in finite volumes.",125
Asymptotics of a vanishing period : General existence theorem and basic properties of frescos,0,"In this paper we introduce the word ""fresco"" to denote a \ $[\lambda]-$primitive monogenic geometric (a,b)-module. The study of this ""basic object"" (generalized Brieskorn module with one generator) which corresponds to the minimal filtered (regular) differential equation satisfied by a relative de Rham cohomology class, began in [B.09] where the first structure theorems are proved. Then in [B.10] we introduced the notion of theme which corresponds in the \ $[\lambda]-$primitive case to frescos having a unique Jordan-H{\""o}lder sequence. Themes correspond to asymptotic expansion of a given vanishing period, so to the image of a fresco in the module of asymptotic expansions. For a fixed relative de Rham cohomology class (for instance given by a smooth differential form $d-$closed and $df-$closed) each choice of a vanishing cycle in the spectral eigenspace of the monodromy for the eigenvalue \ $exp(2i\pi.\lambda)$ \ produces a \ $[\lambda]-$primitive theme, which is a quotient of the fresco associated to the given relative de Rham class itself. The first part of this paper shows that, for any \ $[\lambda]-$primitive fresco there exists an unique Jordan-H{\""o}lder sequence (called the principal J-H. sequence) with corresponding quotients giving the opposite of the roots of the Bernstein polynomial in a non decreasing order.

Then we introduce and study the semi-simple part of a given fresco and we characterize the semi-simplicity of a fresco by the fact for any given order of the roots of its Bernstein polynomial we may find a J-H. sequence making them appear with this order. Then, using the parameter associated to a rank \ 2 \ \ $[\lambda]-$primitive theme, we introduce inductiveley a numerical invariant, that we call the \ $\alpha-$invariant, which depends polynomially on the isomorphism class of a fresco (in a sens which has to be defined) and which allows to give an inductive way to produce a sub-quotient rank \ 2 \ theme of a given \ $[\lambda]-$primitive fresco assuming non semi-simplicity. In the last section we prove a general existence result which naturally associate a fresco to any relative de Rham cohomology class of a proper holomorphic function of a complex manifold onto a disc. This is, of course, the motivation for the study of frescos.",378
Asymptotics of a vanishing period : General existence theorem and basic properties of frescos,1,"This paper studies the asymptotic properties of a vanishing period and presents a general existence theorem and basic properties of frescos within this context. Our main result shows the existence of a solution for a particular class of problems involving a vanishing period, and establishes a representation formula for it. The proof relies on a combination of techniques including the theory of periodic homogenization and the method of Fourier analysis.

In addition to the existence theorem, we investigate several basic properties of frescos and prove that they are a useful tool for studying the behavior of solutions near a vanishing period. Specifically, we show that frescos are uniformly bounded and have an asymptotic expansion in powers of the period that vanishes. Moreover, we explore the connection between the asymptotic behavior of frescos and the behavior of solutions of the original problem.

Our analysis has interesting applications in many fields, including elasticity, electromagnetics, heat transfer, and fluid mechanics. Indeed, many problems in these areas can be recast as problems involving a vanishing period, and our results provide a useful framework for their analysis. For instance, we show that the behavior of wave propagation in a heterogeneous medium can be understood in terms of fresco expansions.

To conclude, the main contribution of this paper is the establishment of a general existence theorem for a class of problems involving a vanishing period, and the investigation of basic properties of frescos in this context. Our results have interesting applications and pave the way for further developments in the analysis of problems with a vanishing period.",261
Fundamental limitations for antenna radiation efficiency,0,"Small volume, finite conductivity and high frequencies are major imperatives in the design of communications infrastructure. The radiation efficiency $\eta_r$ impacts on the optimal gain, quality factor, and bandwidth. The current efficiency limit applies to structures confined to a radian sphere $ka$ ($k$ is the wave number, $a$ is the radius). Here we present new absolute limits to $\eta_r$ for arbitrary antenna shapes based on $k^2S$ where $S$ is the conductor surface area. For a dipole with an electrical length of $10^{-5}$ our result is four orders of magnitude closer to the analytical solution when compared with previous bounds on the efficiency. The improved bound on $\eta_r$ is more accurate, more general, and easier to calculate than other limits. The efficiency of an antenna cannot be larger than the case where the surface of the antenna is 'peeled' off and assembled into a planar sheet with area $S$, and a uniform current is excited along the surface of this sheet.",162
Fundamental limitations for antenna radiation efficiency,1,"Antenna radiation efficiency is a critical factor in the design of wireless communication systems. Despite efforts to improve it, limitations in antenna performance exist at fundamental levels. These limitations are related to physical principles such as the conservation of energy and the impedance matching between the antenna and the feeding circuitry. The study of these limitations calls for analytical and numerical methods that allow for the modeling of the antenna’s behavior under different conditions. A comprehensive understanding of the underlying phenomena is necessary to establish design guidelines that optimize the radiation efficiency of the antenna. This article presents a review of the fundamental limitations for antenna radiation efficiency. It covers topics such as the maximum radiation efficiency, the bandwidth efficiency limits, and the trade-off between antenna gain and bandwidth. The insights gained from this study can aid researchers and practitioners in improving the performance of antenna systems.",149
"Noncommutative Maxwell-Chern-Simons theory, duality and a new noncommutative Chern-Simons theory in d=3",0,"Noncommutative Maxwell-Chern-Simons theory in 3-dimensions is defined in terms of star product and noncommutative fields. Seiberg-Witten map is employed to write it in terms of ordinary fields. A parent action is introduced and the dual action is derived. For spatial noncommutativity it is studied up to second order in the noncommutativity parameter \theta. A new noncommutative Chern-Simons action is defined in terms of ordinary fields, inspired by the dual action. Moreover, a transformation between noncommuting and ordinary fields is proposed.",85
"Noncommutative Maxwell-Chern-Simons theory, duality and a new noncommutative Chern-Simons theory in d=3",1,"In this paper, we investigate the noncommutative Maxwell-Chern-Simons theory in three dimensions. We demonstrate the existence of duality between the electric and magnetic sectors and investigate the underlying algebraic structure of the theory. We then introduce a new noncommutative Chern-Simons theory with a different gauge group and demonstrate its relation with the original theory. Our results provide new insights into the interplay between noncommutative geometry and gauge theories, and have potential implications for higher-dimensional field theories.",80
A Multi-technique Study of the Dynamical Evolution of the Viscous Disk around the Be Star {\omega} CMa,0,"There is an increasing body of evidence that suggests that Be disks are well described by the Viscous Decretion Disk (VDD) model according to which the formation and structure of the disk depend on the kinematic viscosity of the gas. However, most observational tests of the VDD to-date were done for systems that do not display strong temporal variability. From this analysis we (1) obtain a realistic physical model of the circumstellar environment; (2) measure the viscosity parameter of the gas, both during the formation and dissipation phases of the disk; (3) obtain a reliable estimate of the stellar mass and angular momentum loss rates during outburst. Our simulations suggests that the VDD model adequately describes the structural evolution of the disk.

Furthermore, our analysis allowed us to determine the viscosity parameter a, as well as the net mass and angular momentum (AM) loss rates. We find that a is variable, ranging from 0.1 to 1.0, not only from cycle to cycle but also within a given cycle. Additionally, build-up phases have larger values of a than the dissipation phases. We also find that, contrary to what is generally assumed, during dissipation the outward AM flux is not necessarily zero, meaning that {\omega} CMa does not experience a true quiescence but, instead, switches between a high AM loss rate state to a low AM loss rate one during which the disk quickly assumes an overall lower density but never zero. We confront the average AM loss rate with predictions from stellar evolution models for fast-rotating stars, and find that our measurements are smaller by more than one order of magnitude. The model developed using the V-band photometry as a constraint was applied to several other observables. Overall, the results of this multi-technique study were very positive, with a good match for multi-band photometry, polarization, and most spectroscopic characteristics.",316
A Multi-technique Study of the Dynamical Evolution of the Viscous Disk around the Be Star {\omega} CMa,1,"This research paper presents a multi-technique study of the dynamical evolution of the viscous disk around the Be star Ω CMa. The disk around Be stars is a well-known phenomenon in astrophysics and is thought to be caused by a rapid rotation of the star, resulting in the ejection of material from its equator.

In this study, we used a combination of spectroscopic, spectropolarimetric, and interferometric observations to explore the properties of the disk around Ω CMa. Our results show that the disk is highly structured and asymmetric, with different regions of the disk exhibiting different physical conditions.

We used the Hα line profiles to probe the disk kinematics and found that the disk is in Keplerian rotation, with a central mass of 13.2 ± 2.0 M⊙. We also found evidence of non-uniform density and velocity structures in the disk, which could be caused by the presence of spiral arms.

Our spectropolarimetric observations revealed the existence of a magnetic field in the disk, which may play an important role in its dynamics and stability. Our interferometric observations provided spatially resolved images of the disk, which showed that it is extended and clumpy, with the clumps likely caused by instabilities in the disk.

Overall, our study provides a comprehensive view of the dynamical evolution of the viscous disk around Ω CMa, revealing its complex and varied structure. This work contributes to our understanding of the physics of Be star disks and provides a valuable resource for future research in this field.",254
Reflection in Seyfert Galaxies and the Unified Model of AGN,0,"We present a deep study of the average hard X-ray spectra of Seyfert galaxies. We analyzed all public INTEGRAL IBIS/ISGRI data available on all the 165 Seyfert galaxies detected at z<0.2. Our final sample consists of 44 Seyfert 1's, 29 Seyfert 1.5's, 78 Seyfert 2's, and 14 Narrow Line Seyfert 1's. We derived the average hard X-ray spectrum of each subsample in the 17-250keV energy range. All classes of Seyfert galaxies show on average the same nuclear continuum, as foreseen by the zeroth order unified model, with a cut-off energy of Ec>200keV, and a photon index of Gamma ~1.8. Compton-thin Seyfert 2's show a reflection component stronger than Seyfert 1's and Seyfert 1.5's. Most of this reflection is due to mildly obscured (10^23 cm^-2 < NH < 10^24 cm^-2) Seyfert 2's, which have a significantly stronger reflection component (R=2.2^{+4.5}_{-1.1}) than Seyfert 1's (R<=0.4), Seyfert 1.5's (R<= 0.4) and lightly obscured (NH < 10^23 cm^-2) Seyfert 2's (R<=0.5). This cannot be explained easily by the unified model. The absorber/reflector in mildly obscured Seyfert 2's might cover a large fraction of the X-ray source, and have clumps of Compton-thick material. The large reflection found in the spectrum of mildly obscured Seyfert 2's reduces the amount of Compton-thick objects needed to explain the peak of the cosmic X-ray background. Our results are consistent with the fraction of Compton-thick sources being ~10%. The spectra of Seyfert 2's with and without polarized broad lines do not show significant differences, the only difference between the two samples being the higher hard X-ray and bolometric luminosity of Seyfert 2's with polarized broad lines. The average hard X-ray spectrum of Narrow line Seyfert 1's is steeper than those of Seyfert 1's and Seyfert 1.5's, probably due to a lower energy of the cutoff.",350
Reflection in Seyfert Galaxies and the Unified Model of AGN,1,"Seyfert galaxies have been extensively studied in recent years to understand the mechanisms behind active galactic nuclei (AGN). AGN are among the brightest and most energetic sources in the universe, and their observed properties provide valuable information about the physical processes that occur in their vicinity. Reflection is a crucial component of AGN physics, as it serves as a probe of the geometry and composition of the accretion disk and the surrounding material. 

In this paper, we investigate the role of reflection in Seyfert galaxies and its relation to the unified model of AGN. The unified model posits that Seyfert galaxies and other AGN share the same underlying physical structure, but the observed differences are due to the orientation of the observer relative to the source. In particular, the model postulates the existence of an optically thick torus that obscures the central engine and the broad-line region from certain viewing angles.

We analyze a sample of Seyfert galaxies with high-quality X-ray spectra obtained by the NuSTAR satellite, which offers unprecedented sensitivity and resolution in the 3-79 keV energy range. By fitting sophisticated reflection models to the data, we determine the properties of the accretion disk and the covering fraction of the torus. We find that the level of reflection varies widely among Seyfert galaxies, with some sources exhibiting strong reflection, while others show little or none. We also discover a connection between the strength of the reflection and the inclination angle of the torus, which supports the unified model. 

Our results have important implications for the nature and evolution of AGN. The diversity of the reflection properties suggests that Seyfert galaxies are not a homogenous population, and that different mechanisms may be responsible for producing the observed emission. Moreover, the correlation between reflection and orientation provides a new constraint on the geometry and properties of the torus. Further studies of larger samples of Seyfert galaxies and multiwavelength observations will help to refine our understanding of AGN physics and the unified model.",335
Near-infrared observations of type Ia supernovae: The best known standard candle for cosmology,0,"We present an analysis of the Hubble diagram for 12 Type Ia supernovae (SNe Ia) observed in the near-infrared J and H bands. We select SNe exclusively from the redshift range 0.03 < z < 0.09 to reduce uncertainties coming from peculiar velocities while remaining in a cosmologically well-understood region. All of the SNe in our sample exhibit no spectral or B-band light-curve peculiarities and lie in the B-band stretch range of 0.8-1.15. Our results suggest that SNe Ia observed in the near-infrared (NIR) are the best known standard candles. We fit previously determined NIR light-curve templates to new high-precision data to derive peak magnitudes and to determine the scatter about the Hubble line.

Photometry of the 12 SNe is presented in the natural system. Using a standard cosmology of (H_0, Omega_m, Lambda) = (70,0.27,0.73) we find a median J-band absolute magnitude of M_J = -18.39 with a scatter of 0.116 and a median H-band absolute magnitude of M_H = -18.36 with a scatter of 0.085. The scatter in the H band is the smallest yet measured. We search for correlations between residuals in the J- and H-band Hubble diagrams and SN properties, such as SN colour, B-band stretch and the projected distance from host-galaxy centre. The only significant correlation is between the J-band Hubble residual and the J-H pseudo-colour. We also examine how the scatter changes when fewer points in the near-infrared are used to constrain the light curve. With a single point in the H band taken anywhere from 10 days before to 15 days after B-band maximum light and a prior on the date of H-band maximum set from the date of B-band maximum, we find that we can measure distances to an accuracy of 6%. The precision of SNe Ia in the NIR provides new opportunities for precision measurements of both the expansion history of the universe and peculiar velocities of nearby galaxies.",345
Near-infrared observations of type Ia supernovae: The best known standard candle for cosmology,1,"Type Ia supernovae (SNe Ia) are known to be the most reliable ""standard candles"" used in cosmology. These type of supernovae reach an extremely high temperature and brightness, and their light curves are easily observable at both visible and near-infrared wavelengths. Despite this, the wavelength range of the observations of SNe Ia has not always been optimized for maximum efficiency. In recent years, observations in the near-infrared (NIR) have proven to be particularly beneficial for improving the cosmological accuracy of SNe Ia, leading to a more precise measurement of the expansion rate of the universe.

NIR observations provide a number of advantages in comparison to visible light observations. These benefits include lower extinction due to dust, a reduced dependence on the host galaxy's metallicity, and a smaller impact of intrinsic variations in the spectral features of SNe Ia on their observed flux. Additionally, NIR observations can be used to identify SNe Ia at higher redshifts, beyond the capability of optical telescopes, allowing for the study of the distribution of dark matter and dark energy in the universe.

Several research teams have now successfully used NIR observations to identify and classify SNe Ia. Initial results from these studies suggest that NIR observations may produce more accurate determinations of the distance modulus and other cosmological parameters. These new measurements have the potential to uncover new information about the universe, such as precise constraints on the equation of state of dark energy and the evolution of dark matter.

While NIR observations have proven to be a powerful tool for cosmologists, they are not without their limitations. For example, the collection of NIR data is more uniquely challenging than visible light observations, requiring larger detectors and longer exposure times. However, NIR observations of SNe Ia have already demonstrated their efficacy, and future studies are expected to make full use of this powerful tool.

Overall, the application of NIR observations has led to significant progress in determining cosmological parameters. As such, complete surveys using NIR observations of SNe Ia will be essential for the future of precision cosmology.",346
"Physics case for an LHCb Upgrade II - Opportunities in flavour physics, and beyond, in the HL-LHC era",0,"The LHCb Upgrade II will fully exploit the flavour-physics opportunities of the HL-LHC, and study additional physics topics that take advantage of the forward acceptance of the LHCb spectrometer. The LHCb Upgrade I will begin operation in 2020. Consolidation will occur, and modest enhancements of the Upgrade I detector will be installed, in Long Shutdown 3 of the LHC (2025) and these are discussed here. The main Upgrade II detector will be installed in long shutdown 4 of the LHC (2030) and will build on the strengths of the current LHCb experiment and the Upgrade I. It will operate at a luminosity up to $ 2 \times 10^{34} \rm cm^{-2}s^{-1}$, ten times that of the Upgrade I detector. New detector components will improve the intrinsic performance of the experiment in certain key areas. An Expression Of Interest proposing Upgrade II was submitted in February 2017. The physics case for the Upgrade II is presented here in more depth. $CP$-violating phases will be measured with precisions unattainable at any other envisaged facility. The experiment will probe $b\to s \ell^+\ell^-$ and $b\to d \ell^+\ell^-$ transitions in both muon and electron decays in modes not accessible at Upgrade I. Minimal flavour violation will be tested with a precision measurement of the ratio of $B(B^0\to\mu^+\mu^-)/B(B_s^0\to \mu^+\mu^-)$. Probing charm $CP$ violation at the $10^{-5}$ level may result in its long sought discovery. Major advances in hadron spectroscopy will be possible, which will be powerful probes of low energy QCD. Upgrade II potentially will have the highest sensitivity of all the LHC experiments on the Higgs to charm-quark couplings. Generically, the new physics mass scale probed, for fixed couplings, will almost double compared with the pre-HL-LHC era; this extended reach for flavour physics is similar to that which would be achieved by the HE-LHC proposal for the energy frontier.",328
"Physics case for an LHCb Upgrade II - Opportunities in flavour physics, and beyond, in the HL-LHC era",1,"The LHCb collaboration is planning an upgrade to its detector and data acquisition system, which will enable the experiment to collect data at an unprecedented rate at the High-Luminosity LHC (HL-LHC). In this paper, we present the physics case for this upgrade, focusing on the opportunities it will provide for studies of flavour physics and beyond in the HL-LHC era.

Flavour physics is the study of the properties of particles that determine their decays, and it provides a unique window into new physics beyond the Standard Model. The LHCb experiment has already made significant contributions to this field, and the upgrade will allow us to explore even rarer and more subtle phenomena. With the upgraded detector, we will be able to measure with greater precision the decays of b-hadrons, which are rich in flavour-changing neutral currents, and investigate the patterns of CP violation in these decays. In addition, we will be able to search for evidence of new particles and interactions that could explain some of the puzzles in flavour physics, such as the observed excess of matter over antimatter in the universe.

Beyond flavour physics, the upgraded LHCb detector will open up new opportunities in other areas of particle physics. With its improved particle identification and tracking, it will be able to study rare processes involving kaons and rare tau decays, providing complementary information to experiments at other colliders. The upgraded detector will also be sensitive to a wide range of exotic particles, including dark matter candidates, sterile neutrinos, and axion-like particles, which could reveal new physics beyond the Standard Model.

In conclusion, the LHCb Upgrade II presents a compelling physics case for exploring the frontiers of particle physics in the HL-LHC era. With its improved capabilities for studying flavour physics and beyond, it will make a unique contribution to the worldwide effort to understand the fundamental nature of the universe.",319
On torque computation in electric machine simulation by harmonic mortar methods,0,"The use of trigonometric polynomials as Lagrange multipliers in the harmonic mortar method enables an efficient and elegant treatment of relative motion in the stator-rotor coupling of electric machine simulation. Explicit formulas for the torque computation are derived by energetic considerations, and their realization by harmonic mortar finite element and isogemetric analysis discretizations is discussed. Numerical tests are presented to illustrate the theoretical results and demonstrate the potential of harmonic mortar methods for the evaluation of torque ripples.",79
On torque computation in electric machine simulation by harmonic mortar methods,1,"This paper presents a novel approach to torque computation in electric machine simulation using harmonic mortar methods. Specifically, we propose a new formulation based on the mortar element method that yields accurate and efficient results, even for high-order geometries. Through numerical experiments, we demonstrate the superiority of our method over other commonly used techniques, exhibiting excellent convergence rates and scalability. Our findings have important implications for the design and optimization of electric machines for various industrial applications.",78
Inequalities for the Hodge numbers of irregular compact Kaehler manifolds,0,"Based on work of R. Lazarsfeld and M. Popa, we use the derivative complex associated to the bundle of the holomorphic p-forms to provide inequalities for all the Hodge numbers of a special class of irregular compact Kaehler manifolds. For 3-folds and 4-folds we give an asymptotic bound for all the Hodge numbers in terms of the irregularity. As a byproduct, via the BGG correspondence, we also bound the regularity of the exterior cohomology modules of bundles of holomorphic p-forms.",84
Inequalities for the Hodge numbers of irregular compact Kaehler manifolds,1,"This research article presents new inequalities for the Hodge numbers of irregular compact Kaehler manifolds. The main result of the study details the relationship between the Hodge numbers and the dimension of the manifold, and demonstrates how this relationship affects the overall algebraic topology of such manifolds. We prove the inequalities using a combination of geometric and algebraic techniques, yielding novel insights into the structure of these manifolds. This work has broad implications for algebraic geometry, differential geometry, and topology, and represents a significant contribution to the field.",88
New first trimester crown-rump length's equations optimized by structured data collection from a French general population,0,"--- Objectives --- Prior to foetal karyotyping, the likelihood of Down's syndrome is often determined combining maternal age, serum free beta-HCG, PAPP-A levels and embryonic measurements of crown-rump length and nuchal translucency for gestational ages between 11 and 13 weeks. It appeared important to get a precise knowledge of these scan parameters' normal values during the first trimester. This paper focused on crown-rump length. --- METHODS --- 402 pregnancies from in-vitro fertilization allowing a precise estimation of foetal ages (FA) were used to determine the best model that describes crown-rump length (CRL) as a function of FA. Scan measures by a single operator from 3846 spontaneous pregnancies representative of the general population from Northern France were used to build a mathematical model linking FA and CRL in a context as close as possible to normal scan screening used in Down's syndrome likelihood determination. We modeled both CRL as a function of FA and FA as a function of CRL. For this, we used a clear methodology and performed regressions with heteroskedastic corrections and robust regressions.

The results were compared by cross-validation to retain the equations with the best predictive power. We also studied the errors between observed and predicted values. --- Results --- Data from 513 spontaneous pregnancies allowed to model CRL as a function of age of foetal age. The best model was a polynomial of degree 2. Datation with our equation that models spontaneous pregnancies from a general population was in quite agreement with objective datations obtained from 402 IVF pregnancies and thus support the validity of our model. The most precise measure of CRL was when the SD was minimal (1.83mm), for a CRL of 23.6 mm where our model predicted a 49.4 days of foetal age. Our study allowed to model the SD from 30 to 90 days of foetal age and offers the opportunity of using Zscores in the future to detect growth abnormalities. --- Conclusion --- With powerful statistical tools we report a good modeling of the first trimester embryonic growth in the general population allowing a better knowledge of the date of fertilization useful in the ultrasound screening of Down's syndrome. The optimal period to measure CRL and predict foetal age was 49.4 days (9 weeks of gestational age). Our results open the way to the detection of foetal growth abnormalities using CRL Zscores throughout the first trimester.",401
New first trimester crown-rump length's equations optimized by structured data collection from a French general population,1,"In this study, we present our findings in creating new first trimester crown-rump length equations that have been optimized through structured data collection from a French general population. Early prenatal care is essential in ensuring the well-being of both the mother and the fetus. One crucial aspect of early prenatal care is the accurate measurement of the crown-rump length (CRL) of the fetus, which is used to estimate the gestational age of the fetus.

We aimed to develop new CRL equations that were optimized through structured data collection from a French general population. Our dataset consisted of 4,893 pregnant women who underwent routine ultrasound examinations during their first trimester. We gathered data on the CRL and gestational age of these women and developed new equations based on this data.

Our results showed that the CRL equations we developed were more accurate and precise in estimating gestational age than the currently used equations. Furthermore, our equations performed better across a wide range of gestational ages, which makes them more applicable to a diverse population.

One of the most significant contributions of our study is the use of a French general population in the optimization of the CRL equations. Previous studies have focused on specific subpopulations, which limits the applicability of the equations developed. By using a general population, our equations are more generalizable and applicable to a wider population.

Overall, our study provides new CRL equations that are optimized using structured data collection from a French general population. These equations are more accurate and precise in estimating gestational age and are applicable to a diverse population. Our findings have implications for early prenatal care, as accurate gestational age estimation is crucial in ensuring the well-being of both the mother and the fetus.",296
A MIKE + UVES survey of Sub-Damped Lyman-Alpha Systems at z<1.5,0,"We have combined the results from our recent observations of Damped and sub-Damped Lyman-alpha systems with the MIKE and UVES spectrographs on the Magellan Clay and VLT Kueyen telescopes with ones from the literature to determine the N(HI)-weighted mean metallicity of these systems based both on Fe, a depleted element in QSO absorbers and the local ISM, and Zn a relatively undepleted element. In each case, the N(HI)-weighted mean metallicity is higher and shows faster evolution in sub-DLAs than the classical DLA systems. Large grids of photoionisation models over the sub-DLA \nhI range with CLOUDY show that the ionisation corrections to the abundances are in general small, however the fraction of ionized H can be up to ~90 per cent. The individual spectra have been shifted to the rest frame of the absorber and averaged together to determine the average properties of these systems at z<1.5. We find that the average abundance pattern of the Sub-DLA systems is similar to the gas in the halo of the Milky Way, with an offset of ~0.3 dex in the overall metallicity.

Both DLAs and Sub-DLAs show similar characteristics in their relative abundances patterns, although the DLAs have smaller <[Mn/Zn]> as well as higher <[Ti/Zn]> and <[Cr/Zn]>. We calculate the contribution of sub-DLAs to the metal budget of the Universe, and find that the sub-DLA systems at z<1.5 contain a comoving density of metals Omega_met (3.5-15.8)x10^{5} M_sun Mpc^{-3}, at least twice the comoving density of metals in the DLA systems. The sub-DLAs do however track global chemical evolution models much more closely than do the DLAs, perhaps indicating that they are a less dust biased metallicity indicator of galaxies at high redshifts than the DLA systems.",310
A MIKE + UVES survey of Sub-Damped Lyman-Alpha Systems at z<1.5,1,"Recent observations indicate that low-mass galaxies may play a crucial role in the star formation history of the universe. In this context, we present a survey of sub-damped Lyman-Alpha (sub-DLA) systems at redshifts z<1.5, tracing the neutral gas content of low-mass galaxies and their role in galaxy evolution. Our survey is based on the combination of two samples, the MIKE and UVES samples, which consist of high-resolution spectroscopic data taken with the Magellan Inamori Kyocera Echelle (MIKE) and the Ultraviolet and Visual Echelle Spectrograph (UVES) instruments, respectively. Our analysis shows that sub-DLA systems are primarily associated with low-mass galaxies, implying that these galaxies play a crucial role in the process of galaxy evolution by serving as reservoirs of neutral gas.

We apply a bayesian model comparison approach to show that these systems are consistent with a simple model of homogeneous, turbulent gas occupying a spherically-symmetric region within the host galaxy. Our analysis also reveals a correlation between the kinematics of the sub-DLA absorption features and the galaxy, suggesting that the sub-DLA systems are intimately tied to the host galaxy's overall properties. We also investigate the impact of sub-DLA systems on the intergalactic medium (IGM) and find that their contribution to the overall HI content of the IGM is small, indicating that sub-DLAs are unlikely to play a dominant role in cosmic reionization. Overall, our study sheds new light on the connection between low-mass galaxies and the neutral gas content of the universe, providing crucial insights into the processes governing galaxy evolution and the history of the universe.",274
Quotients of exact categories by cluster tilting subcategories as module categories,0,"We prove that some subquotient categories of exact categories are abelian.

This generalizes a result by Koenig-Zhu in the case of (algebraic) triangulated categories. As a particular case, if an exact category B with enough projectives and injectives has a cluster tilting subcategory M, then B/M is abelian. More precisely, it is equivalent to the category of finitely presented modules over the stable category of M.",68
Quotients of exact categories by cluster tilting subcategories as module categories,1,"We study the quotient categories of exact categories by cluster tilting subcategories, which are naturally module categories. We investigate the relationship between these categories and their cluster-tilting objects, showing that such objects act as generators. Our work leads to a complete understanding of the homological properties of these categories, including their Auslander-Reiten theory and the shape of their singularity categories.",62
Curvature-driven migration of colloids on lipid bilayers,0,"Colloids and proteins alike can bind to lipid bilayers and move laterally in these two-dimensional fluids. Inspired by proteins that generate membrane curvature, sense the underlying membrane geometry, and migrate to high curvature sites, we explore the question: Can colloids, adhered to lipid bilayers, also sense and respond to membrane geometry? We report the curvature migration of Janus microparticles adhered to giant unilamellar vesicles elongated to present well defined curvature fields. However, unlike proteins, which migrate to minimize membrane bending energy, colloids migrate by an entirely different mechanism. By determining the energy dissipated along a trajectory, the energy field mediating these interactions is inferred to be linear in the local deviatoric curvature, as reported previously for colloids trapped at curved interfaces between immiscible fluids. In this latter system, however, the energy gradients are far larger, so particles move deterministically, whereas the colloids on vesicles move with significant fluctuations in regions of weak curvature gradient. By addressing the role of Brownian motion, we show that the observed curvature migration of colloids on bilayers is indeed a case of curvature capillary migration, with membrane tension playing the role of interfacial tension. Furthermore, since this motion is mediated by membrane tension and shape, it can be modulated, or even turned ""on"" and ""off"", by simply varying these parameters. While particle-particle interactions on lipid membranes have been considered in many contributions, we report here an exciting and previously unexplored modality to actively direct the migration of colloids to desired locations on lipid bilayers.",251
Curvature-driven migration of colloids on lipid bilayers,1,"This research work investigates the curvature-driven migration of colloids on lipid bilayers. The interaction between colloids and lipid bilayers has gained significant attention in recent years. The curvature of the lipid bilayers acts as a driving force for colloidal migration, but the underlying mechanism behind this phenomenon is not well-understood. By using microscopy and spectroscopic techniques, this study showcases the experimental results of the colloids' dynamic migration on model lipid bilayers.

The outcome of the experiments indicates that the curvature of the lipid bilayers creates gradients in the lateral energy landscape that act as a driving force, leading to the migration of colloids. The migration speed of the colloids is found to increase with the lipid bilayer's curvature, with greater curvature causing faster migration rates. The use of different types of colloids in the experiments helped to elucidate this phenomenon.

This research contributes to our understanding of the interplay between lipid bilayers and colloidal particles, and it opens up new possibilities for the development of colloidal transport devices. It has implications in diverse areas of research, such as biomimetic systems, drug delivery, and pore formation in biological membranes. These findings have significant implications for the design of synthetic systems that mimic the function and behavior of biological systems. Overall, this study provides a fundamental understanding of the dynamics of colloidal migration in lipid bilayers and opens up new possibilities for the development of novel applications in the field of materials science.",244
The biomechanical properties of F1C pili,0,"Uropathogenic Escherichia coli (UPEC) express various kinds of organelles, so-called pili or fimbriae, that mediate adhesion to host tissue in the urinary tract through specific receptor-adhesin interactions. The biomechanical properties of these pili have been considered important for the ability of bacteria to withstand shear forces from rinsing urine flows. Force measuring optical tweezers have been used to characterize individual organelles of F1C type expressed by UPEC bacteria with respect to such properties. Qualitatively, the force-vs.-elongation response was found to be similar to that of other types of helix-like pili expressed by UPEC, i.e. type 1, P, and S, with force-induced elongation in three regions of which one represents the important uncoiling mechanism of the helix-like quaternary structure. Quantitatively, the steady-state uncoiling force was assessed to 26.4(1.4) pN, which is similar to those of other pili (which range from 21 pN for SI to 30 pN for type 1). The corner velocity for dynamic response (1400 nm/s) was found to be larger than those of the other pili (400 -700 nm/s for S and P pili, and 6 nm/s for type 1). The kinetics were found to be faster, with a thermal opening rate of 17 Hz, a few times higher than S and P pili, and three orders of magnitude times higher than type 1. These data suggest that F1C pili are, like P and S pili, evolutionary-selected to primarily withstand the conditions expressed in the upper urinary tract.",256
The biomechanical properties of F1C pili,1,"F1C pili are filamentous surface appendages produced by bacteria that play a crucial role in biofilm formation and bacterial pathogenesis. Understanding the biomechanical properties of F1C pili is key to developing strategies to prevent bacterial infections. In this study, we characterized the mechanical behavior of F1C pili using atomic force microscopy (AFM) and molecular dynamics simulations (MDS). Our AFM experiments revealed that F1C pili exhibit a nonlinear force-extension behavior, with a characteristic sawtooth pattern that suggests a modular structure. Using MDS, we predicted that the mechanical stability of F1C pili arises from the cooperation of individual pilin subunits and their interactions with the solvent and other biomolecules. We also found that the presence of calcium ions enhances the mechanical properties of F1C pili, possibly due to the formation of intramolecular and intermolecular bonds. Our results provide new insights into the biomechanics of F1C pili and pave the way to the rational design of novel antibacterial agents targeting these key virulence determinants. Additionally, our methodology can be extended to study other important pili systems and protein assemblies in the field of molecular biomechanics.",183
Local recoil of extended solitons: a string theory example,0,"It is well-known that localized topological defects (solitons) experience recoil when they suffer an impact by incident particles. Higher-dimensional topological defects develop distinctive wave patterns propagating along their worldvolume under similar circumstances. For 1-dimensional topological defects (vortex lines), these wave patterns fail to decay in the asymptotic future: the propagating wave eventually displaces the vortex line a finite distance away from its original position (the distance is proportional to the transferred momentum). The quantum version of this phenomenon, which we call ``local recoil'', can be seen as a simple geometric manifestation of the absence of spontaneous symmetry breaking in 1+1 dimensions. Analogously to soliton recoil, local recoil of vortex lines is associated with infrared divergences in perturbative expansions. In perturbative string theory, such divergences appear in amplitudes for closed strings scattering off a static D1-brane. Through a Dirac-Born-Infeld analysis, it is possible to resum these divergences in a way that yields finite, momentum-conserving amplitudes.",162
Local recoil of extended solitons: a string theory example,1,"We investigate the phenomenon of local recoil in extended solitons, focusing on a particular example from string theory. Solitons are stable solutions of nonlinear field equations that can propagate without changing their shape, and they can play an important role in many areas of physics. In the case of extended solitons, such as strings or membranes, we show that they can experience a localized recoil when they encounter a defect in their environment. We analyze the dynamics of this process and derive an expression for the recoil velocity in terms of the properties of the soliton and the defect. We use our results to discuss potential applications in string theory and related fields, such as the study of cosmic strings or the behavior of branes in higher-dimensional spaces. Our work provides new insights into the dynamical behavior of extended solitons and their interactions with their surroundings.",147
Groupes analytiques rigides p-divisibles II,0,"Let $K$ be a $p$-adic field. We continue to develop the theory of rigid analytic $p$-divisible groups over $K$. For example, we explain how to find back the category of Banach-Colmez spaces from rigid analytic $p$-divisible groups ""in finite level"" without perfectoid spaces. We then establish some results about families of rigid analytic $p$-divisible groups. This allows us to prove a ""minimality"" result in the sense of birationnal geometry for integral models of unramified Rapoport-Zink spaces.",82
Groupes analytiques rigides p-divisibles II,1,"Building upon the work from the first part of the paper, this article continues the study of rigid analytic groups of p-divisible type. Specifically, we investigate the moduli space of p-divisible groups associated to such groups. We introduce a new construction of these groups, which yields interesting algebraic properties inherited from the original rigid analytic group. The main objects of study are the Newton strata in these moduli spaces, and their description allows us to obtain new results in the arithmetic of these groups.",86
The {-3}-reconstruction and the {-3}-self duality of tournaments,0,"Let T = (V,A) be a (finite) tournament and k be a non negative integer. For every subset X of V is associated the subtournament T[X] = (X,A\cap (X \timesX)) of T, induced by X. The dual tournament of T, denoted by T\ast, is the tournament obtained from T by reversing all its arcs. The tournament T is self dual if it is isomorphic to its dual. T is {-k}-self dual if for each set X of k vertices, T[V \ X] is self dual. T is strongly self dual if each of its induced subtournaments is self dual. A subset I of V is an interval of T if for a, b \in I and for x \in V \ I, (a,x) \in A if and only if (b,x) \in A. For instance, \varnothing, V and {x}, where x \in V, are intervals of T called trivial intervals. T is indecomposable if all its intervals are trivial; otherwise, it is decomposable. A tournament T', on the set V, is {-k}-hypomorphic to T if for each set X on k vertices, T[V \ X] and T'[V \ X] are isomorphic. The tournament T is {-k}-reconstructible if each tournament {-k}-hypomorphic to T is isomorphic to it. Suppose that T is decomposable and | V |\geq 9. In this paper, we begin by proving the equivalence between the {-3}-self duality and the strong self duality of T. Then we characterize each tournament {-3}-hypomorphic to T. As a consequence of this characterization, we prove that if there is no interval X of T such that T[X] is indecomposable and | V \ X |\leq 2, then T is {-3}-reconstructible. Finally, we conclude by reducing the {-3}-reconstruction problem to the indecomposable case (between a tournament and its dual). In particular, we find and improve, in a less complicated way, the results of [6] found by Y. Boudabbous and A. Boussairi.",327
The {-3}-reconstruction and the {-3}-self duality of tournaments,1,"In this paper, we investigate the concept of the {-3}-reconstruction and the {-3}-self duality of tournaments. Tournaments are directed graphs where every pair of distinct vertices is connected by a single directed edge. They are widely used in modeling real-life situations in areas such as sports, politics, and economics. A {-3}-tournament is a tournament where every 3-cycle has a unique chord, meaning that it has a unique directed path connecting two non-adjacent vertices of the cycle. In the {-3}-reconstruction problem, we aim to reconstruct a labeled tournament from the multiset of lengths of its paths of length three.

We first determine the conditions for a tournament to be a {-3}-tournament. We then establish a necessary and sufficient condition for a multiset of integers to be the multiset of lengths of paths of length three in a {-3}-tournament. Using these results, we provide an algorithm for reconstructing a labeled {-3}-tournament from its multiset of path lengths and prove that the algorithm is correct.

Next, we investigate the concept of {-3}-self duality of tournaments. A tournament is {\tau-self dual} if there exists an automorphism of the tournament that takes every vertex to its complement with respect to $\tau$. We give a criterion for determining whether a tournament is {-3}-self dual, and show that this criterion also holds for the classes of transitive, regular, and strongly connected tournaments. Lastly, we provide a construction for {\tau}-self dual {-3}-tournaments with an even number of vertices.

Our results have implications in the fields of graph theory, combinatorics, and theoretical computer science. Specifically, they can be used to analyze and model real-life situations such as voting systems, sports tournaments, and social networks.",291
From core collapse to superluminous: The rates of massive stellar explosions from the Palomar Transient Factory,0,"We present measurements of the local core collapse supernova (SN) rate using SN discoveries from the Palomar Transient Factory (PTF). We use a Monte Carlo simulation of hundreds of millions of SN light curve realizations coupled with the detailed PTF survey detection efficiencies to forward-model the SN rates in PTF. Using a sample of 86 core collapse SNe, including 26 stripped-envelope SNe (SESNe), we show that the overall core collapse SN volumetric rate is $r^\mathrm{CC}_v=9.10_{-1.27}^{+1.56}\times10^{-5}\,\text{SNe yr}^{-1}\,\text{Mpc}^{-3}\, h_{70}^{3}$ at $ \langle z \rangle = 0.028$, and the SESN volumetric rate is $r^\mathrm{SE}_v=2.41_{-0.64}^{+0.81}\times10^{-5}\, \text{SNe yr}^{-1}\,\text{Mpc}^{-3}\, h_{70}^{3}$. We further measure a volumetric rate for hydrogen-free superluminous SNe (SLSNe-I) using 8 events at $z{\le}0.2$ of $r^\mathrm{SLSN-I}_v=35_{-13}^{+25}\, \text{SNe yr}^{-1}\text{Gpc}^{-3}\, h_{70}^{3}$, which represents the most precise SLSN-I rate measurement to date.

Using a simple cosmic star-formation history to adjust these volumetric rate measurements to the same redshift, we measure a local ratio of SLSN-I to SESN of $\sim1/810^{+1500}_{-94}$, and of SLSN-I to all CCSN types of $\sim 1/3500^{+2800}_{-720}$. However, using host galaxy stellar mass as a proxy for metallicity, we also show that this ratio is strongly metallicity dependent: in low-mass ($\mathrm{log} M_{*} < 9.5 \mathrm{M}_\odot$) galaxies, which are the only environments that host SLSN-I in our sample, we measure a SLSN-I to SESN fraction of $1/300^{+380}_{-170}$ and $1/1700^{+1800}_{-720}$ for all CCSN. We further investigate the SN rates a function of host galaxy stellar mass and show that the specific rates of all core collapse SNe decrease with increasing stellar mass.",329
From core collapse to superluminous: The rates of massive stellar explosions from the Palomar Transient Factory,1,"The Palomar Transient Factory (PTF) is a wide-field optical survey designed to systematically explore the transient and variable sky. In this paper, we present the rates of massive stellar explosions observed by PTF. These include core-collapse supernovae (CCSNe), Type IIb supernovae, and superluminous supernovae (SLSNe).

We analyzed a sample of 108 CCSNe, which constitute the largest sample of core-collapse events observed by a single survey to date. We also found 11 Type IIb SNe, which represent a rare subtype of CCSNe that exhibit a hydrogen-poor envelope. Additionally, we discovered 17 SLSNe, which are extremely bright explosions that cannot be explained by conventional models of supernovae.

We used a statistical approach to estimate the rates of these events, corrected for the survey efficiency and selection biases. We found that the rate of CCSNe is 2.73 ± 0.09 events per century per 10^10 solar masses, which is consistent with previous measurements. The rate of Type IIb SNe is much lower at 0.26 ± 0.06 events per century per 10^10 solar masses, while the rate of SLSNe is even lower at 0.31 ± 0.06 events per century per 10^10 solar masses.

Overall, our results provide important constraints on the rates of massive stellar explosions in the local universe, and have implications for the understanding of the final stages of the evolution of massive stars. The large sample of CCSNe observed by PTF enables us to study the properties of these events in more detail, and to explore the diversity in their observational characteristics. The discovery of Type IIb SNe and SLSNe by PTF contributes to the growing field of exotic explosions, and highlights the need for further theoretical and observational studies.",288
Towards Human Computable Passwords,0,"An interesting challenge for the cryptography community is to design authentication protocols that are so simple that a human can execute them without relying on a fully trusted computer. We propose several candidate authentication protocols for a setting in which the human user can only receive assistance from a semi-trusted computer --- a computer that stores information and performs computations correctly but does not provide confidentiality. Our schemes use a semi-trusted computer to store and display public challenges $C_i\in[n]^k$. The human user memorizes a random secret mapping $\sigma:[n]\rightarrow\mathbb{Z}_d$ and authenticates by computing responses $f(\sigma(C_i))$ to a sequence of public challenges where $f:\mathbb{Z}_d^k\rightarrow\mathbb{Z}_d$ is a function that is easy for the human to evaluate. We prove that any statistical adversary needs to sample $m=\tilde{\Omega}(n^{s(f)})$ challenge-response pairs to recover $\sigma$, for a security parameter $s(f)$ that depends on two key properties of $f$. To obtain our results, we apply the general hypercontractivity theorem to lower bound the statistical dimension of the distribution over challenge-response pairs induced by $f$ and $\sigma$. Our lower bounds apply to arbitrary functions $f $ (not just to functions that are easy for a human to evaluate), and generalize recent results of Feldman et al. As an application, we propose a family of human computable password functions $f_{k_1,k_2}$ in which the user needs to perform $2k_1+2k_2+1$ primitive operations (e.g., adding two digits or remembering $\sigma(i)$), and we show that $s(f) = \min\{k_1+1, (k_2+1)/2\}$.

For these schemes, we prove that forging passwords is equivalent to recovering the secret mapping. Thus, our human computable password schemes can maintain strong security guarantees even after an adversary has observed the user login to many different accounts.",310
Towards Human Computable Passwords,1,"Passwords are ubiquitous in our digital lives, serving as the gateway to a multitude of sensitive information. However, traditional alphanumeric passwords have become increasingly vulnerable to attacks by hackers. In response, researchers have begun exploring alternative authentication measures that are both secure and user-friendly. One such innovation is the concept of human computable passwords. 

Human computable passwords leverage the unique cognitive abilities of humans to create robust and easily remembered passwords. These passwords incorporate elements of randomness, requiring users to identify patterns and complete tasks that are intuitive for humans but difficult for machines. By harnessing the power of human cognition, human computable passwords are less vulnerable to attacks that rely on automated brute force or dictionary attacks. 

To date, research in this area has focused on optimizing the usability and security of human computable passwords. One key challenge is ensuring that users can effectively create and remember these passwords, especially across multiple accounts. Researchers have explored various mechanisms, such as creating visual mnemonics or using personalized stories, to facilitate this process. 

In addition to its potential as a secure, user-friendly authentication mechanism, human computable passwords may also have implications for fields such as cryptography and cognitive psychology. For example, some researchers have proposed leveraging human computable password schemes to support secure multi-party computation and to create secure computational protocols that are resilient to adversaries. Furthermore, the study of human computable passwords can provide insights into the cognitive processes that underlie human information processing and memory. 

In conclusion, human computable passwords represent a promising innovation in the field of secure authentication. The development of user-friendly and robust human computable password schemes has the potential to enhance security across a broad range of digital applications. Continued research in this area will bring us closer to realizing this promising potential.",302
"Fine-Grained, Language-Based Access Control for Database-Backed Applications",0,"Context: Database-backed applications often run queries with more authority than necessary. Since programs can access more data than they legitimately need, flaws in security checks at the application level can enable malicious or buggy code to view or modify data in violation of intended access control policies.

Inquiry: Although database management systems provide tools to control access to data, these tools are not well-suited for modern applications which often have many users and consist of many different software components. First, databases are unaware of application users, and creating a new database user for each application user is impractical for applications with many users.

Second, different components of the same application may require different authority, which would require creating different database users for different software components. Thus, it is difficult to use existing tools to properly limit the authority an application has when executing queries. For this reason, we consider a new, language-based approach to application-specific database security.

Approach: Prior work has addressed the difficulty of running applications with least privilege using capability-based security and software contracts, which we adapt to the setting of database-backed applications.

Knowledge: This paper's main contribution is the design and implementation of ShillDB, a language for writing secure database-backed applications. ShillDB enables reasoning about database access at the language level through capabilities, which limit which database tables a program can access, and contracts, which limit what operations a program can perform on those tables.

ShillDB contracts are expressed as part of function interfaces, making it easy to specify different access control policies for different components.

Contracts act as executable security documentation for ShillDB programs and are enforced by the language runtime. Further, ShillDB provides database access control guarantees independent of (and in addition to) the security mechanisms of the underlying database management system.

Grounding: We have implemented a prototype of ShillDB and have used it to implement the backend for a lending library reservation system with contracts for each endpoint to evaluate the performance and usability of ShillDB.

Further, we benchmark individual database operations in ShillDB to better understand the language's performance overhead.

Importance: Our experience indicates that ShillDB is a practical language for enforcing database access control policies in realistic, multi-user applications and has reasonable performance overhead. ShillDB allows developers to reason about security at the component level, safely compose components, and reuse third-party components with their own application-specific database security policies.",409
"Fine-Grained, Language-Based Access Control for Database-Backed Applications",1,"Fine-grained, language-based access control for database-backed applications refers to a security mechanism that offers database access based on predefined language constructs. The aim of this research paper is to investigate the effectiveness of fine-grained access control in enforcing data privacy and security. 

This study was motivated by the need to control and manage access to sensitive data stored in database-backed applications. Malicious actors continually look for ways to exploit vulnerabilities in software systems to gain unauthorized access to sensitive data. Access control, therefore, is necessary to prevent unauthorized access and protect data privacy.

We conducted a comprehensive review of the existing literature on access control mechanisms for database-backed applications. Existing approaches rely on coarse-grained access control that grants privileges to large user groups. However, as databases become more complex and contain more sensitive information, the need for more fine-grained access control becomes critical.

We propose a fine-grained access control mechanism that is based on the constructs of the programming language used to develop the application. This approach leverages the familiarity of developers with the programming language and its constructs to enforce access control. To evaluate the effectiveness of our approach, we developed a prototype application that implements our mechanism.

The prototype application was subject to various simulated attack scenarios to test the security and effectiveness of the fine-grained access control mechanism. The results of our experiments show that fine-grained access control based on language constructs effectively prevents unauthorized access to sensitive data.

Furthermore, our proposed mechanism does not require extensive modifications to the application code or the database structure. Instead, it uses the existing programming constructs, making it easier to integrate with existing applications. 

In summary, the proposed fine-grained, language-based access control mechanism offers significant improvements over the traditional coarse-grained access control. Our experiments demonstrate that the proposed mechanism is effective in enforcing data privacy and security and does not require extensive changes to the database schema. We believe that our approach could be easily adopted by software developers to improve the security of their applications and databases.",352
Characterization of the electronic properties of YB$_4$ and YB$_6$ using $^{11}$B NMR and first-principles calculations,0,"Two compounds, tetragonal YB$_4$ and cubic YB$_6$, have been investigated by electric-field gradient (EFG) and Knight shift measurements at the boron sites using the $^{11}$B nuclear magnetic resonance (NMR) technique and by performing first-principles calculations. In YB$_6$ $^{11}$B ($I=3/2$) NMR spectra reveal patterns typical for an axially symmetric field gradient with a quadrupole coupling frequency of $\nu_Q=600\pm15$ kHz. In the second boride (YB$_4$) three different EFGs were observed corresponding to the three inequivalent crystallographic sites for the boron atoms ($4h$, $4e$, and $8j$). They correspond to: $\nu_Q(4h)=700\pm30$ kHz with an asymmetry parameter $\eta=0.02\pm0.02$, $\nu_Q(4e)=515\pm30$ kHz, $\eta=0.00+0.02/-0.00$, and $\nu_Q(8j)=515\pm40$ kHz, $\eta=0.46\pm0.08$. The Knight shifts measured by Magic-Angle Spinning (MAS) NMR at room temperature are very small being $0.6\pm8$ ppm and $-1\pm8$ ppm for YB$_4$ and YB$_6$, respectively. For the theoretical calculations structure optimizations were performed as a first step. For the obtained structural parameters the EFGs were computed within the local-density approximation. Very satisfactory agreement between experimental and theoretical results is obtained both for the structural parameters and the B EFGs thus confirming the underlying structural models. In addition to the EFGs, band structures, densities of states, and valence-electron densities are presented and the bonding situation in the two yttrium borides is discussed.

The band-structure results are compatible with the very low values for the Knight shifts mentioned above.",262
Characterization of the electronic properties of YB$_4$ and YB$_6$ using $^{11}$B NMR and first-principles calculations,1,"The electronic properties of YB$_4$ and YB$_6$ have been characterized in this study using $^{11}$B NMR and first-principles calculations. Our findings show that YB$_4$ and YB$_6$ exhibit distinguishable NMR signals, which we attribute to the different environments experienced by the B atoms within their respective crystal structures. From our first-principles calculations, we have elucidated the nature of the electronic states at the Fermi level of YB$_4$ and YB$_6$, which are shown to be predominantly derived from the B $p$ orbitals, with an admixture of Y $d$ states. The calculated density of states also reveals that YB$_4$ and YB$_6$ exhibit metallic behavior with a small overlap of the B $p$ bands at the Fermi level, suggesting weak B-B interactions. Our results are consistent with previous experimental findings, and provide further insight into the nature of the electronic properties of these two ytterbium borides. Our study could help pave the way for the design and discovery of new boride materials with interesting physical properties. Future work should continue to explore the electronic and magnetic properties of these materials, including both their bulk and surface properties, which could have important technological implications. Overall, this study contributes to a broader understanding of the electronic structure and bonding of boride materials.",218
"Vibroacoustics of the piano soundboard: Reduced models, mobility synthesis, and acoustical radiation regime",0,"In string musical instruments, the sound is radiated by the soundboard, subject to the strings excitation. This vibration of this rather complex structure is described here with models which need only a small number of parameters. Predictions of the models are compared with results of experiments that have been presented in Ege et al. [Vibroacoustics of the piano soundboard: (Non)linearity and modal properties in the low- and mid- frequency ranges, Journal of Sound and Vibration 332 (5) (2013) 1288-1305]. The apparent modal density of the soundboard of an upright piano in playing condition, as seen from various points of the structure, exhibits two well-separated regimes, below and above a frequency flim that is determined by the wood characteristics and by the distance between ribs. Above flim, most modes appear to be localised, presumably due to the irregularity of the spacing and height of the ribs. The low-frequency regime is predicted by a model which consists of coupled sub-structures: the two ribbed areas split by the main bridge and, in most cases, one or two so-called cut-off corners. In order to assess the dynamical properties of each of the subplates (considered here as homogeneous plates), we propose a derivation of the (low-frequency) modal density of an orthotropic homogeneous plate which accounts for the boundary conditions on an arbitrary geometry. Above flim, the soundboard, as seen from a given excitation point, is modelled as a set of three structural wave-guides, namely the three inter-rib spacings surrounding the excitation point. Based on these low- and high-frequency models, computations of the point-mobility and of the apparent modal densities seen at several excitation points match published measurements.

The dispersion curve of the wave-guide model displays an acoustical radiation scheme which differs significantly from that of a thin homogeneous plate. It appears that piano dimensioning is such that the subsonic regime of acoustical radiation extends over a much wider frequency range than it would be for a homogeneous plate with the same low-frequency vibration. One problem in piano manufacturing is examined in relationship with the possible radiation schemes induced by the models.",360
"Vibroacoustics of the piano soundboard: Reduced models, mobility synthesis, and acoustical radiation regime",1,"The soundboard of a piano plays a vital role in the production of its distinctive sound. However, due to its complex nature, analyzing the vibroacoustics of the soundboard can be a daunting task. This research paper presents reduced models of the piano soundboard that aid in the analysis of its vibroacoustics.

The reduced models are created using the Craig-Bampton method, which enables the reduction of finite element models. The models successfully capture the frequency response of the soundboard and are able to predict its behavior in response to different boundary conditions.

To understand the mobility synthesis of the soundboard, a novel point mobility measurement method is proposed. The proposed method utilizes laser Doppler vibrometry to measure the point mobility of the soundboard. The measured point mobility data is used to synthesize the mobility of the entire soundboard. By employing this technique, it is possible to obtain a better understanding of the sound radiation behavior of the soundboard.

The acoustical radiation regime of the piano soundboard is analyzed using numerical simulations. The simulations are performed using the boundary element method, and they successfully predict the acoustical radiation behavior of the soundboard. The analysis demonstrates the importance of the boundary conditions on the radiated sound field.

In addition, the relationship between the soundboard and the piano strings is analyzed. The results show that the coupling between the soundboard and the strings plays a significant role in determining the overall sound quality of the piano.

Overall, this research paper presents a comprehensive study of the vibroacoustics of the piano soundboard. The reduced models, point mobility measurement method, numerical simulations, and analysis of the soundboard-string coupling all contribute to a better understanding of the sound production mechanism of the piano.",288
Age-Minimal Transmission for Energy Harvesting Sensors with Finite Batteries: Online Policies,0,"An energy-harvesting sensor node that is sending status updates to a destination is considered. The sensor is equipped with a battery of finite size to save its incoming energy, and consumes one unit of energy per status update transmission, which is delivered to the destination instantly over an error-free channel. The setting is online in which the harvested energy is revealed to the sensor causally over time, and the goal is to design status update transmission policy such that the long term average age of information (AoI) is minimized. AoI is defined as the time elapsed since the latest update has reached at the destination. Two energy arrival models are considered: a random battery recharge (RBR) model, and an incremental battery recharge (IBR) model. In both models, energy arrives according to a Poisson process with unit rate, with values that completely fill up the battery in the RBR model, and with values that fill up the battery incrementally, unit-by-unit, in the IBR model. The key approach to characterizing the optimal status update policy for both models is showing the optimality of renewal policies, in which the inter-update times follow a specific renewal process that depends on the energy arrival model and the battery size. It is then shown that the optimal renewal policy has an energy-dependent threshold structure, in which the sensor sends a status update only if the AoI grows above a certain threshold that depends on the energy available. For both the RBR and the IBR models, the optimal energy-dependent thresholds are characterized explicitly, i.e., in closed-form, in terms of the optimal long term average AoI. It is also shown that the optimal thresholds are monotonically decreasing in the energy available in the battery, and that the smallest threshold, which comes in effect when the battery is full, is equal to the optimal long term average AoI.",318
Age-Minimal Transmission for Energy Harvesting Sensors with Finite Batteries: Online Policies,1,"This paper focuses on the problem of age-minimal transmission for energy harvesting sensors with finite batteries. In order to conserve energy and prolong the lifetime of the sensor, the focus is on developing online policies that can make intelligent decisions on when and how to transmit information. We introduce a novel online policy, called the ""age-threshold policy"", which takes a proactive approach by dynamically adjusting the transmission threshold to minimize the average age of information at the receiver. 

To do this, we first model the energy harvesting sensor system to identify the key factors that affect information transmission. We then prove theoretical bounds on the age of information under different policies, including the age-threshold policy. We develop an efficient algorithm to implement the policy and show that it outperforms existing policies in terms of minimizing the average age of information at the receiver. 

Additionally, we consider the impact of battery capacity and harvesting rate on the system performance. We show that the age-threshold policy is particularly effective when the battery capacity is small, and that the harvesting rate has a significant impact on the performance of the policy. We conclude by discussing practical considerations and future directions for research in this area.

Overall, this paper is a significant contribution to the field of energy harvesting sensors and online policy design. By developing a new age-threshold policy and providing theoretical bounds on its performance, we provide a foundation for further research on age-minimal transmission in the context of energy harvesting sensors. The results of this paper can be used to improve the performance and lifetime of energy harvesting sensor systems, enabling more efficient and effective information transmission in a variety of applications.",287
Convergence bounds for empirical nonlinear least-squares,0,"We consider best approximation problems in a nonlinear subset $\mathcal{M}$ of a Banach space of functions $(\mathcal{V},\|\bullet\|)$. The norm is assumed to be a generalization of the $L^2$-norm for which only a weighted Monte Carlo estimate $\|\bullet\|_n$ can be computed. The objective is to obtain an approximation $v\in\mathcal{M}$ of an unknown function $u \in \mathcal{V}$ by minimizing the empirical norm $\|u-v\|_n$. We consider this problem for general nonlinear subsets and establish error bounds for the empirical best approximation error. Our results are based on a restricted isometry property (RIP) which holds in probability and is independent of the nonlinear least squares setting. Several model classes are examined where analytical statements can be made about the RIP and the results are compared to existing sample complexity bounds from the literature. We find that for well-studied model classes our general bound is weaker but exhibits many of the same properties as these specialized bounds. Notably, we demonstrate the advantage of an optimal sampling density (as known for linear spaces) for sets of functions with sparse representations.",187
Convergence bounds for empirical nonlinear least-squares,1,"This paper presents new theoretical results regarding convergence bounds for empirical nonlinear least-squares (NLS) methods. The study of empirical NLS is crucial in a wide range of applications, including machine learning, signal processing, and data analysis. Our work addresses some previously unresolved issues regarding convergence that arise when using NLS methods, such as the dependence on initialization and the sensitivity to noise in the data. Overall, our main contribution is to establish conditions under which empirical NLS achieves the optimal rate of convergence. We use a combination of classical techniques, such as the Cramér-Rao bound, as well as new tools based on recent advances in optimization theory, to derive our results. We also discuss how our results can be applied in practical situations, such as model fitting and parameter estimation. Our work will be useful to researchers in a diverse range of fields who use NLS methods for data analysis.",152
Concurrent Constraint Conditional-Branching Timed Interactive Scores,0,"Multimedia scenarios have multimedia content and interactive events associated with computer programs. Interactive Scores (IS) is a formalism to represent such scenarios by temporal objects, temporal relations (TRs) and interactive events. IS describe TRs, but IS cannot represent TRs together with conditional branching. We propose a model for conditional branching timed IS in the Non-deterministic Timed Concurrent Constraint (ntcc) calculus. We ran a prototype of our model in Ntccrt (a real-time capable interpreter for ntcc) and the response time was acceptable for real-time interaction. An advantage of ntcc over Max/MSP or Petri Nets is that conditions and global constraints are represented declaratively.",106
Concurrent Constraint Conditional-Branching Timed Interactive Scores,1,"The paper proposes a new formalism called Concurrent Constraint Conditional-Branching Timed Interactive Scores (C3BTIS) for specifying interactive multimedia works. C3BTIS models the timing and interaction patterns of multimedia works in a way that is intuitively appealing, while remaining mathematically well-defined and computationally tractable. It allows for the creation of complex multimedia works in a modular fashion, while also supporting runtime adaptation and collaboration between works. The paper presents the syntax and semantics of C3BTIS, and shows how it can be used to specify several multimedia works, verifying their correctness and studying their behavior under different execution scenarios.",99
Covariant Holographic Entanglement Negativity for Adjacent Subsystems in $\mathrm{AdS_{3}/CFT_2}$,0,"We propose a covariant holographic entanglement negativity constructionfor time-dependent mixed states of adjacent intervals in $(1+1)$-dimensional conformal field theories dual to non-static bulk $\mathrm{AdS_3}$ configurations. Our construction applied to $(1+1)$-dimensional conformal field theories with a conserved charge dual to non-extremal and extremal rotating BTZ black holes exactly reproduces the corresponding replica technique results, in the large central charge limit. We also utilize our conjecture to obtain the time-dependent holographic entanglement negativity for the mixed state in question for the $(1+1)$- dimensional CFT dual to a bulk Vaidya-$\mathrm{AdS_3}$ configuration.",100
Covariant Holographic Entanglement Negativity for Adjacent Subsystems in $\mathrm{AdS_{3}/CFT_2}$,1,"In this paper, we develop a framework for computing holographic entanglement negativity in adjacent subsystems of the $\mathrm{AdS_{3}/CFT_2}$ correspondence. We introduce covariant holographic entanglement negativity as a new measure of quantum entanglement that satisfies a number of desirable properties. We apply our formalism to several examples, including a conformal field theory (CFT) on the plane and the BTZ black hole. In particular, we show that the covariant holographic entanglement negativity for a pair of intervals in the CFT scales with the central charge as expected, and that it reproduces the Ryu-Takayanagi formula for the BTZ black hole.",101
Search for top squark pair production in a final state with two tau leptons in proton-proton collisions at $\sqrt{s} =$ 13 TeV,0,"A search for pair production of the supersymmetric partner of the top quark, the top squark, in proton-proton collision events at $\sqrt{s} =$ 13 TeV is presented in a final state containing hadronically decaying tau leptons and large missing transverse momentum. This final state is highly sensitive to high-$\tan{\beta}$ or higgsino-like scenarios in which decays of electroweak gauginos to tau leptons are dominant. The search uses a data set corresponding to an integrated luminosity of 77.2 fb$^{-1}$, which was recorded with the CMS detector during 2016 and 2017. No significant excess is observed with respect to the background prediction. Exclusion limits at 95% confidence level are presented in the top squark and lightest neutralino mass plane within the framework of simplified models, in which top squark masses up to 1100 GeV are excluded for a nearly massless neutralino.",144
Search for top squark pair production in a final state with two tau leptons in proton-proton collisions at $\sqrt{s} =$ 13 TeV,1,"This paper reports on the search for the pair production of top squarks, the supersymmetric partners of the top quark, in proton-proton collisions at a center-of-mass energy of 13 TeV. The final state under investigation is characterized by the presence of two tau leptons, which are identified through their decay modes. The analysis uses data collected with the CMS detector at the CERN LHC. The main sources of background are estimated from data control regions, while the signal acceptance and efficiency are determined from simulations based on the SUSY model. No significant excess is observed over the expected background, and exclusion limits are set on the top squark mass. This search contributes to our understanding of supersymmetry and the nature of dark matter.",126
Displacement correlations in disordered athermal networks,0,"We derive exact results for correlations in the displacement fields $\{ \delta \vec{r} \} \equiv \{ \delta r_{\mu = x,y} \}$ in near-crystalline athermal systems in two dimensions. We analyze the displacement correlations produced by different types of microscopic disorder, and show that disorder at the microscopic scale gives rise to long-range correlations with a dependence on the system size $L$ given by $\langle \delta r_{\mu} \delta r_{\nu} \rangle \sim c_{\mu \nu}(r/L,\theta)$. In addition, we show that polydispersity in the constituent particle sizes and random bond disorder give rise to a logarithmic system size scaling, with $c_{\mu \nu}(\rho,\theta) \sim \text{const}_{\mu\nu} - \text{a}_{\mu\nu}(\theta)\log \rho + \text{b}_{\mu\nu}(\theta) \rho^{2} $ for $\rho~(=r/L) \to 0$. This scaling is different for the case of displacement correlations produced by random external forces at each vertex of the network, given by $c^{f}_{\mu \nu}(\rho,\theta) \sim \text{const}^{f}_{\mu \nu} -( \text{a}^{f}_{\mu \nu}(\theta) + \text{b}^{f}_{\mu \nu}(\theta) \log \rho ) \rho^2 $. Additionally, we find that correlations produced by polydispersity and the correlations produced by disorder in bond stiffness differ in their symmetry properties. Finally, we also predict the displacement correlations for a model of polydispersed soft disks subject to external pinning forces, that involve two different types of microscopic disorder. We verify our theoretical predictions using numerical simulations of polydispersed soft disks with random spring contacts in two dimensions.",258
Displacement correlations in disordered athermal networks,1,"The study investigates the displacement correlations in disordered athermal networks. Athermal networks, that is, systems without energy input, have been gaining attention as models to study jamming and rigidity transitions. Randomly rewired networks, such as the ones studied in this work, serve as diagnostic tools to understand such transitions. The authors introduce the concept of a ""displacement correlation matrix"" as a means to represent the deformation patterns of a disordered network with quenched disorder. Through numerical simulations, they quantify the range and magnitude of the displacements that are spatially correlated, and they analyze the associated eigenvectors and eigenvalues. The results indicate that the displacement correlations are mediated by geometric frustration effects, which are a hallmark of disordered systems. The authors further explore the implications of the spatial correlations on the elastic response of the network, and found that they contribute to reducing the network's effective rigidity. The findings suggest new perspectives for analyzing the response of disordered mechanical systems and could have implications for the design of materials with controlled mechanical properties. The analysis of displacement correlations provides new insights into the fascinating physics of disordered athermal networks and paves the way for future studies.",196
A 2MASS All-Sky View of the Sagittarius Dwarf Galaxy: I. Morphology of the Sagittarius Core and Tidal Arms,0,"We present the first all-sky view of the Sagittarius (Sgr) dwarf galaxy mapped by M giant star tracers detected in the complete Two Micron All-Sky Survey (2MASS). The main body is fit with a King profile of 30 deg limiting radius, but with a break in the density profile from stars in tidal tails. We argue that much of the observed structure beyond the 224' core radius may be unbound as the satellite undergoes catastrophic disruption. A striking, >150 deg trailing tidal tail extends from the Sgr center and arcs across the South Galactic Hemisphere. A prominent leading debris arm extends from the Sgr center northward of the Galactic plane to an ~40 kpc apoGalacticon, loops towards the North Galactic Cap (NGC) and descends back towards the Galactic plane, foreshortened and covering the NGC. The Sgr tails lie along a well-defined orbital plane that shows little precession, which supports the notion of a nearly spherical Galactic potential. The Sun lies near the path of leading Sgr debris; thus, former Sgr stars may be near or in the solar neighborhood. The number of M giants in the Sgr tails is >15% that within the King limiting radius of the Sgr center. That several gigayear old M giants are so widespread along the Sgr tidal arms not only places limits on the dynamical age of these arms but poses a timing problem that bears on the recent binding energy of the Sgr core and that is naturally explained by recent and catastrophic mass loss.

Sgr appears to contribute >75% of the high latitude, halo M giants; no evidence for M giant tidal debris from the Magellanic Clouds is found. Generally good correspondence is found between the M giant, all-sky map of the Sgr system and all previously published detections of potential Sgr debris with the exception of Sgr carbon stars -- which must be subluminous to resolve the discrepancy.",320
A 2MASS All-Sky View of the Sagittarius Dwarf Galaxy: I. Morphology of the Sagittarius Core and Tidal Arms,1,"The Sagittarius Dwarf Galaxy is located in the important dwarf galaxy population of the Milky Way halo. It is a well-known example of a dwarf galaxy that is being tidally disrupted by the Milky Way. To improve our understanding of the morphology of the Sagittarius core and tidal arms, we have conducted a comprehensive analysis of 2MASS all-sky data. 

We used color-magnitude diagram analysis to determine the distance to individual stars in the Sagittarius system and overlayed the results on top of the core and tidal structures seen in the 2MASS data. Our analysis reveals a centrally concentrated Sagittarius Core that is partially overlaid by an extended, low surface brightness Sagittarius Stream. In addition, we find that the Sagittarius Stream does not trace a symmetrical structure around the core. Instead, it exhibits strong evidence for the presence of a secondary branch in the northwest. This branch is clearly distinct from the main stream, and we consider its discovery especially significant given the ongoing debate about the Sagittarius Stream's three-dimensional structure.

We determined the range of magnitudes for Sagittarius' tip of the red giant branch and the vertical distance from the Galactic plane. We searched for and identify the most likely dwarf galaxy or globular cluster candidates embedded in the Sagittarius Stream as signposts that provide clues about the environment in which Sagittarius is being disrupted. We also discuss the implications of this analysis for the interaction between the Milky Way's halo and the Galactic Disk. Overall, the results of this study provide important new information about Sagittarius' core and tidal arms and offer a fascinating glimpse of the ongoing process of their disruption.",279
A search on the Nikiforov-Uvarov formalism,0,"An alternative treatment is proposed for the calculations carried out within the frame of Nikiforov-Uvarov method, which removes a drawback in the original theory and by pass some difficulties in solving the Schrodinger equation. The present procedure is illustrated with the example of orthogonal polynomials.

The relativistic extension of the formalism is discussed.",54
A search on the Nikiforov-Uvarov formalism,1,The Nikiforov-Uvarov (NU) method has been extensively studied for solving Schrödinger's equation under various conditions. This search presents a comprehensive review of the NU formalism and its applications in mathematical physics. Our analysis provides a deeper understanding of the NU method and its implementation in solving problems in different fields of physics.,54
Testing the Consistency of Dust Laws in SN Ia Host Galaxies: A BayeSN Examination of Foundation DR1,0,"We apply BayeSN, our new hierarchical Bayesian model for the SEDs of Type Ia supernovae (SNe Ia), to analyse the $griz$ light curves of 157 nearby SNe Ia ($0.015<z<0.08$) from the public Foundation DR1 dataset. We train a new version of BayeSN, continuous from 0.35--0.95 $\mu$m, which we use to model the properties of SNe Ia in the rest-frame $z$-band, study the properties of dust in their host galaxies, and construct a Hubble diagram of SN Ia distances determined from full $griz$ light curves. Our $griz$ Hubble diagram has a low total RMS of 0.13 mag using BayeSN, compared to 0.16 mag using SALT2.

Additionally, we test the consistency of the dust law $R_V$ between low- and high-mass host galaxies by using our model to fit the full time- and wavelength-dependent SEDs of SNe Ia up to moderate reddening (peak apparent $B-V \lesssim 0.3$). Splitting the population at the median host mass, we find $R_V=2.84\pm0.31$ in low-mass hosts, and $R_V=2.58\pm0.23$ in high-mass hosts, both consistent with the global value of $R_V=2.61\pm0.21$ that we estimate for the full sample. For all choices of mass split we consider, $R_V$ is consistent across the step within $\lesssim1.2\sigma$. Modelling population distributions of dust laws in low- and high-mass hosts, we find that both subsamples are highly consistent with the full sample's population mean $\mu(R_V) = 2.70\pm0.25$ with a 95% upper bound on the population $\sigma(R_V) < 0.61$. The $R_V$ population means are consistent within $\lesssim1.2\sigma$. We find that simultaneous fitting of host-mass-dependent dust properties within our hierarchical model does not account for the conventional mass step.",304
Testing the Consistency of Dust Laws in SN Ia Host Galaxies: A BayeSN Examination of Foundation DR1,1,"This research paper presents a study on the consistency of dust laws in SN Ia host galaxies. Using the BayeSN framework and Foundation DR1 data, we examine the effects of dust on SN Ia observations. We begin by outlining the motivations for this research, which include the desire to better understand the astrophysical processes underlying SN Ia and the possible role of dust in affecting these observations. We then describe the methodology used in our study, which incorporates Bayesian analysis techniques to more accurately model the effects of dust. 

Our analysis reveals that the standard dust laws commonly used in SN Ia cosmology may not be consistent across different host galaxies. We find that the BayeSN framework can provide a more nuanced understanding of the effects of dust on SN Ia observations, allowing us to better quantify uncertainties associated with dust and other variable parameters. Our results also indicate that the Foundation DR1 data set is well-suited for this type of analysis and can yield new insights into the causes of observed SN Ia phenomena. 

The implications of these findings are significant for our understanding of SN Ia, which have played a critical role in our current understanding of the universe's expansion. By demonstrating the importance of considering variations in dust laws across different host galaxies, this research highlights the need for more robust models of SN Ia and the underlying physics at play. Overall, our study represents an important step forward in better understanding one of the key astronomical phenomena of our time.",256
Learning Sparse Representations in Reinforcement Learning with Sparse Coding,0,"A variety of representation learning approaches have been investigated for reinforcement learning; much less attention, however, has been given to investigating the utility of sparse coding. Outside of reinforcement learning, sparse coding representations have been widely used, with non-convex objectives that result in discriminative representations. In this work, we develop a supervised sparse coding objective for policy evaluation. Despite the non-convexity of this objective, we prove that all local minima are global minima, making the approach amenable to simple optimization strategies. We empirically show that it is key to use a supervised objective, rather than the more straightforward unsupervised sparse coding approach. We compare the learned representations to a canonical fixed sparse representation, called tile-coding, demonstrating that the sparse coding representation outperforms a wide variety of tilecoding representations.",131
Learning Sparse Representations in Reinforcement Learning with Sparse Coding,1,"Sparse coding has been successfully used in various machine learning applications including image and audio processing. In this paper, we introduce a novel approach for learning sparse representations in reinforcement learning. Our proposed method combines sparse coding with value-based RL algorithms to learn compact and efficient representations of complex state spaces. We demonstrate the effectiveness of our approach in several benchmark environments, showing significant improvements in learning speed and performance, particularly in high-dimensional and noisy state spaces. Furthermore, we analyze the learned representations and show that they extract meaningful features relevant to the task at hand. Our method provides a promising direction to address the curse of dimensionality in reinforcement learning and to enable more efficient and intelligent agents for real-world applications.",125
An Evans function approach to spectral stability of small-amplitude shock profiles,0,"We establish one-dimensional spectral stability of small amplitude viscous and relaxation shock profiles using Evans function techniques to perform a series of reductions and normal forms to reduce to the case of the scalar Burgers equation. In multidimensions, the canonical behavior is described, rather by a 2x2 viscous conservation law; this case will be treated in a companion paper by similar techniques.",63
An Evans function approach to spectral stability of small-amplitude shock profiles,1,"We present a novel Evans function method to analyze the spectral stability of small-amplitude shock profiles. By considering the linear stability problem, we show that the sign of the Evans function determines the stability of the shock profile. Our approach offers distinct computational advantages over traditional methods and allows the assessment of the stability of shock waves with high accuracy.",61
Collaborative search on the plane without communication,0,"We generalize the classical cow-path problem [7, 14, 38, 39] into a question that is relevant for collective foraging in animal groups. Specifically, we consider a setting in which k identical (probabilistic) agents, initially placed at some central location, collectively search for a treasure in the two-dimensional plane. The treasure is placed at a target location by an adversary and the goal is to find it as fast as possible as a function of both k and D, where D is the distance between the central location and the target.

This is biologically motivated by cooperative, central place foraging such as performed by ants around their nest. In this type of search there is a strong preference to locate nearby food sources before those that are further away.

Our focus is on trying to find what can be achieved if communication is limited or altogether absent. Indeed, to avoid overlaps agents must be highly dispersed making communication difficult. Furthermore, if agents do not commence the search in synchrony then even initial communication is problematic. This holds, in particular, with respect to the question of whether the agents can communicate and conclude their total number, k. It turns out that the knowledge of k by the individual agents is crucial for performance. Indeed, it is a straightforward observation that the time required for finding the treasure is $\Omega$(D + D 2 /k), and we show in this paper that this bound can be matched if the agents have knowledge of k up to some constant approximation. We present an almost tight bound for the competitive penalty that must be paid, in the running time, if agents have no information about k. Specifically, on the negative side, we show that in such a case, there is no algorithm whose competitiveness is O(log k). On the other hand, we show that for every constant $\epsilon \textgreater{} 0$, there exists a rather simple uniform search algorithm which is $O( \log^{1+\epsilon} k)$-competitive. In addition, we give a lower bound for the setting in which agents are given some estimation of k.

As a special case, this lower bound implies that for any constant $\epsilon \textgreater{} 0$, if each agent is given a (one-sided) $k^\epsilon$-approximation to k, then the competitiveness is $\Omega$(log k).

Informally, our results imply that the agents can potentially perform well without any knowledge of their total number k, however, to further improve, they must be given a relatively good approximation of k. Finally, we propose a uniform algorithm that is both efficient and extremely simple suggesting its relevance for actual biological scenarios.",440
Collaborative search on the plane without communication,1,"Collaborative search on the plane without communication presents a novel approach to solving the task of finding a target on a flat surface, without the use of communication among the searchers. This is a challenging, yet realistic problem that has not been fully explored in the literature to date. The proposed solution consists of a distributed algorithm that leverages a combination of individual heuristic rules and probabilistic reasoning to guide the searchers towards the target. 

Each searcher is equipped with a sensor that can detect the target with some level of uncertainty and can communicate only with very close neighbors within a certain range. No global information about the sensor measurements or search process is shared among the searchers, which makes the task quite complex. The algorithm is designed to enable the searchers to coordinate their movements and avoid redundant exploration by exploiting the limited communication capabilities. 

The algorithm incorporates a distributed consensus mechanism, where each searcher maintains its belief about the target's location based on its sensor readings and the interactions with its neighbors. This belief is updated by combining the information from its own observations with that of its neighbors using a Bayesian inference framework. The final consensus is reached by using a likelihood function that takes into account the uncertainty in the observations and the reliability of the neighbors. 

The proposed approach is evaluated using a set of simulations and compared to a centralized algorithm that has access to all the sensor measurements. The results show that the proposed algorithm is able to achieve comparable performance to the centralized algorithm, while using only local information and limited communication. Moreover, the proposed algorithm is shown to be scalable and robust to changes in the search environment, such as the disappearance and sudden reappearance of the target.

The proposed algorithm has several potential applications in the field of swarm robotics and autonomous systems. For example, it can be used in search and rescue operations, where a team of robots needs to search for a missing person in a hazardous environment. The algorithm can also be applied in precision agriculture, where a team of drones needs to identify and localize diseased crops in a field without the need for expensive communication infrastructure.

In conclusion, the proposed collaborative search algorithm presents a practical solution to the problem of finding a target on a plane without communication. The algorithm leverages a combination of distributed consensus, probabilistic reasoning, and individual heuristic rules to enable the searchers to coordinate their movements and avoid redundant exploration. The algorithm is shown to be robust and scalable, and has potential applications in many real-world scenarios.",440
3-dimensional $\Lambda$-BMS Symmetry and its Deformations,0,"In this paper we study quantum group deformations of the infinite dimensional symmetry algebra of asymptotically AdS spacetimes in three dimensions. Building on previous results in the finite dimensional subalgebras we classify all possible Lie bialgebra structures and for selected examples, we explicitly construct the related Hopf algebras. Using cohomological arguments we show that this construction can always be performed by a so-called twist deformation. The resulting structures can be compared to the well-known $\kappa$-Poincar\'e Hopf algebras constructed on the finite dimensional Poincar\'e or (anti) de Sitter algebra. The dual $\kappa$ Minkowski spacetime is supposed to describe a specific non-commutative geometry. Importantly, we find that some incarnations of the $\kappa$-Poincar\'e can not be extended consistently to the infinite dimensional algebras. Furthermore, certain deformations can have potential physical applications if subalgebras are considered. Since the conserved charges associated with asymptotic symmetries in 3-dimensional form a centrally extended algebra we also discuss briefly deformations of such algebras. The presence of the full symmetry algebra might have observable consequences that could be used to rule out these deformations. }",184
3-dimensional $\Lambda$-BMS Symmetry and its Deformations,1,"In this paper, we investigate the three-dimensional $\Lambda$-BMS symmetry and its deformations. By utilizing the techniques of loop quantum gravity and spin foam models, we derive the algebra of $\Lambda$-BMS transformations and explore their actions on the asymptotic boundary of spacetime. We discuss how the $\Lambda$-BMS symmetry differs from the usual BMS symmetry and highlight its physical significance in the cosmic microwave background radiation. Furthermore, we introduce new deformations of $\Lambda$-BMS transformations, generalizing previous work on deformed symmetries in four-dimensional spacetimes. These deformations are shown to have various interesting features, such as modified transformation laws and noncommutativity of symmetries. Finally, we discuss the implications of our results for the description of gravitational waves and the effective quantum field theories on curved spacetimes. Our findings provide novel insights into the geometry and symmetries of three-dimensional spacetime, with potential applications to both theoretical and observational aspects of gravity.",153
Variation of the gas and radiation content in the sub-Keplerian accretion disk around black holes and its impact to the solutions,0,"We investigate the variation of the gas and the radiation pressure in accretion disks during the infall of matter to the black hole and its effect to the flow. While the flow far away from the black hole might be non-relativistic, in the vicinity of the black hole it is expected to be relativistic behaving more like radiation. Therefore, the ratio of gas pressure to total pressure (beta) and the underlying polytropic index (gamma) should not be constant throughout the flow. We obtain that accretion flows exhibit significant variation of beta and then gamma, which affects solutions described in the standard literature based on constant beta. Certain solutions for a particular set of initial parameters with a constant beta do not exist when the variation of beta is incorporated appropriately. We model the viscous sub-Keplerian accretion disk with a nonzero component of advection and pressure gradient around black holes by preserving the conservations of mass, momentum, energy, supplemented by the evolution of beta. By solving the set of five coupled differential equations, we obtain the thermo-hydrodynamical properties of the flow. We show that during infall, beta of the flow could vary upto ~300%, while gamma upto ~20%. This might have a significant impact to the disk solutions in explaining observed data, e.g. super-luminal jets from disks, luminosity, and then extracting fundamental properties from them. Hence any conclusion based on constant gamma and beta should be taken with caution and corrected.",245
Variation of the gas and radiation content in the sub-Keplerian accretion disk around black holes and its impact to the solutions,1,"The study of the sub-Keplerian accretion disk around black holes has been a topic of great interest in astrophysics due to its implications for understanding the dynamics of black holes. This research aims to analyze the variations in the gas and radiation content within the disk to determine their impact on the solutions. Using numerical simulations, we investigated the hydrodynamic structure of the disk and its evolution over time. Our results show that the gas and radiation content vary significantly with distance from the black hole, with the inner regions being dominated by gas and the outer regions being dominated by radiation. Additionally, we found that the gas and radiation content exhibits oscillations over time due to the interaction between the disk and the black hole. These variations have a significant impact on the overall structure and properties of the disk, including its temperature distribution and the transport of energy and momentum. Our findings provide valuable insight into the physics of sub-Keplerian accretion disks and their role in the dynamics of black holes. Furthermore, our research contributes to a deeper understanding of the mechanisms that govern the behavior of black holes and could have important implications for future studies of astrophysical phenomena.",204
Stringent Constraint on Galactic Positron Production,0,"The intense 0.511 MeV gamma-ray line emission from the Galactic Center observed by INTEGRAL requires a large annihilation rate of nonrelativistic positrons. If these positrons are injected at even mildly relativistic energies, higher-energy gamma rays will also be produced. We calculate the gamma-ray spectrum due to inflight annihilation and compare to the observed diffuse Galactic gamma-ray data. Even in a simplified but conservative treatment, we find that the positron injection energies must be $\lesssim 3$ MeV, which strongly constrains models for Galactic positron production.",89
Stringent Constraint on Galactic Positron Production,1,"The paper provides a stringent constraint on the production of Galactic positron. The findings suggest that the Galactic positron source term is likely lower than the standard value inferred from the current models. Our result comes from a careful statistical analysis of the cosmic-ray electrons and positrons measured with the Alpha Magnetic Spectrometer experiment on the International Space Station, indicating an electron-to-positron ratio that is unexpectedly high, even with respect to the well-known uncertainties of the propagation models.",82
Spitzer-MIPS survey of the young stellar content in the Vela Molecular Cloud-D,0,"A new, unbiased Spitzer-MIPS imaging survey (~1.8 square degs) of the young stellar content of the Vela Molecular Cloud-D is presented. The survey is complete down to 5mJy and 250mJy at 24micron (mu) and 70mu, respectively. 849 sources are detected at 24mu and 52 of them also have a 70mu counterpart. The VMR-D region is one that we have already partially mapped in dust and gas millimeter emission, and we discuss the correlation between the Spitzer compact sources and the mm contours. About half of the 24mu sources are located inside the region delimited by the 12CO(1-0) contours (corresponding to only one third of the full area mapped with MIPS) with a consequent density increase of about 100% of the 24mu sources [four times for 70mu ones] moving from outside to inside the CO contours. About 400 sources have a 2MASS counterpart. So we have constructed a Ks vs. Ks-[24] diagram and identified the protostellar population. We find an excess of Class I sources in VMR-D in comparison with other star forming regions. This result is reasonably biased by the sensitivity limits, or, alternatively, may reflect a very short lifetime (<=10^6yr) of the protostellar content in this cloud. The MIPS images have identified embedded cool objects in most of the previously identified starless cores; in addition, there are 6 very young, possibly Class 0 objects identified. Finally we report finding of the driving sources for a set of five out of six very compact protostellar jets previously discovered in near-infrared images.",261
Spitzer-MIPS survey of the young stellar content in the Vela Molecular Cloud-D,1,"The Vela Molecular Cloud-D has long been of interest to astronomers, owing to its young stellar content and potential for observing the early stages of star formation. In this paper, we report on a Spitzer Space Telescope survey of the Vela Molecular Cloud-D using the Multi-band Imaging Photometer for Spitzer (MIPS). The survey coverage spanned 6 square degrees, and images were taken at 24, 70, and 160 microns. From these observations, we identified 604 young stellar object (YSO) candidates, which we classified as Class I, II, and III based on their spectral energy distributions. We also examined the distribution of these YSO candidates through the cloud, and found a strong correlation with the densest regions of molecular gas. Additionally, we identified several protostellar clusters, which we believe mark regions of particularly active star formation. Using a hierarchical clustering algorithm, we were able to group these clusters into two distinct populations, which we classified as older and younger. We speculate that the older population has already reached the main sequence, while the younger population is still undergoing active star formation. Overall, our survey highlights the rich diversity of the young stellar content within the Vela Molecular Cloud-D, and underscores the importance of continuing observations in order to better understand the processes of star formation in this and other molecular clouds.",223
An independent determination of Fomalhaut b's orbit and the dynamical effects on the outer dust belt,0,"The nearby star Fomalhaut harbours a cold, moderately eccentric dust belt with a sharp inner edge near 133 au. A low-mass, common proper motion companion (Fom b), was discovered near the inner edge and was identified as a planet candidate that could account for the belt morphology. However, the most recent orbit determination based on four epochs of astrometry over eight years reveals a highly eccentric orbit that appears to cross the belt in the sky plane projection. We perform here a full orbital determination based on the available astrometric data to independently validate the orbit estimates previously presented. Adopting our values for the orbital elements and their associated uncertainties, we then study the dynamical interaction between the planet and the dust ring, to check whether the proposed disk sculpting scenario by Fom b is plausible. We used a dedicated MCMC code to derive the statistical distributions of the orbital elements of Fom b. Then we used symplectic N-body integration to investigate the dynamics of the dust belt, as perturbed by a single planet. Different attempts were made assuming different masses for Fom b. We also performed a semi-analytical study to explain our results. Our results are in good agreement with others regarding the orbit of Fom b. We find that the orbit is highly eccentric, is close to apsidally aligned with the belt, and has a moderate mutual inclination relative to the belt plane of. If coplanar, this orbit crosses the disk. Our dynamical study then reveals that the observed planet could sculpt a transient belt configuration with a similar eccentricity to what is observed, but it would not be simultaneously apsidally aligned with the planet. This transient configuration only occurs a short time after the planet is placed on such an orbit (assuming an initially circular disk), a time that is inversely proportional to the planet's mass, and that is in any case much less than the 440 Myr age of the star. We constrain how long the observed dust belt could have survived with Fom b on its current orbit, as a function of its possible mass. This analysis leads us to conclude that Fom b is likely to have low mass, that it is unlikely to be responsible for the sculpting of the belt, and that it supports the hypothesis of a more massive, less eccentric planet companion Fom c.",398
An independent determination of Fomalhaut b's orbit and the dynamical effects on the outer dust belt,1,"This study presents an independent determination of Fomalhaut b's orbit and investigates its dynamical effects on the outer dust belt. Fomalhaut b is a directly imaged exoplanet located in the Fomalhaut system, approximately 25 light-years away from Earth. Previous studies have suggested that Fomalhaut b has a highly eccentric orbit, contributing to the disruption of the outer dust belt. Our study aims to provide a more accurate determination of Fomalhaut b's orbit and a deeper understanding of its effect on the dust belt.

To achieve this, we analyzed archival Hubble Space Telescope images spanning over 7 years and used astrometric techniques to measure the position and motion of Fomalhaut b. We combined these measurements with previous astrometric data and employed a statistical approach to compute the orbital parameters and their uncertainties. Our analysis indicates that Fomalhaut b's orbit is consistent with a highly eccentric ellipse, with a period of about 1600 years and a periastron distance of about 7.4 AU. The large eccentricity of the orbit suggests that Fomalhaut b is perturbed by a massive and distant object, which could be a yet undetected planet or a remnant of the protoplanetary disk.

We then employed numerical simulations to investigate the dynamical effects of Fomalhaut b on the outer dust belt. Our simulations include the gravitational perturbations of Fomalhaut b, the asymmetry of the dust belt, and the radiation pressure of the central star. We found that Fomalhaut b induces a series of azimuthal dust structures in the outer belt, which are consistent with the observed morphology. These structures are caused by the gravitational resonances between Fomalhaut b and the dust particles, and their locations and shapes depend on the orbital parameters of Fomalhaut b. Our simulations also suggest that Fomalhaut b's eccentricity is important for shaping the dust structures, as it determines the strength and duration of the gravitational perturbations.

Overall, our study provides a more accurate determination of Fomalhaut b's orbit and sheds new light on its dynamical effects on the outer dust belt. Our results have implications for the formation and evolution of exoplanetary systems, and highlight the importance of studying the orbital dynamics of directly imaged planets.",367
Machine Learning-Based Estimation and Goodness-of-Fit for Large-Scale Confirmatory Item Factor Analysis,0,"We investigate novel parameter estimation and goodness-of-fit (GOF) assessment methods for large-scale confirmatory item factor analysis (IFA) with many respondents, items, and latent factors. For parameter estimation, we extend Urban and Bauer's (2021) deep learning algorithm for exploratory IFA to the confirmatory setting by showing how to handle user-defined constraints on loadings and factor correlations. For GOF assessment, we explore new simulation-based tests and indices. In particular, we consider extensions of the classifier two-sample test (C2ST), a method that tests whether a machine learning classifier can distinguish between observed data and synthetic data sampled from a fitted IFA model. The C2ST provides a flexible framework that integrates overall model fit, piece-wise fit, and person fit. Proposed extensions include a C2ST-based test of approximate fit in which the user specifies what percentage of observed data can be distinguished from synthetic data as well as a C2ST-based relative fit index that is similar in spirit to the relative fit indices used in structural equation modeling. Via simulation studies, we first show that the confirmatory extension of Urban and Bauer's (2021) algorithm produces more accurate parameter estimates as the sample size increases and obtains comparable estimates to a state-of-the-art confirmatory IFA estimation procedure in less time. We next show that the C2ST-based test of approximate fit controls the empirical type I error rate and detects when the number of latent factors is misspecified. Finally, we empirically investigate how the sampling distribution of the C2ST-based relative fit index depends on the sample size.",265
Machine Learning-Based Estimation and Goodness-of-Fit for Large-Scale Confirmatory Item Factor Analysis,1,"This paper introduces a novel approach to confirmatory item factor analysis (CFA) that relies on machine learning-based estimation and goodness-of-fit techniques. The proposed methodology addresses the demands of large-scale CFA, where traditional methods can become computationally infeasible. By leveraging the advantages of machine learning, we aim to provide a viable alternative that yields more accurate and efficient CFA solutions.

Specifically, our approach involves two main stages. In the first stage, we use state-of-the-art machine learning algorithms, such as stochastic gradient descent and Adam, to estimate the CFA model's parameters. This step's advantage is that it can handle the large-scale data sets commonly encountered in CFA, which can have hundreds or thousands of items. Moreover, by employing machine learning techniques, we can obtain more precise and accurate estimates than those provided by conventional methods.

In the second stage, we assess the goodness-of-fit between the estimated model and the observed data using the Bayesian Information Criterion (BIC), which is a widely used criterion that balances model complexity and goodness-of-fit. Compared to other techniques, our approach results in BIC values that more accurately reflect the underlying model's fit to the data.

We illustrate the potential of our methodology through a simulation study and a real data application. The results demonstrate that our approach outperforms existing techniques in terms of accuracy and computational efficiency. Overall, our approach offers a promising solution for large-scale CFA with practical applications in various domains such as psychology, education, and healthcare.",258
Adaptive Sparse Polynomial Chaos Expansions via Leja Interpolation,0,"This work suggests an interpolation-based stochastic collocation method for the non-intrusive and adaptive construction of sparse polynomial chaos expansions (PCEs). Unlike pseudo-spectral projection and regression-based stochastic collocation methods, the proposed approach results in PCEs featuring one polynomial term per collocation point. Moreover, the resulting PCEs are interpolating, i.e., they are exact on the interpolation nodes/collocation points. Once available, an interpolating PCE can be used as an inexpensive surrogate model, or be post-processed for the purposes of uncertainty quantification and sensitivity analysis. The main idea is conceptually simple and relies on the use of Leja sequence points as interpolation nodes. Using Newton-like, hierarchical basis polynomials defined upon Leja sequences, a sparse-grid interpolation can be derived, the basis polynomials of which are unique in terms of their multivariate degrees. A dimension-adaptive scheme can be employed for the construction of an anisotropic interpolation. Due to the degree uniqueness, a one-to-one transform to orthogonal polynomials of the exact same degrees is possible and shall result in an interpolating PCE.

However, since each Leja node defines a unique Newton basis polynomial, an implicit one-to-one map between Leja nodes and orthogonal basis polynomials exists as well. Therefore, the in-between steps of hierarchical interpolation and basis transform can be discarded altogether, and the interpolating PCE can be computed directly. For directly computed, adaptive, anisotropic interpolating PCEs, the dimension-adaptive algorithm is modified accordingly. A series of numerical experiments verify the suggested approach in both low and moderately high-dimensional settings, as well as for various input distributions.",265
Adaptive Sparse Polynomial Chaos Expansions via Leja Interpolation,1,"The current work presents a novel approach towards constructing adaptive sparse polynomial chaos expansions through the application of Leja interpolation. Using advanced mathematical techniques, we have developed a framework for constructing polynomials that efficiently select only the most informative degrees of freedom from the problem at hand. By doing so, our approach optimizes the accuracy-to-complexity trade-off of standard polynomial chaos methods. We demonstrate the efficacy of our approach by applying it to a range of test problems, including those which exhibit high levels of nonlinearity and dimensionality. Our results indicate that our approach can produce sparse expansions which match or outperform existing state-of-the-art methods, while requiring considerably fewer function evaluations to do so. We also explore the impact of various design considerations, such as sampling strategies and the choice of interpolation points, on the overall efficacy of our approach. Finally, we provide guidance on how to choose appropriate parameters to balance accuracy and computational efficiency. Our approach has practical applications across a wide range of complex engineering and scientific problems, and can be easily implemented using standard software tools.",185
Combinatorial Redundancy Detection,0,"The problem of detecting and removing redundant constraints is fundamental in optimization. We focus on the case of linear programs (LPs) in dictionary form, given by $n$ equality constraints in $n+d$ variables, where the variables are constrained to be nonnegative. A variable $x_r$ is called redundant, if after removing $x_r \geq 0$ the LP still has the same feasible region. The time needed to solve such an LP is denoted by $LP(n,d)$.

It is easy to see that solving $n+d$ LPs of the above size is sufficient to detect all redundancies. The currently fastest practical method is the one by Clarkson: it solves $n+d$ linear programs, but each of them has at most $s$ variables, where $s$ is the number of nonredundant constraints.

In the first part we show that knowing all of the finitely many dictionaries of the LP is sufficient for the purpose of redundancy detection. A dictionary is a matrix that can be thought of as an enriched encoding of a vertex in the LP. Moreover - and this is the combinatorial aspect - it is enough to know only the signs of the entries, the actual values do not matter. Concretely we show that for any variable $x_r$ one can find a dictionary, such that its sign pattern is either a redundancy or nonredundancy certificate for $x_r$.

In the second part we show that considering only the sign patterns of the dictionary, there is an output sensitive algorithm of running time $\mathcal{O}(d \cdot (n+d) \cdot s^{d-1} \cdot LP(s,d) + d \cdot s^{d} \cdot LP(n,d))$ to detect all redundancies. In the case where all constraints are in general position, the running time is $\mathcal{O}(s \cdot LP(n,d) + (n+d) \cdot LP(s,d))$, which is essentially the running time of the Clarkson method.

Our algorithm extends naturally to a more general setting of arrangements of oriented topological hyperplane arrangements.",327
Combinatorial Redundancy Detection,1,"Combinatorial redundancy detection is a crucial problem in computer science, particularly in the design and testing of digital systems. Redundancy is the presence of multiple copies or versions of the same data, component, or function within a system, and is often introduced intentionally as a means of improving reliability or performance. However, when redundancy is introduced inadvertently or without proper management, it can lead to subtle and difficult-to-detect errors that can compromise the integrity and functionality of a system. 

In this paper, we present a novel approach to combinatorial redundancy detection that leverages the power of mathematical combinatorics and graph theory. Our approach is based on the identification and analysis of redundant subgraphs in a system's dependency graph, which captures the relationships between its components and the interactions between them. We introduce a number of combinatorial algorithms and heuristics for identifying and analyzing such subgraphs, and demonstrate the effectiveness of our approach through experimental results on a range of benchmarks. 

We show that our approach can detect a wide range of redundant structures in digital systems, including replica components, cyclic dependencies, and functionally identical modules. Furthermore, we demonstrate that our approach can scale to large and complex systems, making it a practical solution for real-world applications. We also discuss the limitations of our approach and opportunities for future research. 

Overall, our work contributes to the field of digital system design and testing by providing a powerful and flexible approach to combinatorial redundancy detection. Our methods are based on sound mathematical principles and are validated through rigorous experimentation, suggesting that they are effective and practical tools for ensuring the reliability and performance of digital systems.",278
Ringed accretion disks: instabilities,0,"We analyze the possibility that several instability points may be formed, due to the Paczy\'nski mechanism of violation of mechanical equilibrium, in the orbiting matter around a supermassive Kerr black hole. We consider recently proposed model of ringed accretion disk, made up by several tori (rings) which can be corotating or counterrotating relative to the Kerr attractor due to the history of the accretion process. Each torus is governed by the general relativistic hydrodynamic Boyer condition of equilibrium configurations of rotating perfect fluids. We prove that the number of the instability points is generally limited and depends on the dimensionless spin of the rotating attractor.",106
Ringed accretion disks: instabilities,1,"The formation and dynamics of ringed accretion disks around astrophysical objects have been the subject of extensive research. Unstable behavior within these systems has been observed and analyzed. Non-axisymmetric perturbations, whether external or intrinsic to the disk, can lead to instabilities such as spiral arms, warping, and fragmentation. These instabilities can play a crucial role in the accretion process, affecting the transport of mass and angular momentum. Multiple mechanisms have been proposed to explain these phenomena, including thermal and hydrodynamic effects, magnetic fields, and self-gravity. Understanding the nature of these instabilities is crucial for modeling the behavior of accretion disks and better understanding the formation of astrophysical objects.",110
How orbital angular momentum affects beam shifts in optical reflection,0,"It is well known that reflection of a Gaussian light beam ($\text{TEM}_{00}$) by a planar dielectric interface leads to four beam shifts when compared to the geometrical-optics prediction. These are the spatial Goos-H\""{a}nchen (GH) shift, the angular GH shift, the spatial Imbert-Fedorov (IF) shift and the angular IF shift. We report here, theoretically and experimentally, that endowing the beam with Orbital Angular Momentum (OAM) leads to coupling of these four shifts; this is described by a $4 \times 4$ mixing matrix.",89
How orbital angular momentum affects beam shifts in optical reflection,1,"This paper investigates the influence of orbital angular momentum (OAM) on the beam shifts in optical reflection. By analyzing the reflection of vortex beams with OAM, we show that the shift effect depends on the OAM and that the shift due to OAM can be manipulated by controlling the polarization of the incident beam. Our theoretical and experimental results indicate that OAM plays a significant role in the lateral and angular shifts of reflected beams, offering a promising way to control light propagation in various applications such as optical trapping and sensing.",92
Improving Neural Network Verification through Spurious Region Guided Refinement,0,"We propose a spurious region guided refinement approach for robustness verification of deep neural networks. Our method starts with applying the DeepPoly abstract domain to analyze the network. If the robustness property cannot be verified, the result is inconclusive. Due to the over-approximation, the computed region in the abstraction may be spurious in the sense that it does not contain any true counterexample. Our goal is to identify such spurious regions and use them to guide the abstraction refinement. The core idea is to make use of the obtained constraints of the abstraction to infer new bounds for the neurons. This is achieved by linear programming techniques. With the new bounds, we iteratively apply DeepPoly, aiming to eliminate spurious regions. We have implemented our approach in a prototypical tool DeepSRGR. Experimental results show that a large amount of regions can be identified as spurious, and as a result, the precision of DeepPoly can be significantly improved. As a side contribution, we show that our approach can be applied to verify quantitative robustness properties.",174
Improving Neural Network Verification through Spurious Region Guided Refinement,1,"Deep neural networks are widely used in applications including image recognition, natural language processing, and autonomous driving. However, ensuring the reliability and robustness of these networks remains a challenge. To address this challenge, we propose a method for improving neural network verification through spurious region guided refinement. Our approach involves identifying regions in the input space where the network may produce incorrect predictions, known as spurious regions, and iteratively refining the network to improve its accuracy in these areas. We demonstrate the effectiveness of our method on various benchmarks and show that it outperforms state-of-the-art approaches in terms of verification accuracy. Furthermore, we analyze the learned spurious regions and show how they can offer insights into the behavior of the network. Our proposed method provides a promising step towards more reliable and verifiable neural networks, which are crucial for their deployment in safety-critical applications.",148
A Complete Characterization of Infinitely Repeated Two-Player Games having Computable Strategies with no Computable Best Response under Limit-of-Means Payoff,0,"It is well-known that for infinitely repeated games, there are computable strategies that have best responses, but no computable best responses. These results were originally proved for either specific games (e.g., Prisoner's dilemma), or for classes of games satisfying certain conditions not known to be both necessary and sufficient.

We derive a complete characterization in the form of simple necessary and sufficient conditions for the existence of a computable strategy without a computable best response under limit-of-means payoff. We further refine the characterization by requiring the strategy profiles to be Nash equilibria or subgame-perfect equilibria, and we show how the characterizations entail that it is efficiently decidable whether an infinitely repeated game has a computable strategy without a computable best response.",127
A Complete Characterization of Infinitely Repeated Two-Player Games having Computable Strategies with no Computable Best Response under Limit-of-Means Payoff,1,"In this paper, we provide a thorough analysis of infinitely repeated two-player games, where the strategies are computable but have no computable best response under a Limit-of-Means payoff. We establish conditions for the non-existence of computable best responses, and provide a complete characterization of such games in terms of their underlying structures. Our analysis reveals the crucial role of effective randomness in the computation of strategies. We prove that every opponent class of strategies, with non-empty effective support, corresponds to a unique class of repeated games, and show that certain classes of computable stationary strategies do not have a computable best response. Our results shed new light on the complexity of repeated games and have practical implications for the design of algorithms and decision-making processes in strategic interactions.",134
Dipole anisotropy in sky brightness and source count distribution in radio NVSS data,0,"We study the dipole anisotropy in number counts and flux density weighted number counts {or sky brightness} in the NRAO VLA Sky Survey (NVSS) data. The dipole anisotropy is expected due to our local motion with respect to the CMBR rest frame. We analyse data with an improved fit to the number density, n(S), as a function of the flux density S, which allows deviation from a pure power law behaviour. We also impose more stringent cuts to remove the contribution due to clustering dipole. In agreement with earlier results, we find that the amplitude of anisotropy is significantly larger in comparison to the prediction based on CMBR measurements. The extracted speed is found to be roughly 3 times the speed corresponding to CMBR. The significance of deviation is smaller, roughly 2 sigma, in comparison to earlier estimates. For the cut, S>30 mJy, the speed is found to be $1110\pm370$ Km/s using the source count analysis. The direction of the dipole anisotropy is found to be approximately in agreement with CMBR. We find that the results are relatively insensitive to the lower as well as upper limit imposed on the flux density. Our results suggest that the Universe is intrinsically anisotropic with the axis of anisotropy axis pointing roughly towards the CMBR dipole direction. Finally we present a method which may allow an independent extraction of the local speed and an intrinsic dipole anisotropy, provided a larger data set becomes available in future.",247
Dipole anisotropy in sky brightness and source count distribution in radio NVSS data,1,"This study examines the dipole anisotropy in the sky brightness and source count distribution using radio data from the NRAO VLA Sky Survey (NVSS). We utilize the cross-power spectrum approach to characterize this anisotropy, as well as to separate it from any potential systematic effects. Our analysis reveals a statistically significant dipole anisotropy in the sky brightness distribution, consistent with the expected dipole modulation due to the motion of our Local Group with respect to the microwave background. Such a detection allows for a direct measurement of our peculiar velocity, which is in good agreement with independent measurements. Additionally, we investigate the effect of this dipole on the distribution of radio sources in the NVSS catalog. We find evidence for dipole modulation in the source count distribution, albeit with a lower significance compared to the sky brightness signal. The direction of the most significant dipole signal is consistent with that of the sky brightness signal, further reinforcing the veracity of our detection. Our results indicate that a dipole anisotropy is indeed present in both the sky brightness and the source count distribution of the NVSS data, and its characterization can provide important clues to cosmological parameters and the large-scale structure of the universe.",205
Graphs in machine learning: an introduction,0,"Graphs are commonly used to characterise interactions between objects of interest. Because they are based on a straightforward formalism, they are used in many scientific fields from computer science to historical sciences. In this paper, we give an introduction to some methods relying on graphs for learning.

This includes both unsupervised and supervised methods. Unsupervised learning algorithms usually aim at visualising graphs in latent spaces and/or clustering the nodes. Both focus on extracting knowledge from graph topologies. While most existing techniques are only applicable to static graphs, where edges do not evolve through time, recent developments have shown that they could be extended to deal with evolving networks. In a supervised context, one generally aims at inferring labels or numerical values attached to nodes using both the graph and, when they are available, node characteristics. Balancing the two sources of information can be challenging, especially as they can disagree locally or globally. In both contexts, supervised and un-supervised, data can be relational (augmented with one or several global graphs) as described above, or graph valued. In this latter case, each object of interest is given as a full graph (possibly completed by other characteristics). In this context, natural tasks include graph clustering (as in producing clusters of graphs rather than clusters of nodes in a single graph), graph classification, etc. 1 Real networks One of the first practical studies on graphs can be dated back to the original work of Moreno [51] in the 30s. Since then, there has been a growing interest in graph analysis associated with strong developments in the modelling and the processing of these data. Graphs are now used in many scientific fields. In Biology [54, 2, 7], for instance, metabolic networks can describe pathways of biochemical reactions [41], while in social sciences networks are used to represent relation ties between actors [66, 56, 36, 34]. Other examples include powergrids [71] and the web [75]. Recently, networks have also been considered in other areas such as geography [22] and history [59, 39]. In machine learning, networks are seen as powerful tools to model problems in order to extract information from data and for prediction purposes. This is the object of this paper. For more complete surveys, we refer to [28, 62, 49, 45].

In this section, we introduce notations and highlight properties shared by most real networks. In Section 2, we then consider methods aiming at extracting information from a unique network. We will particularly focus on clustering methods where the goal is to find clusters of vertices. Finally, in Section 3, techniques that take a series of networks into account, where each network is",441
Graphs in machine learning: an introduction,1,"Graphs have emerged as a powerful tool in the field of machine learning due to their ability to capture and represent complex data relationships. In this paper, we introduce the fundamentals of graphs and their applications in machine learning.

We begin by discussing the basics of graph theory, including different types of graphs such as directed and undirected graphs, and their representation using adjacency matrices and lists. Next, we explore how graphs can be used to model various aspects of machine learning, such as clustering and classification.

One key application of graphs in machine learning is community detection, where nodes within a graph are grouped into clusters based on their structural similarities. We review different approaches to community detection, including modularity optimization and spectral clustering, and highlight their strengths and weaknesses. 

Another important application is graph-based semi-supervised learning, where partially labeled data is used to predict labels for unlabeled nodes within a graph. We explore different semi-supervised learning algorithms, such as label propagation and graph convolutional networks, and discuss their performance on real-world datasets.

We also discuss the use of graphs in deep learning, specifically graph neural networks (GNNs), which can be applied to various tasks such as node classification and link prediction. We provide an overview of different types of GNNs, including graph attention networks and graph convolutional networks, and compare their performance with traditional deep learning models.

Finally, we discuss some of the challenges and open research problems in the field of graph-based machine learning, such as scalability and interpretability. We conclude by summarizing the key points of the paper and highlighting the potential impact of graphs in future machine learning applications.

In conclusion, this paper provides a comprehensive introduction to graphs in machine learning, highlighting their importance in various applications. By presenting an overview of different graph-based machine learning techniques, we hope to stimulate further research and innovation in this exciting field.",321
$^{25}$Si $\beta^+$-decay spectroscopy,0,"$\beta$-decay spectroscopy provides valuable information on exotic nuclei and a stringent test for nuclear theories beyond the stability line. To search for new $\beta$-delayed protons and $\gamma$ rays of $^{25}$Si to investigate the properties of $^{25}$Al excited states. $^{25}$Si $\beta$ decays were measured by using the Gaseous Detector with Germanium Tagging system at the National Superconducting Cyclotron Laboratory. The protons and $\gamma$ rays emitted in the decay were detected simultaneously. A Monte Carlo method was used to model the Doppler broadening of $^{24}$Mg $\gamma$-ray lines caused by nuclear recoil from proton emission. Shell-model calculations using two newly developed universal \textit{sd}-shell Hamiltonians, USDC and USDI, were performed. The most precise $^{25}$Si half-life to date has been determined. A new proton branch at 724(4)~keV and new proton-$\gamma$-ray coincidences have been identified. Three $^{24}$Mg $\gamma$-ray lines and eight $^{25}$Al $\gamma$-ray lines are observed for the first time in $^{25}$Si decay. The first measurement of the $^{25}$Si $\beta$-delayed $\gamma$ ray intensities through the $^{25}$Al unbound states is reported. All the bound states of $^{25}$Al are observed to be populated in the $\beta$ decay of $^{25}$Si. Several inconsistencies between the previous measurements have been resolved, and new information on the $^{25}$Al level scheme is provided. An enhanced decay scheme has been constructed and compared to the mirror decay of $^{25}$Na and the shell-model calculations. The measured excitation energies, $\gamma$-ray and proton branchings, log~$ft$ values, and Gamow-Teller transition strengths for the states of $^{25}$Al populated in the $\beta$ decay of $^{25}$Si are in good agreement with the shell-model calculations, offering gratifyingly consistent insights into the fine nuclear structure of $^{25}$Al.",300
$^{25}$Si $\beta^+$-decay spectroscopy,1,"The study of the nuclear structure and decay of exotic isotopes is of great importance for our understanding of the fundamental properties of matter. In particular, the $\beta^+$-decay of $^{25}$Si is a topic of intense research due to its potential application in nuclear astrophysics and the search for new physics beyond the standard model.

In this work, we present a detailed spectroscopic study of the $\beta^+$-decay of $^{25}$Si, performed using a sophisticated experimental setup which combines high-resolution gamma-ray spectroscopy and charged-particle detection. The data analysis has allowed us to identify a number of excited states in the daughter nucleus, $^{25}$Al, and to study the properties of the $\beta^+$-decay process.

Our results shed new light on the structure of $^{25}$Al and provide valuable insights into the weak interaction responsible for the $\beta^+$-decay. Specifically, we observe a significant enhancement of the so-called Gamow-Teller transition strength, a key parameter for the calculation of reaction rates in stellar environments. Our findings have important implications for the understanding of astrophysical nucleosynthesis and the synthesis of heavy elements in the universe.

Overall, our study represents a significant contribution to the field of nuclear physics and demonstrates the power of advanced spectroscopic techniques for the investigation of exotic nuclear systems.",216
Computer-inspired concept for high-dimensional multipartite quantum gates,0,"An open question in quantum optics is how to manipulate and control complex quantum states in an experimentally feasible way. Here we present concepts for transformations of high-dimensional multi-photonic quantum systems. The proposals rely on two new ideas: (I) a novel high-dimensional quantum non-demolition measurement, (II) the encoding and decoding of the entire quantum transformation in an ancillary state for sharing the necessary quantum information between the involved parties. Many solutions can readily be performed in laboratories around the world, and identify important pathways for experimental research in the near future. The concept has been found using the computer algorithm Melvin for designing computer-inspired quantum experiments.

This demonstrates that computer algorithms can inspire new ideas in science, which is a widely unexplored potential.",128
Computer-inspired concept for high-dimensional multipartite quantum gates,1,"In this paper, we propose a novel computer-inspired concept for implementing high-dimensional multipartite quantum gates. Our approach takes advantage of recent advances in quantum computing to design a fault-tolerant gate which can manipulate multiple quantum systems simultaneously, leading to significant improvements in quantum information processing. Specifically, our method involves utilizing classical algorithms and error correction methods to design a high-fidelity gate that can operate on systems with up to N dimensions. We demonstrate the effectiveness of our algorithm by simulating it on a quantum computer, verifying its ability to perform a variety of multi-party operations. Our results suggest that this methodology will be a valuable tool for researchers looking to implement high-dimensional quantum gates in a scalable and efficient manner, with applications in fields such as quantum cryptography and communication.",136
"Nuclear and Magnetic Structures of the Frustrated Quantum Antiferromagnet Barlowite, Cu$_{4}$(OH)$_{6}$FBr",0,"Barlowite, Cu$_{4}$(OH)$_{6}$FBr, has attracted much attention as the parent compound of a new series of quantum spin liquid candidates, Zn$_{x}$Cu$_{4-x}$(OH)$_{6}$FBr. While it is known to undergo a magnetic phase transition to a long-range ordered state at $T_{N} = 15$ K, there is still no consensus over either its nuclear or magnetic structures. Here, we use comprehensive powder neutron diffraction studies on deuterated samples of barlowite to demonstrate that the only space group consistent with the observed nuclear and magnetic diffraction at low-temperatures is the orthorhombic $Pnma$ space group. We furthermore conclude that the magnetic intensity at $T < T_{N}$ is correctly described by the $Pn^\prime m^\prime a$ magnetic space group, which crucially allows the ferromagnetic component observed in previous single-crystal and powder magnetisation measurements. As such, the magnetic structure of barlowite resembles that of the related material clinoatacamite, Cu$_{4}$(OH)$_{6}$Cl$_{2}$, the parent compound of the well-known quantum spin liquid candidate hebertsmithite, ZnCu$_{3}$(OH)$_{6}$Cl$_{2}$.",189
"Nuclear and Magnetic Structures of the Frustrated Quantum Antiferromagnet Barlowite, Cu$_{4}$(OH)$_{6}$FBr",1,"In this research paper, we investigate the nuclear and magnetic structures of the mineral barlowite, Cu$_{4}$(OH)$_{6}$FBr, which exhibits frustrated quantum antiferromagnetic behavior. Through neutron diffraction experiments, we have determined the crystal structure of barlowite to be tetragonal with space group P4/ncc and refined the site occupancy factors, as well as the thermal and magnetic parameters of the copper cations. Our measurements confirm that the copper spins in barlowite are arranged in a two-dimensional frustrated antiferromagnetic pattern. In addition, we have used muon spectroscopy to probe the local magnetic field at the copper cation sites and determined that the moments are highly anisotropic. Using density-functional-theory calculations, we have shown that the observed magnetic anisotropy can be explained by the strong spin-orbit coupling and anisotropic exchange interactions in the crystal structure. These results provide essential insights into the complex and fascinating magnetic behavior of barlowite and have implications for the understanding of frustrated quantum antiferromagnets in general.",166
Holomorphic matrix models,0,"This is a study of holomorphic matrix models, the matrix models which underlie the conjecture of Dijkgraaf and Vafa. I first give a systematic description of the holomorphic one-matrix model. After discussing its convergence sectors, I show that certain puzzles related to its perturbative expansion admit a simple resolution in the holomorphic set-up. Constructing a `complex' microcanonical ensemble, I check that the basic requirements of the conjecture (in particular, the special geometry relations involving chemical potentials) hold in the absence of the hermicity constraint. I also show that planar solutions of the holomorphic model probe the entire moduli space of the associated algebraic curve. Finally, I give a brief discussion of holomorphic $ADE$ models, focusing on the example of the $A_2$ quiver, for which I extract explicitly the relevant Riemann surface. In this case, use of the holomorphic model is crucial, since the Hermitian approach and its attending regularization would lead to a singular algebraic curve, thus contradicting the requirements of the conjecture. In particular, I show how an appropriate regularization of the holomorphic $A_2$ model produces the desired smooth Riemann surface in the limit when the regulator is removed, and that this limit can be described as a statistical ensemble of `reduced' holomorphic models.",207
Holomorphic matrix models,1,"Holomorphic matrix models are a class of mathematical models used to study quantum field theories. These models are characterized by the holomorphic behavior of the matrix variables, meaning that they satisfy certain analytic properties. They have been extensively studied in the field of theoretical physics and have been shown to be particularly useful in the study of two-dimensional string theories. One of the main advantages of holomorphic matrix models is their ability to solve problems that are difficult to approach using other methods, such as non-perturbative effects in string theory. Holomorphic matrix models have also been used to study matrix quantum mechanics, random matrix theory, and integrable systems. Despite their usefulness, there are still many open questions related to holomorphic matrix models, including the exact nature of the relationship between them and topological string theory. In this paper, we present a detailed review of the current state of research on holomorphic matrix models, including recent developments and future directions. We also discuss some of the most important open questions in this field.",174
Unsupervised Learning from Continuous Video in a Scalable Predictive Recurrent Network,0,"Understanding visual reality involves acquiring common-sense knowledge about countless regularities in the visual world, e.g., how illumination alters the appearance of objects in a scene, and how motion changes their apparent spatial relationship. These regularities are hard to label for training supervised machine learning algorithms; consequently, algorithms need to learn these regularities from the real world in an unsupervised way. We present a novel network meta-architecture that can learn world dynamics from raw, continuous video. The components of this network can be implemented using any algorithm that possesses three key capabilities: prediction of a signal over time, reduction of signal dimensionality (compression), and the ability to use supplementary contextual information to inform the prediction. The presented architecture is highly-parallelized and scalable, and is implemented using localized connectivity, processing, and learning. We demonstrate an implementation of this architecture where the components are built from multi-layer perceptrons. We apply the implementation to create a system capable of stable and robust visual tracking of objects as seen by a moving camera.

Results show performance on par with or exceeding state-of-the-art tracking algorithms. The tracker can be trained in either fully supervised or unsupervised-then-briefly-supervised regimes. Success of the briefly-supervised regime suggests that the unsupervised portion of the model extracts useful information about visual reality. The results suggest a new class of AI algorithms that uniquely combine prediction and scalability in a way that makes them suitable for learning from and --- and eventually acting within --- the real world.",255
Unsupervised Learning from Continuous Video in a Scalable Predictive Recurrent Network,1,"This paper presents an approach to unsupervised learning in an environment of continuous video streams using a scalable and predictive recurrent neural network. The aim of this study is to develop a model capable of discovering and learning the underlying structure of visual data from primary inputs in an unsupervised manner. This model extracts spatial and temporal representations from incoming frames to build a comprehensive understanding of the environment. 

Our proposed architecture consists of a set of neural modules that process the incoming video through different temporal scales. These modules integrate spatial and temporal information to form higher-level abstractions, resulting in an efficient and scalable model. Additionally, our model can adapt to new data streams without interfering with previously learned knowledge, making it suitable for real-world applications that require continuous learning.

To evaluate the effectiveness of our model, we conducted experiments on various data streams. Our results demonstrate that our model achieves state-of-the-art performance in an unsupervised manner, surpassing other existing methods. We also show that our model can identify and classify multiple objects in scenes, making it a promising tool for video analysis and surveillance.

In conclusion, our scalable predictive recurrent neural network presents a new approach to unsupervised learning from continuous video streams. It has great potential for a wide range of applications beyond our current experiments, such as autonomous driving and robotics, making it a valuable contribution to the field of artificial intelligence.",241
A new route towards merging massive black holes,0,"Recent advances in gravitational-wave astronomy make the direct detection of gravitational waves from the merger of two stellar-mass compact objects a realistic prospect. Evolutionary scenarios towards mergers of double compact objects generally invoke common-envelope evolution which is poorly understood, leading to large uncertainties in merger rates. We explore the alternative scenario of massive overcontact binary (MOB) evolution, which involves two very massive stars in a very tight binary which remain fully mixed due to their tidally induced high spin. We use the public stellar-evolution code MESA to systematically study this channel by means of detailed simulations. We find that, at low metallicity, MOBs produce double-black-hole (BH+BH) systems that will merge within a Hubble time with mass ratios close to one, in two mass ranges, ~25...60msun and >~ 130msun, with pair instability supernovae (PISNe) being produced in-between. Our models are also able to reproduce counterparts of various stages in the MOB scenario in the local Universe, providing direct support for it. We map the initial parameter space that produces BH+BH mergers, determine the expected chirp mass distribution, merger times, Kerr parameters and predict event rates. We typically find that for Z~<Z_sun/10, there is one BH+BH merger for ~1000 core-collapse supernovae. The advanced LIGO (aLIGO) detection rate is more uncertain and depends on the metallicity evolution.

Deriving upper and lower limits from a local and a global approximation for the metallicity distribution of massive stars, we estimate aLIGO detection rates (at design limit) of ~19-550 yr^(-1) for BH+BH mergers below the PISN gap and of ~2.1-370 yr^(-1) above the PISN gap. Even with conservative assumptions, we find that aLIGO should soon detect BH+BH mergers from the MOB scenario and that these could be the dominant source for aLIGO detections.",307
A new route towards merging massive black holes,1,"The merger of massive black holes is a striking astrophysical phenomenon that continuously puzzles astronomers, particularly as the gravitational waves produced by these events can be detected by advanced instruments such as LIGO and Virgo. In this work, we explore a new route towards achieving the merger of massive black holes through the process of dynamical capture.

Recent simulations have suggested that more massive black holes can be captured and merge with lighter ones in dense star clusters. However, this dynamical capture process requires the black holes to overcome the so-called ""last parsec problem"" - a quandary regarding the rate at which black holes spiraling towards each other in dense environments are brought close enough to merge via gravitational wave emission. Previous research has focused on the use of stellar nuclei to bring black holes close enough to merge, but this method has limited efficiency.

In this study, we propose a new method to overcome the last parsec problem that involves the introduction of a third, intermediate mass black hole. The interaction of the massive black holes with the intermediate ones allows the overall system to shrink to a scale where gravitational radiation becomes dominant, leading to their eventual merge.

We demonstrate the efficacy of this new method through numerical simulations of massive black hole triplets in dense star clusters. Our results indicate that the merger rate of black holes can be significantly enhanced by the presence of intermediate mass black holes. These results have significant implications for our understanding of fundamental astrophysical processes, as well as the detection and interpretation of gravitational wave events.",265
Structure of the Source I disk in Orion-KL,0,"This paper analyses images from 43 to 340 GHz to trace the structure of the Source I disk in Orion-KL with $\sim$12 AU resolution. The data reveal an almost edge-on disk with an outside diameter $\sim$ 100 AU which is heated from the inside. The high opacity at 220-340 GHz hides the internal structure and presents a surface temperature $\sim$500 K. Images at 43, 86 and 99 GHz reveal structure within the disk. At 43 GHz there is bright compact emission with brightness temperature $\sim$1300 K. Another feature, most prominent at 99 GHz, is a warped ridge of emission. The data can be explained by a simple model with a hot inner structure, seen through cooler material. A wide angle outflow mapped in SiO emission ablates material from the interior of the disk, and extends in a bipolar outflow over 1000 AU along the rotation axis of the disk.

SiO $v=0$ $J=5-4$ emission appears to have a localized footprint in the warped ridge. These observations suggest that the ridge is the working surface of the disk, and heated by accretion and the outflow. The disk structure may be evolving, with multiple accretion and outflow events. We discuss two sources of variability: 1) variable accretion onto the disk as Source I travels through the filamentary debris from the BN-Source I encounter $\sim$550 yr ago; and 2) episodic accretion from the disk onto the protostar which may trigger multiple outflows. The warped inner disk structure is direct evidence that SrcI could be a binary experiencing episodic accretion.",266
Structure of the Source I disk in Orion-KL,1,"The Orion Molecular Cloud Complex has been a topic of interest for astronomers for the past few decades. In particular, the disk around the young massive star Source I in the Orion-KL region has been a subject of extensive research. In this paper, we present an analysis of the structure of the Source I disk using observations obtained with the Atacama Large Millimeter/submillimeter Array (ALMA).

Our observations reveal that the Source I disk is an inclined ring, with a radius of approximately 60 astronomical units (AU), and a height of around 7 AU. The disk shows a distinctive spiral arm structure, as well as several other small features, including a ""hole"" or low-density region close to the center. 

We also find evidence for a temperature gradient in the disk, which could be due to variations in the heating and cooling mechanisms. Our analysis suggests that the disk is likely to be in a state of Keplerian rotation, indicating that the central star is the primary source of mass and angular momentum. 

Overall, our results provide new insights into the structure and dynamics of the Source I disk in the Orion-KL region, and contribute to our understanding of the formation and early evolution of massive stars. Further observations and modeling efforts will be necessary to fully characterize this interesting system and to better constrain the physical processes at play.",232
Context based Roman-Urdu to Urdu Script Transliteration System,0,"Now a day computer is necessary for human being and it is very useful in many fields like search engine, text processing, short messaging services, voice chatting and text recognition. Since last many years there are many tools and techniques that have been developed to support the writing of language script.

Most of the Asian languages like Arabic, Urdu, Persian, Chains and Korean are written in Roman alphabets. Roman alphabets are the most commonly used for transliteration of languages, which have non-Latin scripts. For writing Urdu characters as an input, there are many layouts which are already exist. Mostly Urdu speaker prefer to use Roman-Urdu for different applications, because mostly user is not familiar with Urdu language keyboard. The objective of this work is to improve the context base transliteration of Roman-Urdu to Urdu script. In this paper, we propose an algorithm which effectively solve the transliteration issues. The algorithm work like, convert the encoding roman words into the words in the standard Urdu script and match it with the lexicon.

If match found, then display the word in the text editor. The highest frequency words are displayed if more than one match found in the lexicon. Display the first encoded and converted instance and set it to the default if there is not a single instance of the match is found and then adjust the given ambiguous word to their desire location according to their context. The outcome of this algorithm proved the efficiency and significance as compare to other models and algorithms which work for transliteration of Raman-Urdu to Urdu on context.",268
Context based Roman-Urdu to Urdu Script Transliteration System,1,"The aim of this paper is to propose a contextual approach to Roman-Urdu to Urdu script transliteration. The need for this system arises due to the widespread usage of Roman-Urdu in digital communication, whereas Urdu script remains the preferred choice in official and formal documents. The proposed system takes into account the contextual meaning and grammar of the words being transliterated and provides an accurate conversion to Urdu script. 

The system consists of two main modules: a contextual analysis module and a transliteration module. The contextual analysis module utilizes a morphological parser to analyze the context in which the word is used. The module considers the word form, part of speech, and the surrounding words to provide a more accurate conversion. The transliteration module then utilizes a set of conversion rules specifically designed for the contextual conversion of Roman-Urdu to Urdu script. 

Experimental results show that the proposed system achieves an accuracy rate of 94.5%, which is significantly higher than existing systems. The proposed system provides a practical solution for the transliteration of Roman-Urdu to Urdu script in official documents, digital communication, and Urdu language learning. 

The proposed system also has the potential for adaptation to other languages that use Roman script. Future work involves exploring the adaptability of the system to other languages and developing a user-friendly interface to facilitate its use by a wider audience.",233
Analysis of the main factors for the configuration of green ports in Colombia,0,"This study analyzes the factors affecting the configuration and consolidation of green ports in Colombia. For this purpose a case stady of maritime cargo ports of Cartagena, Barranquilla and Santa Marta is performed addressing semiestructured interviews to identify the factors contributing to the consolidation of green ports and the factors guiding the sustainability management in the ports that have not yet been certified as green ports. The results show that environmental regulations are atarting point not the key factor to consolidate asgreen ports. As a conclusions, the conversion of Colombian to green ports should not be limited to the attaiment of certifications, such as Ecoport certification, but should ensure the contribution to sustainable development through economic, social and environmental dimensions and the achievement of the SDGs",126
Analysis of the main factors for the configuration of green ports in Colombia,1,"This research paper aims to analyze the primary factors influencing the creation of green ports in Colombia, addressing the challenges and opportunities generated by environmental concerns, port stakeholders' expectations, and global market's demands. To achieve this objective, the study combines a literature review and a case study method applied to a sample of Colombian ports. The analysis highlights the importance of policy integration, stakeholder collaboration, technological innovation, and workforce training in promoting sustainability dimensions of port operations and reducing their negative impacts on the environment. Overall, the findings suggest that the implementation of green ports in Colombia represents a significant transition towards a more sustainable and socially responsible port management model that aligns economic growth with environmental protection and climate action.",122
Benchmark Calculations of Electron Impact Electronic Excitation of the Hydrogen Molecule,0,"We present benchmark integrated and differential cross-sections for electron collisions with H$_2$ using two different theoretical approaches, namely, the R-matrix and molecular convergent close-coupling (MCCC). This is similar to comparative studies conducted on electron-atom collisions for H, He and Mg.

Electron impact excitation to the $b \ ^3\Sigma_u^+$, $a \ ^3\Sigma_g^+$, $B \ ^1\Sigma_u^+$, $c \ ^3\Pi_u$, $EF \ ^1\Sigma_g^+$, $C \ ^1\Pi_u$, $e \ ^3\Sigma_u^+$, $h \ ^3\Sigma_g^+$, $B' \ ^1\Sigma_u^+$ and $d \ ^3\Pi_u$ excited electronic states are considered. Calculations are presented in both the fixed nuclei and adiabatic nuclei approximations, where the latter is shown only for the $b \ ^3\Sigma_u^+$ state. Good agreement is found for all transitions presented. Where available, we compare with existing experimental and recommended data.",128
Benchmark Calculations of Electron Impact Electronic Excitation of the Hydrogen Molecule,1,"The development of accurate models for understanding the electronic excitation of the hydrogen molecule by electron impact has been the focus of much research. In this paper, we present benchmark calculations of electronic excitation that utilize a theoretical method specifically designed to study small molecular systems. Through advanced simulations, we have analyzed the accuracy of different theoretical models and have shown that electron impact excitation can only be accurately studied by accounting for both the static and dynamic correlation within the molecular system. Our calculations demonstrate the significance of electron correlation effects and provide valuable insights into the electronic excitation process of the hydrogen molecule. This research could have significant implications for the design and development of molecular systems in fields such as atmospheric sciences and astrophysics.",127
Preservation of the joint essential matricial range,0,"Let $A = (A_1, \dots, A_m)$ be an $m$-tuple of elements of a unital $C$*-algebra ${\cal A}$ and let $M_q$ denote the set of $q \times q$ complex matrices. The joint $q$-matricial range $W^q(A)$ is the set of $(B_1, \dots, B_m) \in M_q^m$ such that $B_j = \Phi(A_j)$ for some unital completely positive linear map $\Phi: {\cal A} \rightarrow M_q$. When ${\cal A}= B(H)$, where $B(H)$ is the algebra of bounded linear operators on the Hilbert space $H$, the {\bf joint spatial $q$-matricial range} $W^q_s(A)$ of $A$ is the set of $(B_1, \dots, B_m) \in M_q^m$ for which there is a $q$-dimensional $V$ of $H$ such that $B_j$ is a compression of $A_j$ to $V$ for $j=1,\dots, m$. Suppose $K(H)$ is the set of compact operators in $B(H)$. The joint essential spatial $q$-matricial range is defined as $$W_{ess}^q(A) = \cap \{ {\bf cl}(W_s^q(A_1+K_1, \dots, A_m+K_m)): K_1, \dots, K_m \in K(H) \},$$ where ${\bf cl}$ denotes the closure. Let $\pi$ be the canonical surjection from $B(H)$ to the Calkin algebra $B(H)/K(H)$. We prove that $W_{ess}^q(A) =W^q(\pi(A) $, where $\pi(A) = (\pi(A_1), \dots, \pi(A_m))$. Furthermore, for any positive integer $N$, we prove that there are self-adjoint compact operators $K_1, \dots, K_m$ such that $${\bf cl}(W^q_s(A_1+K_1, \dots, A_m+K_m)) = W^q_{ess}(A) \quad \hbox{ for all } q \in \{1, \dots, N\}.$$ These results generalize those of Narcowich-Ward and Smith-Ward, obtained in the $m=1$ case, and also generalize a result of M\""{u}ller obtained in case $m \ge 1$ and $q=1$.

Furthermore, if $W_{ess}^1({\bf A}) $ is a simplex in ${\mathbb R}^m$, then we prove that there are self-adjoint $K_1, \dots, K_m \in K(H)$ such that ${\bf cl}(W^q_s(A_1+K_1, \dots, A_m+K_m)) = W^q_{ess}(A)$ for all positive integers $q$.",340
Preservation of the joint essential matricial range,1,"The preservation of the joint essential matricial range is a central question in the field of linear algebra. In essence, this issue concerns whether or not a matrix has a range of vectors that spans all of the spaces essential to its operation. There are a number of reasons why this question is important, ranging from the development of advanced algorithms and computational techniques to the modeling of complex systems in fields such as physics and biology.

One approach to investigating the preservation of the joint essential matricial range involves the use of a method known as singular value decomposition (SVD). This technique allows researchers to break down a matrix into its constituent components, including its singular values and eigenvectors. By doing so, it becomes possible to analyze the matrix in great detail and determine whether or not it satisfies certain criteria related to the preservation of the joint essential matricial range.

Another important area of research in this field involves the development of new algorithms and computational techniques for analyzing complex systems. For example, advanced numerical methods and iterative algorithms have been developed to help researchers better understand the behavior of large matrices with numerous components. These techniques have been particularly important in the study of biological systems, where large matrices are often used to model complex interactions between genes and proteins.

Overall, the preservation of the joint essential matricial range is an important area of research with numerous practical applications in fields ranging from engineering to biology. By better understanding the properties of large matrices and their essential matricial ranges, researchers will be better equipped to develop the tools and techniques necessary to analyze and predict the behavior of complex systems.",283
Bounds on Herman's algorithm,0,"Herman's self-stabilisation algorithm allows a ring of $N$ processors having any odd number of tokens to reach a stable state where exactly one token remains. McIver and Morgan conjecture that the expected time taken for stabilisation is maximised when there are three equally-spaced tokens. We prove exact results on a related cost function, and obtain a bound on expected time which is very close to the conjectured bound.",71
Bounds on Herman's algorithm,1,"This paper derives novel lower and upper bounds on the running time of Herman's algorithm. The proposed bounds are shown to be tighter than previously known bounds, and are derived by analyzing the algorithm's behavior on a specific class of inputs. The theoretical analysis is complemented by experimental evaluations, which provide empirical evidence that the tighter bounds are also reflected in the algorithm's practical performance. Our results have important implications for the design and analysis of algorithms with similar properties.",83
Yang-Mills thermodynamics,0,We present a quantitative analysis of Yang-Mills thermodynamics in 4D flat spacetime. The focus is on the gauge group SU(2). Results for SU(3) are mentioned in passing. Although all essential arguments and results were reported elsewhere we summarize them here in a concise way and offer a number of refinements and some additions.,56
Yang-Mills thermodynamics,1,"This paper reviews the thermodynamics of the Yang-Mills theory. The approach is based on the recent developments in quantum chromodynamics using lattice simulations. We address the underlying assumptions and physical interpretation of the thermodynamic quantities, such as the equation of state and transport coefficients, and summarize their status in the context of the heavy-ion collision experiments.",58
Beta-decay formulas revisited (I): Gamow--Teller and spin-dipole contributions to allowed and first-forbidden transitions,0,"We propose formulas of the nuclear beta-decay rate that are useful in a practical calculation. The decay rate is determined by the product of the lepton and hadron current densities. A widely used formula relies upon the fact that the low-energy lepton wave functions in a nucleus can be well approximated by a constant and linear to the radius for the $s$-wave and $p$-wave wave functions, respectively. We find, however, the deviation from such a simple approximation is evident for heavy nuclei with large $Z$ by numerically solving the Dirac equation. In our proposed formulas, the neutrino wave function is treated exactly as a plane wave, while the electron wave function is obtained by iteratively solving the integral equation, thus we can control the uncertainty of the approximate wave function. The leading-order approximation gives a formula equivalent to the conventional one and overestimates the decay rate. We demonstrate that the next-to-leading-order formula reproduces well the exact result for a schematic transition density as well as a microscopic one obtained by a nuclear energy-density functional method.",184
Beta-decay formulas revisited (I): Gamow--Teller and spin-dipole contributions to allowed and first-forbidden transitions,1,"In this paper, we revisit the beta-decay formulas and examine the contributions of the Gamow-Teller and spin-dipole mechanisms to allowed and first-forbidden transitions. We present a comprehensive theoretical framework for beta decay that takes into account the effects of these two important contributions. Our analysis shows that the inclusion of these mechanisms into the calculation significantly improves the agreement between theory and experiment. We also highlight the impact of nuclear structure on the beta-decay rates and illustrate the use of the formulas in predicting decay spectra. Our findings suggest that the Gamow-Teller and spin-dipole contributions play a crucial role in understanding beta decay and should be taken into consideration in future studies. Overall, this work provides a deeper insight into the physics of beta decay and has important implications for nuclear structure and astrophysics.",141
On Learning Combinatorial Patterns to Assist Large-Scale Airline Crew Pairing Optimization,0,"Airline Crew Pairing Optimization (CPO) aims at generating a set of legal flight sequences (crew pairings), to cover an airline's flight schedule, at minimum cost. It is usually performed using Column Generation (CG), a mathematical programming technique for guided search-space exploration. CG exploits the interdependencies between the current and the preceding CG-iteration for generating new variables (pairings) during the optimization-search. However, with the unprecedented scale and complexity of the emergent flight networks, it has become imperative to learn higher-order interdependencies among the flight-connection graphs, and utilize those to enhance the efficacy of the CPO. In first of its kind and what marks a significant departure from the state-of-the-art, this paper proposes a novel adaptation of the Variational Graph Auto-Encoder for learning plausible combinatorial patterns among the flight-connection data obtained through the search-space exploration by an Airline Crew Pairing Optimizer, AirCROP (developed by the authors and validated by the research consortium's industrial sponsor, GE Aviation). The resulting flight-connection predictions are combined on-the-fly using a novel heuristic to generate new pairings for the optimizer.

The utility of the proposed approach is demonstrated on large-scale (over 4200 flights), real-world, complex flight-networks of US-based airlines, characterized by multiple hub-and-spoke subnetworks and several crew bases.",222
On Learning Combinatorial Patterns to Assist Large-Scale Airline Crew Pairing Optimization,1,"The airline industry is a complex system with many challenges to optimize operations. One of the main challenges is the crew pairing optimization, which is the process of assigning a crew to a sequence of flights. This problem becomes particularly difficult when dealing with large-scale airline operations. In this paper, we present a method that utilizes machine learning to learn and apply combinatorial patterns in assisting with crew pairing optimization.

Our approach leverages both unsupervised and supervised learning techniques to extract combinatorial patterns from the historical data of flight schedules and crew assignments. We then use these patterns to predict the most likely crew pairing options for new flights. To evaluate our method, we conducted experiments using real-world airline data, and the results show that our approach significantly outperforms existing optimization methods in terms of accuracy and computational efficiency.

By applying machine learning to assist with crew pairing optimization, we provide a new approach that has the potential to revolutionize the airline industry. Our method can help airlines to reduce operational costs, improve crew satisfaction, and enhance the overall customer experience by ensuring that flights are staffed with highly effective and efficient crews. Additionally, our work provides a framework for applying combinatorial pattern analysis to other optimization problems in complex systems.",213
A chain dictionary method for Word Sense Disambiguation and applications,0,"A large class of unsupervised algorithms for Word Sense Disambiguation (WSD) is that of dictionary-based methods. Various algorithms have as the root Lesk's algorithm, which exploits the sense definitions in the dictionary directly. Our approach uses the lexical base WordNet for a new algorithm originated in Lesk's, namely ""chain algorithm for disambiguation of all words"", CHAD. We show how translation from a language into another one and also text entailment verification could be accomplished by this disambiguation.",80
A chain dictionary method for Word Sense Disambiguation and applications,1,"This paper presents a novel technique for Word Sense Disambiguation (WSD), called the chain dictionary method. The approach involves the use of a chain of dictionaries to improve WSD performance by incorporating the information from multiple sources. The method has been evaluated on several benchmark datasets, demonstrating its effectiveness in improving the accuracy of WSD. Furthermore, we discuss the potential applications of the chain dictionary method in various fields, including natural language processing, information retrieval, and machine translation.",78
The unmixed kinematics and origins of diffuse stellar light in the core of the Hydra I cluster (Abell 1060),0,"Diffuse intracluster light (ICL) and cD galaxy halos are believed to originate from galaxy evolution and disruption. We present a kinematic study of the ICL in the Hydra I cluster core, using planetary nebulas (PNs) as tracers.

We used multi-slit imaging spectroscopy with FORS2 on VLT-UT1 to detect 56 PNs associated with diffuse light in the central 100 x 100 kpc^2 of Hydra I. We measured their [OIII] magnitudes, sky positions, and velocity distribution (LOSVD), and compared with the phase-space distribution of nearby galaxies. The luminosity function of the detected PNs is consistent with that expected at a distance of ~50 Mpc. Their number density is ~4 times lower for the light seen than expected, and we discuss ram pressure stripping of the PNs by the hot ICM as one of the possible explanations. The LOSVD histogram of the PNs is highly non-Gaussian and multipeaked: it is dominated by a broad central component with sigma~500 km/s at around the average velocity of the cluster, and shows two additional narrower peaks at 1800 km/s and 5000 km/s. The main component is broadly consistent with the outward continuation of the intracluster halo of NGC 3311, which was earlier shown to have a velocity dispersion of ~470 km/s at radii of >50"". Galaxies with velocities in this range are absent in the central 100 x 100 kpc^2 and may have been disrupted earlier to build this component.

The PNs in the second peak in the LOSVD at 5000 km/s are coincident spatially and in velocities with a group of dwarf galaxies in the MSIS field. They may trace the debris from the ongoing tidal disruption of these galaxies. Most of the diffuse light in the core of Hydra is still not phase-mixed. The build-up of ICL and the dynamically hot cD halo around NGC 3311 are ongoing, through the accretion of material from galaxies falling into the cluster core and tidally interacting with its potential well.",337
The unmixed kinematics and origins of diffuse stellar light in the core of the Hydra I cluster (Abell 1060),1,"In this study, we investigate the kinematics and origins of the diffuse stellar light found in the core of the Hydra I cluster (Abell 1060). Through deep imaging, we were able to analyze the properties of the diffuse light and distinguish it from the light produced by the individual stars. We found that the diffuse light has a unique velocity distribution compared to the individual stars, indicating a different origin. Our analysis suggests that the diffuse light is likely associated with the intracluster stellar population which has been tidally stripped from galaxies in the cluster and is now free-floating.

We also investigated the dynamical state of the Hydra I cluster through the velocity distribution of its member galaxies. Our results show that the cluster is in a relaxed state, with a relatively low velocity dispersion and a slight elongation in the southeast-northwest direction.

Furthermore, we conducted a comparative analysis of the diffuse light in the Hydra I cluster and in two other galaxy clusters, Abell 2744 and the Coma cluster. Our results suggest that the properties of the diffuse light are unique to each cluster, implying that they have different origins. The diffuse light in the Hydra I cluster has a higher surface brightness and a steeper radial profile compared to those in the other clusters, indicating a stronger tidal interaction with the galaxies in the cluster.

In conclusion, our study provides new insights into the kinematics and origins of the diffuse stellar light in the core of the Hydra I cluster. Our findings suggest that the intracluster stellar population plays a significant role in the evolution of galaxy clusters and provides important clues to understanding the formation of galaxies in the universe.",285
A Possible High Nova Rate for Two Local Group Dwarf Galaxies: M32 and NGC 205,0,"We report the results of a preliminary nova survey of Local Group dwarf ellipticals. We used the Tenagra Observatory to observe M32, NGC 205, NGC 147, and NGC 185 in their entirety every clear night over a 4.5 month interval and discovered one nova in M32 and a candidate nova in NGC 205. The nova in M32 was verified spectroscopically. The nova candidate in NGC 205 had an unusually low peak luminosity (M_V = -5.1), and we were unable to obtain spectroscopic verification. We report a high bulk nova rate for M32 of 2(+2.4,-1.0) yr^-1 and, assuming the candidate nova is correctly identified, for NGC 205 of 2(+2.2,-1.0) yr^-1. If the NGC 205 variable is not a nova, we calculate an upper limit on the bulk nova rate for NGC 205 of 1.5 yr^-1. We report upper limits on the bulk nova rates in NGC 147 of 2 yr^-1 and NGC 185 of 1.8 yr^-1 and a combined bulk nova rate for the four galaxies of 4(+4.2,-1.4) yr^-1 (2{+3.9,-1.4} yr^-1 without the NGC 205 nova candidate). From the bulk rates, integrated and extinction corrected V-band photometry, and (V-K)_0 colors we derive a luminosity specific nova rate for M32 of 12.0(+14.4,-6.0) yr^-1 [10^10 L_Sun,K]^-1 and for NGC 205 of 29.3(+32.3,-14.7) yr^-1 [10^10 L_Sun,K]^-1 and for the combined 4 galaxies of 14.1(+14.8,-4.9) yr^-1 [10^10 L_Sun,K]^-1 (7.0{+13.7,-4.9} yr^-1[10^10 L_Sun,K]^-1 without the NGC 205 nova candidate).

If the higher rate is confirmed by surveys in subsequent seasons, it would imply that either dwarf ellipticals have a higher interacting binary fraction than their higher mass counter parts, or that the completeness is higher for these less complex systems and the nova rates for larger, more distant systems are systematically underestimated.",351
A Possible High Nova Rate for Two Local Group Dwarf Galaxies: M32 and NGC 205,1,"Recent studies have suggested that the nearby Local Group dwarf galaxies M32 and NGC 205 may experience a high rate of nova occurrences. To investigate this possibility, we have conducted a detailed analysis of archival data from the Hubble Space Telescope and ground-based observations obtained over multiple epochs. Utilizing these data, we employed a novel statistical methodology to identify potential nova candidates in both galaxies.

Our analysis has yielded a statistically significant excess of light curves consistent with nova-like events in both M32 and NGC 205. These novae appear to be concentrated toward the outskirts of the galaxies, possibly indicating an association with the extended stellar halos which are a common feature of dwarf galaxies. By comparing our observed nova rates to predictions from current theoretical models, we find that such a high rate of novae is unexpected, and may necessitate revisions of these models.

However, we caution that uncertainties in our statistical methodology and the small sample size of known novae in these systems mean that our results should be interpreted with caution. Future observations with more advanced instruments, such as the James Webb Space Telescope, will be crucial in resolving the nature of these novae and shedding light on their potential origins.

Our results have important implications for our understanding of the evolution of dwarf galaxies, which are the most abundant type of galaxy in the Universe. Specifically, they suggest that novae may play a more important role in the enrichment of these systems than previously thought. Our study highlights the importance of continued observations of Local Group dwarf galaxies to better understand the complex processes which shape the evolution of these intriguing cosmic structures.",279
Relaxation by nonlinear diffusion enhancement in a two-dimensional cross-diffusion model for urban crime propagation,0,"We consider a class of macroscopic models for the spatio-temporal evolution of urban crime, as originally going back to Short et al. (Math. Mod. Meth.

Appl. Sci. 18, 2008). The focus here is on the question how far a certain nonlinear enhancement in the random diffusion of criminal agents may exert visible relaxation effects. Specifically, in the context of the system \begin{eqnarray*} \left\{ \begin{array}{l} u_t = \nabla \cdot (u^{m-1} \nabla u) - \chi \nabla \cdot \Big(\frac{u}{v} \nabla v \Big) - uv + B_1(x,t), \\[1mm] v_t = \Delta v +uv - v + B_2(x,t), \end{array} \right. \end{eqnarray*} it is shown that whenever $\chi>0$ and the given nonnegative source terms $B_1$ and $B_2$ are sufficiently regular, the assumption \begin{eqnarray*} m>\frac{3}{2} \end{eqnarray*} is sufficient to ensure that a corresponding Neumann-type initial-boundary value problem, posed in a smoothly bounded planar convex domain, admits locally bounded solutions for a wide class of arbitrary initial data. Furthermore, this solution is seen to be globally bounded if both $B_1$ and $B_2$ are bounded and $\liminf_{t\to\infty} \int_\Omega B_2(\cdot,t)$ is positive. This is supplemented by numerical evidence which, besides illustrating associated smoothing effects in particular situations of sharply structured initial data in the presence of such porous medium type diffusion mechanisms, indicates a significant tendency toward support of singular structures in the linear diffusion case $m=1$.",240
Relaxation by nonlinear diffusion enhancement in a two-dimensional cross-diffusion model for urban crime propagation,1,"This paper presents a two-dimensional cross-diffusion model for urban crime propagation based on the enhancement of nonlinear diffusion. Using this model, we investigate how relaxation can be achieved in urban regions and how crime can spread across space over time. This work is motivated by the need to understand the complex dynamics of crime and to develop effective strategies to combat its propagation in urban areas.

Our approach takes into account the effects of different factors such as population density, crime rate, and diffusion processes. Nonlinear diffusion is introduced to describe the spread of crime in urban regions, and cross-diffusion is incorporated to account for the interactions between different criminal activities. We use mathematical modeling and numerical simulations to demonstrate how our approach can capture key features of urban crime propagation and provide insights into its behavior.

Our results suggest that the nonlinear diffusion enhancement approach can be effective in reducing crime rates in urban areas. We find that relaxation can be achieved by controlling the diffusion rate and the strength of interactions between different criminal activities. Furthermore, we identify some key factors that can influence the speed and extent of crime propagation in urban regions.

Overall, this paper provides a novel approach for studying urban crime propagation based on a two-dimensional cross-diffusion model and nonlinear diffusion enhancement. Our findings have important implications for policymakers and law enforcement agencies seeking to develop effective strategies for controlling crime in urban areas.",245
The VMC survey XXVIII. Improved measurements of the proper motion of the Galactic globular cluster 47 Tucanae,0,"We use deep multi-epoch PSF photometry taken with the Visible and Infrared Survey Telescope for Astronomy (VISTA) to measure and analyze the proper motions of stars within the Galactic globular cluster 47 Tucanae (47 Tuc, NGC 104). The observations are part of the ongoing near-infrared VISTA survey of the Magellanic Cloud system (VMC). The data analyzed here corresponds to one VMC tile and covers a total sky area of 1.77 deg^2. Absolute proper motions with respect to ~9070 background galaxies are calculated from a linear regression model applied to the stellar positions in 11 epochs in the Ks filter. The data extend over a total time baseline of ~17 months. We found a median proper motion of the stars within 47 Tuc of (mu_a cos(d), mu_d) = (+5.89 +/- 0.02(stat) +/- 0.13(sys), -2.14 +/- 0.02(stat) +/- 0.08(sys)) mas/yr, based on the measurements of ~35000 individual sources between 5' and 42' from the cluster center. We compared our result to the proper motions from the newest US Naval Observatory CCD Astrograph Catalog (UCAC5) which includes data from the Gaia data release 1. Selecting cluster members (~2700 stars) we found a median proper motion of (mu_a cos(d), mu_d) = (+5.30 +/- 0.03(stat) +/- 0.70(sys), -2.70 +/- 0.03(stat) +/- 0.70(sys)) mas/yr. The values derived from the VMC data are consistent with the UCAC5 result, and are close to literature measurements obtained using HST. We combined our results with literature radial velocity measurements and reconstructed the orbit of 47 Tuc, finding that the cluster is on a low-ellipticity orbit and is confined within the inner ~7.5 kpc of the Galaxy. We show that the use of an increased time baseline combined with PSF-determined stellar centroids in crowded regions significantly improves the accuracy of the method. In future works, we will apply this method to more VMC tiles to study in detail the kinematics of the Magellanic Clouds.",334
The VMC survey XXVIII. Improved measurements of the proper motion of the Galactic globular cluster 47 Tucanae,1,"This study presents improved measurements of the proper motion of the Galactic globular cluster 47 Tucanae, using data from the Vista Variables in the Vía Láctea (VMC) survey. The VMC survey enables us to achieve a thorough understanding of the 47 Tucanae cluster by obtaining multi-epoch, high spatial resolution imaging in the near-infrared wavelength range. This data is fundamental for studying the kinematics and dynamics of the oldest Galactic globular clusters.

To obtain the proper motion of the cluster, astrometric measurements were compared to the reference catalogs Gaia DR2 and HST. The combined use of Gaia DR2 and VMC provided the best accuracy for the cluster proper motion. The resulting values of proper motion μalpha cos(delta) = 37.11±0.08 mas/yr and μdelta = -26.78±0.09 mas/yr agree within the uncertainties with previous determinations.

The new measurements allowed us to estimate the absolute kinematic parameters of the cluster. From the proper motion, we obtained a space velocity of V = 17.97 ± 0.30 km/s and calculated an orbit with RGC = 8.06 ± 0.13 kpc, vGC = 228.3 ± 4.2 km/s, e = 0.24 ± 0.04, and zmax = 1.02 ± 0.03 kpc. These values agree well with previous studies, but offer a more precise estimation.

We studied the internal dynamics of the cluster by measuring the radial velocities of its stars. The resulting velocity dispersion profile was combined with the estimated surface brightness profile, leading to a dynamical mass of Mdyn = (6.7 ± 0.4) × 10^5 M_sun within a projected radius of 27.2 arcmin. This mass estimate is consistent with previous determinations and confirms the high mass-to-light ratio of 47 Tuc.

Finally, by measuring the proper motion of the cluster, we constructed a relative proper motion diagram of stars in the VMC field. This allowed us to identify candidate cluster members and non-member foreground stars, which will be useful for further studies of the cluster properties.

In conclusion, the presented measurements of the proper motion of 47 Tucanae provide a comprehensive study of the kinematic and dynamic properties of this old Galactic globular cluster.",358
Monte Carlo population synthesis of post-common-envelope white dwarf binaries and type Ia supernova rate,0,"Binary population synthesis (BPS) study provides a comprehensive way to understand evolutions of binaries and their end products. Close white dwarf (WD) binaries have crucial characteristics in examining in uence of yetunresolved physical parameters on the binary evolution. In this paper, we perform Monte Carlo BPS simulations, investigating the population of WD/main sequence (WD/MS) binaries and double WD binaries, with a publicly available binary star evolution code under 37 different assumptions on key physical processes and binary initial conditions. We considered different combinations of the binding energy parameter (lambda_g:considering gravitational energy only, lambda_b: considering both gravitational energy and internal energy, and lambda_e:considering gravitational energy, internal energy, and entropy of the envelope, the values of them derived with the MESA code), CE effciency, critical mass ratio, initial primary mass function and metallicity. We find that a larger number of post-CE WD/MS binaries in tight orbits are formed when the binding energy parameters is set by lambda_e than the cases adopting the other prescriptions. We also find effects of the other input parameters on orbital period and mass distributions of post-CE WD/MS binaries as well.

Containing at least one CO WD, the double WD system evolved from WD/MS binaries may explode as type Ia supernovae (SNe Ia) by merging. In this work, we also investigate a frequency of two WD mergers and compare it to the SNe Ia rate.",236
Monte Carlo population synthesis of post-common-envelope white dwarf binaries and type Ia supernova rate,1,"In this paper, we present the results of a Monte Carlo population synthesis study aimed at understanding the properties of post-common-envelope white dwarf binaries and their contribution to Type Ia supernova rates. Our model takes into account key parameters such as binary star initial masses, initial binary separations, and mass transfer efficiency. We find that the final white dwarf binary population is heavily dependent on the choice of initial conditions, with significant variations in the mass distribution and number of surviving systems. Additionally, our simulations suggest that the white dwarf–white dwarf merger rate may be a more reliable indicator of the Type Ia supernova rate than the common assumption of a constant rate of supernovae per unit stellar mass. Our results also suggest that a significant fraction of Type Ia supernovae may be attributed to the accretion-induced collapse of white dwarfs that exceed the Chandrasekhar mass limit, rather than the traditional single-degenerate scenario. We discuss the implications of these findings for observational programs aiming to constrain the progenitors of Type Ia supernovae and the origins of the observed diversity among these events. Overall, our study highlights the importance of including the effects of binary evolution in models of Type Ia supernova rates.",207
A Possible Solution to the Horizon Problem: The Mad Era for Massless Scalar Theories of Gravity,0,"Extensions of Einstein gravity which allow the gravitational constant $G$ to change with time as the universe evolves may provide a resolution to the horizon problem without invoking a period of vacuum domination and without the subsequent entropy violation. In a cosmology for which the gravitational constant is not in fact constant, the universe may be older at a given temperature than in a standard Hot Big Bang universe; thus, larger regions of space could have come into causal contact at that temperature. This opens the possibility that large regions became smooth at some high temperature without violating causality. The extra aging of the universe can be accomplished by an early period with a large Planck mass, a period we call the MAD era (Modified Aging era or the Massively Aged and Detained era). We discuss in this paper theories of gravity in which the gravitational constant is replaced with a function of a scalar field. However, this resolution to the smoothness problem",163
A Possible Solution to the Horizon Problem: The Mad Era for Massless Scalar Theories of Gravity,1,"Cosmic microwave background measurements have confirmed that the temperature of our universe has remained nearly constant, which gives rise to the horizon problem. In this paper, we propose a solution to the horizon problem by investigating the Madelung representation of massless scalar theories of gravity. We show that the Madelung representation can be used to account for the effects of quantum gravity and provide a framework to study the propagation of gravitational waves. Our numerical simulations demonstrate that the Madelung representation is consistent with observations of the CMB, which supports our suggestion that it may be a possible solution to the horizon problem. We further explore the physical implications of our approach and present a number of ideas for future research, including the possibility of extending our analysis to other theories of gravity. Overall, our results provide a promising pathway for understanding the fundamental nature of the universe and its evolution.",151
Optimal minimax random designs for weighted least squares estimators,0,"This work studies an experimental design problem where $x$'s are to be selected with the goal of estimating a function $m(x)$, which is observed with noise. A linear model is fitted to $m(x)$ but it is not assumed that the model is correctly specified. It follows that the quantity of interest is the best linear approximation of $m(x)$, which is denoted by $\ell(x)$. It is shown that in this framework the ordinary least squares estimator typically leads to an inconsistent estimation of $\ell(x)$, and rather weighted least squares should be considered. An asymptotic minimax criterion is formulated for this estimator, and a design that minimizes the criterion is constructed. An important feature of this problem is that the $x$'s should be random, rather than fixed. Otherwise, the minimax risk is infinite. It is shown that the optimal random minimax design is different from its deterministic counterpart, which was studied previously, and a simulation study indicates that it generally performs better when $m(x)$ is a quadratic or a cubic function.

Another finding is that when the variance of the noise goes to infinity, the random and deterministic minimax designs coincide. The results are illustrated for polynomial regression models and different generalizations are presented.",210
Optimal minimax random designs for weighted least squares estimators,1,"This paper introduces a novel methodology for constructing optimal minimax random designs for weighted least squares (WLS) estimators. Our approach is based on a weighted criterion that combines both the variance and the bias of the estimator, and allows us to obtain designs that minimize the maximum risk across a range of weighting schemes. Specifically, we use a general class of random designs based on non-negative weighted averages of simpler designs, and we derive a closed-form expression for the weight function that minimizes the criterion. We show that the resulting designs are asymptotically minimax, in the sense that they achieve the optimal rate of convergence for the worst-case risk. We also provide insights into the structure of the optimal designs, and investigate their performance in simulations and real-world examples. Our results demonstrate that our methodology can lead to substantial improvements in the estimation accuracy over existing design methods, particularly in settings where the weighting scheme is unknown or uncertain. Overall, our work contributes to the development of robust and efficient design methods for WLS estimation, with potential applications in various fields such as medicine, engineering, and social sciences.",192
"Ortho-to-para ratio of NH2. Herschel-HIFI observations of ortho- and para-NH2 rotational transitions towards W31C, W49N, W51 and G34.3+0.1",0,"We have used the Herschel-HIFI instrument to observe both nuclear spin symmetries of amidogen (NH2) towards the high-mass star-forming regions W31C (G10.6-0.4), W49N (G43.2-0.1), W51 (G49.5-0.4) and G34.3+0.1. The aim is to investigate the ratio of nuclear spin types, the ortho-to-para ratio (OPR), of NH2. The excited NH2 transitions are used to construct radiative transfer models of the hot cores and surrounding envelopes in order to investigate the excitation and possible emission of the ground state rotational transitions of ortho-NH2 N_(K_a,K_c} J=1_(1,1) 3/2 - 0_(0,0) 1/2 and para-NH2 2_(1,2) 5/2 - 1_(0,1) 3/2$ used in the OPR calculations. Our best estimate of the average OPR in the envelopes lie above the high temperature limit of three for W49N, specifically 3.5 with formal errors of \pm0.1, but for W31C, W51, and G34.3+0.1 we find lower values of 2.5\pm0.1, 2.7\pm0.1, and 2.3\pm0.1, respectively. Such low values are strictly forbidden in thermodynamical equilibrium since the OPR is expected to increase above three at low temperatures. In the translucent interstellar gas towards W31C, where the excitation effects are low, we find similar values between 2.2\pm0.2 and 2.9\pm0.2. In contrast, we find an OPR of 3.4\pm0.1 in the dense and cold filament connected to W51, and also two lower limits of >4.2 and >5.0 in two other translucent gas components towards W31C and W49N. At low temperatures (T \lesssim 50 K) the OPR of H2 is <10^-1, far lower than the terrestrial laboratory normal value of three. In such a ""para-enriched H2"" gas, our astrochemical models can reproduce the variations of the observed OPR, both below and above the thermodynamical equilibrium value, by considering nuclear-spin gas-phase chemistry. The models suggest that values below three arise in regions with temperatures >20-25 K, depending on time, and values above three at lower temperatures.",358
"Ortho-to-para ratio of NH2. Herschel-HIFI observations of ortho- and para-NH2 rotational transitions towards W31C, W49N, W51 and G34.3+0.1",1,"This paper presents spectroscopic observations of the NH2 molecule using the Herschel-HIFI instrument towards four high-mass star-forming regions; namely W31C, W49N, W51 and G34.3+0.1. The ortho-to-para (o/p) ratio of NH2 has long been debated in the astrophysical context, with implications for the temperature and formation history of the gas. The authors used the high spectral resolution of Herschel-HIFI to measure the o/p ratios of NH2 using its rotational transitions with high signal to noise ratio (>30). The observations reveal an o/p ratio of 1.5±0.1 in W31C, 1.3±0.1 in W49N, 1.2±0.1 in W51, which are consistent with previous measurements of the ratio of N2H+ towards these sources. In contrast, a significantly lower o/p ratio of 0.9±0.1 was found in G34.3+0.1. The authors discuss the possible implications of these findings in the context of the astrophysical processes occurring in these high-mass star-forming regions. They note that the measured o/p ratios are suggestive of the presence of warm gas from shocked regions in W31C and W49N. In W51, a possible explanation for the lower than expected o/p ratio may be depletion of NH2 on to dust grains. The low o/p ratio in G34.3+0.1, however, is more challenging to explain within the current understanding of the chemistry and dynamics of high-mass star-forming regions. The authors conclude that the Herschel-HIFI observations of NH2 presented in this work provide new insights into the physical conditions and chemical processes at play in these fascinating and complex astrophysical environments.",280
Bracket map for Heisenberg group and the characterization of cyclic subspaces,0,"The bracket map was originally considered for locally compact abelian groups.

In this work we extend the study of bracket maps to the noncommutative setting, providing characterizations of bases and frames for cyclic subspaces of the Heisenberg group. We also indicate how to generalize these results to a class of non-abelian nilpotent Lie groups whose irreducible representations are square integrable modulo the center.",64
Bracket map for Heisenberg group and the characterization of cyclic subspaces,1,"This paper presents the construction of a bracket map for the Heisenberg group, which plays a central role in the study of geometric quantization. Using this bracket map, we characterize cyclic subspaces of the group's representation space. Our results offer insight into the nature of Heisenberg's uncertainty principle and have important implications for the theory of operator algebras and noncommutative geometry.",63
On generalized forces in higher derivative Lagrangian theory,0,"In this article, we introduce higher derivative Lagrangians of this form $\alpha_1 A_{\mu}(x)\dot{x}^\mu$, $\alpha_2 G_{\mu}(x)\ddot{x}^\mu$, $\alpha_3 B_{\mu}(x)\dddot{x}^\mu$, $\alpha_4 K_{\mu}(x)\ddddot{x}^\mu$, $\cdots$, that generalize the electromagnetic interaction to higher order derivatives. We show that odd order Lagrangians describe interactions analog to electromagnetism while even order Lagrangians are similar to gravitational interaction. From this analogy, we formulate the concept of the generalized induction principle assuming the coupling between the higher fields $U_{(n),\mu}(x),\ n\geq1$ and the higher currents $j^{(n)\mu}=\rho(x)d^nx^{\mu}/ds^n$, where $\rho(x)$ is the spatial density of mass ($n$ even) or of electric charge ($n$ odd). In short, this article is an invitation to reflect on a generalization of the concept of force and of inertia. We discuss the implications of these paradigms more in depth in the last section of the paper.",162
On generalized forces in higher derivative Lagrangian theory,1,"This paper investigates generalized forces in higher derivative Lagrangian theory. We consider a wide class of Lagrangians with higher derivatives and perform a covariant analysis of the associated equations of motion. In particular, we derive expressions for the generalized forces, which are necessary to describe the dynamics of the system under consideration. We show that these forces offer a more comprehensive understanding of the system's behavior than traditional notions of force, such as the gradient of the potential energy. Moreover, we demonstrate that the presence of higher derivatives allows for a rich variety of physical phenomena, which cannot be captured in theories with only first or second derivatives. Our findings have implications for a broad range of fields, including classical mechanics and quantum field theory, and point towards new directions for future research.",134
On the set of local extrema of a subanalytic function,0,"Let ${\mathfrak F}$ be a category of subanalytic subsets of real analytic manifolds that is closed under basic set-theoretical and basic topological operations. Let $M$ be a real analytic manifold and denote ${\mathfrak F}(M)$ the family of the subsets of $M$ that belong to ${\mathfrak F}$. Let $f:X\to{\mathbb R}$ be a subanalytic function on a subset $X\in{\mathfrak F}(M)$ such that the inverse image under $f$ of each interval of ${\mathbb R}$ belongs to ${\mathfrak F}(M)$. Let ${\rm Max}(f)$ be the set of local maxima of $f$ and consider ${\rm Max}_\lambda(f):={\rm Max}(f)\cap\{f=\lambda\}$ for each $\lambda\in{\mathbb R}$. If $f$ is continuous, then ${\rm Max}(f)=\bigsqcup_{\lambda\in{\mathbb R}}{\rm Max}_\lambda(f)\in{\mathfrak F}(M)$ if and only if the family $\{{\rm Max}_\lambda(f)\}_{\lambda\in{\mathbb R}}$ is locally finite in $M$. If we erase continuity condition, there exist subanalytic functions $f:X\to M$ such that ${\rm Max}(f)\in{\mathfrak F}(M)$, but the family $\{{\rm Max}_\lambda(f)\}_{\lambda\in{\mathbb R}}$ is not locally finite in $M$ or such that ${\rm Max}(f)$ is connected but it is not even subanalytic. If ${\mathfrak F}$ is the category of subanalytic sets and $f:X\to{\mathbb R}$ is a subanalytic map $f$ that maps relatively compact subsets of $M$ contained in $X$ to bounded subsets of ${\mathbb R}$, then ${\rm Max}(f)\in{\mathfrak F}(M)$ and the family $\{{\rm Max}_\lambda(f)\}_{\lambda\in{\mathbb R}}$ is locally finite in $M$. If the category ${\mathfrak F}$ contains the intersections of algebraic sets with real analytic submanifolds and $X\in{\mathfrak F}(M)$ is not closed in $M$, there exists a continuous subanalytic function $f:X\to{\mathbb R}$ with graph belonging to ${\mathfrak F}(M\times{\mathbb R})$ such that inverse images under $f$ of the intervals of ${\mathbb R}$ belong to ${\mathfrak F}(M)$ but ${\rm Max}(f)$ does not belong to ${\mathfrak F}(M)$.",350
On the set of local extrema of a subanalytic function,1,"In the field of mathematical analysis, the study of local extrema of subanalytic functions is an important and challenging area of research. In this paper, we present a comprehensive investigation of the set of local extrema of a subanalytic function.

Our focus on subanalytic functions is motivated by their importance in mathematical analysis, especially in geometry and topology. They provide a natural and flexible framework for studying singularities of analytic functions and provide a basis for the development of various mathematical theories. Our work expands the existing literature on subanalytic functions and their local extrema by investigating the properties of these extrema in a more general setting.

We begin by establishing the basic properties of subanalytic functions and their local extrema. We then proceed to investigate the behavior of these extrema under various transformations, such as scaling, translation, and rotation. Our results show that the set of local extrema is invariant under these transformations, which has important implications for the study of subanalytic functions.

Next, we focus on the relationship between the set of local extrema and the singularities of a subanalytic function. We show that the local extrema can be used to characterize certain types of singularities and obtain new results on the strata of singularities of subanalytic functions.

Finally, we explore some applications of our results to other areas of mathematics, such as geometric topology and algebraic geometry. Our investigations provide new insights into the structure of the set of local extrema of a subanalytic function, which can be used to derive new results and advance the field of mathematical analysis.

In conclusion, our work contributes to the extensive body of research on subanalytic functions and their local extrema. Our investigations establish new results and contribute to a more comprehensive understanding of the mathematical properties of these functions. We believe our work will be of interest to mathematicians working in various areas of mathematical analysis, as well as to researchers in other fields who employ subanalytic functions in their work.",332
Supersymmetric SYK models,0,"We discuss a supersymmetric generalization of the Sachdev-Ye-Kitaev model.

These are quantum mechanical models involving $N$ Majorana fermions. The supercharge is given by a polynomial expression in terms of the Majorana fermions with random coefficients. The Hamiltonian is the square of the supercharge. The ${\cal N}=1$ model with a single supercharge has unbroken supersymmetry at large $N$, but non-perturbatively spontaneously broken supersymmetry in the exact theory. We analyze the model by looking at the large $N$ equation, and also by performing numerical computations for small values of $N$. We also compute the large $N$ spectrum of ""singlet"" operators, where we find a structure qualitatively similar to the ordinary SYK model. We also discuss an ${\cal N}=2$ version. In this case, the model preserves supersymmetry in the exact theory and we can compute a suitably weighted Witten index to count the number of ground states, which agrees with the large $N$ computation of the entropy. In both cases, we discuss the supersymmetric generalizations of the Schwarzian action which give the dominant effects at low energies.",179
Supersymmetric SYK models,1,"Supersymmetric Sachdev-Ye-Kitaev (SYK) models have been objects of great interest in recent years, due to their numerous intriguing properties and potential applications in various areas of physics. These models are characterized by a peculiar duality between fermionic and bosonic degrees of freedom, originating from their supersymmetric nature. In particular, they possess a non-Fermi liquid behavior and a chaotic dynamics at low energies. In this work, we aim to explore some of the main features of supersymmetric SYK models, focusing on their holographic interpretation, which relates them to gravity theories in higher dimensions. Our analysis is carried out both numerically and analytically, using advanced tools from quantum field theory and statistical mechanics. We provide evidence for the existence of a non-trivial phase structure, including a quantum critical point and an intriguing ""ferromagnetic"" phase. Our results shed new light on the rich physics underlying supersymmetric SYK models, and their potential relevance for understanding fundamental aspects of many-body systems.",161
ISO measurements of [CII] line variations in galaxies,0,"We report measurements of the [CII] fine structure line at 157.714 micron in 30 normal star-forming galaxies with the Long Wavelength Spectrometer (LWS) on the Infrared Space Observatory (ISO). The ratio of the line to total far-infrared luminosity, [CII]/FIR, measures the ratio of the cooling of gas to that of dust; and thus the efficiency of the grain photoelectric heating process. This ratio varies by a factor of 40 in the current sample. About two-thirds of the galaxies have [CII]/FIR = 2-7 x 10^{-3}. The other one-third show trends of decreasing [CII]/FIR with increasing dust temperature, indicated by the ratio of infrared emission at 60 and 100 microns; and with increasing star-formation activity, measured by the ratio of far-infrared and blue band luminosity. We find three FIR bright galaxies with undetected [CII] line at 3-sigma upper limits of [CII]/FIR < 0.5-2 x 10^{-4}. The trend in the [CII]/FIR ratio with the temperature of dust and with star-formation activity may be due to decreased efficiency of photoelectric heating of gas at high UV radiation intensity as dust grains become positively charged, decreasing the yield and the energy of the photoelectrons. The three galaxies with no observed PDR lines have among the highest ratios of FIR to Blue luminosity and the ratio of 60 and 100 micron emission. Their lack of [CII] lines may be due to a continuing trend of decreasing [CII]/FIR with increasing star-formation activity and dust temperature seen in one-third of the sample with warm IRAS colors. In that case the upper limits on [CII]/FIR imply a ratio of UV flux to gas density G_0/n > 10 cm$^3. The low [CII]/FIR could also be due to either weak [CII] because of self-absorption or strong FIR continuum from regions weak in [CII], such as dense HII regions or plasma ionized by hard radiation of AGNs.",329
ISO measurements of [CII] line variations in galaxies,1,"This paper presents the results of measurements of the [CII] line variations in galaxies using the ISO satellite. The [CII] line is one of the most important cooling lines in the interstellar medium, and its emission can be used as a tracer of the physical and chemical conditions of the gas in galaxies. The ISO satellite, which operated from 1995 to 1998, provided high spectral resolution observations of the [CII] line in a large sample of galaxies.

We analyzed the spectra of the [CII] line in a sample of 50 galaxies at redshifts between 0.01 and 0.2. We found that the [CII] line intensity varies greatly from galaxy to galaxy, with some galaxies showing very strong emission and others very weak emission. We also found that the [CII] line intensity is correlated with other properties of the galaxies, such as their star formation rates, metallicities, and gas densities.

We used the [CII] line to estimate the total amount of gas in the galaxies and compared this to estimates based on other gas tracers, such as CO. We found that in some galaxies the [CII] line provides a more reliable estimate of the gas mass than CO, especially in low-metallicity environments where the CO emission may be suppressed.

Our results have important implications for our understanding of galaxy evolution and the role of gas in driving star formation. By measuring the [CII] line variations in a large sample of galaxies, we can better constrain the physical and chemical conditions of the interstellar medium, and test models of galaxy formation and evolution. The ISO measurements of the [CII] line in galaxies represent a significant step forward in our understanding of the cooling and heating processes of the gas in galaxies, and their role in shaping the properties of the galaxies we see today.",304
Periodic structure of memory function in spintronics reservoir with feedback current,0,"The role of the feedback effect on physical reservoir computing is studied theoretically by solving the vortex-core dynamics in a nanostructured ferromagnet. Although the spin-transfer torque due to the feedback current makes the vortex dynamics complex, it is clarified that the feedback effect does not always contribute to the enhancement of the memory function in a physical reservoir. The memory function, characterized by the correlation coefficient between the input data and the dynamical response of the vortex core, becomes large when the delay time of the feedback current is not an integral multiple of the pulse width. On the other hand, the memory function remains small when the delay time is an integral multiple of the pulse width.

As a result, a periodic behavior for the short-term memory capacity is observed with respect to the delay time, the phenomenon of which can be attributed to correlations between the virtual neurons via the feedback current.",157
Periodic structure of memory function in spintronics reservoir with feedback current,1,"The memory function of spintronics reservoir with a feedback current exhibits a periodic structure, a phenomenon which has been investigated in this study. Theoretical models and numerical simulations have been employed to examine the periodicity and its properties. The results reveal that the periodicity of the memory function is dependent on the strength of the feedback current, with behavioral differences being observed between weak and strong feedback cases. Moreover, the structure of the periodicity, which includes multiple harmonics, has also been found to be influenced by the feedback current. This study thus provides important insights into the understanding of spintronics reservoir with a feedback current and its potential applications in memory and computing. Additionally, it opens a new direction for future research to explore the system's behavior under different settings, such as temperature and external magnetic fields.",138
Drift mode accelerometry for spaceborne gravity measurements,0,"A drift mode accelerometer is a precision device that overcomes the much of the acceleration noise and readout dynamic range limitations of traditional electrostatic accelerometers. It has the potential of achieving acceleration noise performance of drag-free systems over a restricted frequency band without the need for external drag-free control or spacecraft propulsion. Like traditional accelerometers, the drift mode accelerometer contains a high-density test mass surrounded by an electrode housing, which can control and sense all six degrees of freedom of the test mass. Unlike traditional accelerometers, the suspension system is operated with a low duty cycle so that the limiting suspension force noise only acts over brief, known time intervals, which can be neglected in the data analysis. The readout is performed using a laser interferometer which is immune to the dynamic range limitations of even the best voltage references typically used to determine the inertial acceleration of electrostatic accelerometers. The drift mode accelerometer is related to the like-named operational mode of the LISA Pathfinder spacecraft, which will be used to estimate the acceleration noise associated with the LISA Pathfinder front end electronics. This paper describes operation of such a device, develops models for its performance with respect to satellite geodesy and gravitational wave astrophysics applications, and discusses methods for testing its performance using torsion pendula in the laboratory and the LISA Pathfinder mission in space.",230
Drift mode accelerometry for spaceborne gravity measurements,1,"This research paper presents a novel method to improve spaceborne gravity measurements using drift mode accelerometry. Traditional accelerometer-based gravity measurements are prone to measurement noise, which leads to reduced accuracy in determining gravity field parameters. Drift mode accelerometry, on the other hand, uses a free-falling mass that oscillates in a controlled manner, allowing for more precise measurements. This paper demonstrates the success of this technique by analyzing data acquired by the European Space Agency's GOCE satellite.

The drift mode accelerometry method presented in this paper involves generating a controlled oscillation of a freely falling mass within the GOCE spacecraft. This technique effectively separates the measurement of gravity from other sources of acceleration, such as spacecraft motion or atmospheric drag. By analyzing the resulting data, researchers were able to quantify the effect of the Earth's gravity field on the GOCE spacecraft.

The data showed that the measured acceleration of the freely-falling mass was highly correlated to the gravity field strength and allowed for precise measurement of gravity-related parameters such as the geoid height. Using this technique, researchers achieved unprecedented accuracy in spaceborne gravity measurements. In addition, this method has the potential to improve future space missions that require accurate measurements of gravitational forces.

Overall, this paper demonstrates the effectiveness of drift mode accelerometry for spaceborne gravity measurements. The results have significant implications for understanding the Earth's gravity field and for future space-based applications, such as mapping, geodesy, and geophysics.",246
New Compactifications of Supergravities and Large N QCD,0,"We construct supergravity backgrounds representing non-homogeneous compactifications of d=10,11 supergravities to four dimensions, which cannot be written as a direct product. The geometries are regular and approach $AdS_7\times S^4$ or $AdS_5\times S^5$ at infinity; they are generically non-supersymmetric, except in a certain ""extremal"" limit, where a Bogomol'nyi bound is saturated and a naked singularity appears. By using these spaces, one can construct a model of QCD that generalizes by one (or two) extra parameters a recently proposed model of QCD based on the non-extremal D4 brane. This allows for some extra freedom to circumvent some (but not all) limitations of the simplest version.",113
New Compactifications of Supergravities and Large N QCD,1,"In this paper, we explore the potential of utilizing new compactification techniques to study both supergravity theories and large N Quantum Chromodynamics (QCD). The compactification schemes in question generalize previous approaches and feature novel geometric structures, which allow for the study of these theories and their relationship in previously unexplored ways. We demonstrate the utility of these compactification methods by exploring the properties of a specific example. Our results indicate that these new techniques can provide significant insights into the behavior of supergravities and QCD, and may even help to bridge the gap between the two.",96