{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguilin1/tda_ai_text_generation/blob/main/tda_ai_text_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aguilin1/tda_ai_text_generation.git"
      ],
      "metadata": {
        "id": "rNoNDVYHKGF_",
        "outputId": "aabb0ee4-248f-45a3-f19b-1749ae7ab04c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tda_ai_text_generation'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 27 (delta 13), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (27/27), 110.76 KiB | 852.00 KiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RnbbJceiiAO3",
        "outputId": "d6de478c-7f5b-44cc-d640-f62300c987bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements. The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances. However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood. Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field. Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields. We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes. Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation. Finally, we use numerical simulations to confirm the validity of our experimental results. Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.',\n",
              " 'In this paper, we investigate Weighted Solyanik Estimates for the Strong Maximal Function. The purpose of this study is to determine the optimal range of weights for which the Solyanik estimates hold true for the strong maximal function in both dyadic and non-dyadic contexts. Our work is motivated by recent developments in the area of harmonic analysis and Fourier analysis, which have demonstrated the importance of the strong maximal function in many areas of mathematics. We begin our investigation by defining the strong maximal function and introducing the weighted Solyanik estimates. We then analyze the properties of the strong maximal function and its relationship to weighted estimates. Our findings demonstrate that the range of suitable weights for the Solyanik estimates is significantly larger in the dyadic context than in the non-dyadic context. Moreover, we establish new estimates for the strong maximal function in the dyadic context, which improve upon existing results. Our study contributes to the development of more precise and accurate techniques for analyzing the strong maximal function, and may have potential applications in other areas of mathematics as well. In conclusion, our investigation of Weighted Solyanik Estimates for the Strong Maximal Function provides new insights into this important topic in harmonic analysis, and we expect our results to be of interest to researchers in this field and related areas of study.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "DATA_FILE = '/content/tda_ai_text_generation/research-abstracts-labeled-first-100.csv'\n",
        "\n",
        "human_texts = []\n",
        "ai_texts = []\n",
        "with open(DATA_FILE) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    next(csv_reader, None) # Skip header row\n",
        "    for row in csv_reader:\n",
        "      if row[1] == '0':\n",
        "        human_texts.append(row[2])\n",
        "      else:\n",
        "        ai_texts.append(row[2])\n",
        "# Print first 2 rows to sanity check\n",
        "ai_texts[:2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "x88OSoqsKghJ",
        "outputId": "9872a99c-4245-4013-d316-344e53aba91d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "text = ai_texts[0]\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "proceesed_sentences = []\n",
        "for sentence in sentences:\n",
        "  # Uncomment to remve punctuation if not doing sentence-level transform\n",
        "  sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  filtered_text = []\n",
        "\n",
        "  for word in word_tokenize(sentence):\n",
        "    if word not in stop_words:\n",
        "      filtered_text.append(wnl.lemmatize(word, pos=\"v\").lower())\n",
        "\n",
        "  post_filtered_text = ' '.join(filtered_text)\n",
        "  proceesed_sentences.append(post_filtered_text)\n",
        "\n",
        "proceesed_sentences"
      ],
      "metadata": {
        "id": "UuzdYItZKcti",
        "outputId": "f90828ea-1fa2-41f7-9395-1c5b5885939b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in study investigate couple loss bicolumnar bsccoag tap use ac susceptibility measurements',\n",
              " 'the bicolumnar structure bscco tap know offer several advantage traditional tape configurations include increase tolerance magnetic field disturbances',\n",
              " 'however effect bi2212ag interface couple superconducting filaments bscco tape well understand',\n",
              " 'our experiment show couple loss dominate bi2212ag interface vary significantly orientation magnitude apply ac magnetic field',\n",
              " 'specifically couple loss find lower inplane magnetic field higher outofplane magnetic field',\n",
              " 'we also observe anneal tap significantly affect couple loss anneal tap exhibit lower loss value unannealed tap',\n",
              " 'furthermore find couple loss sensitive orientation ag matrix demonstrate measurements tap transverse longitudinal matrix orientation',\n",
              " 'finally use numerical simulations confirm validity experimental result',\n",
              " 'overall study provide important insights couple loss mechanisms bicolumnar bsccoag tap highly relevant development practical applications hightemperature superconductors']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "embeddings = vectorizer.fit_transform(proceesed_sentences)\n",
        "print(embeddings.toarray())"
      ],
      "metadata": {
        "id": "vbRKh5J0Ky98",
        "outputId": "8f799e24-8a55-44f7-fdc9-570631177d0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            "  0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
            "  0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
            "  0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1\n",
            "  1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
            "  0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            "  1 0 0 0 0 0 1 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 1 0 1 0 0 0 0 0 0 0\n",
            "  1 0 0 0 0 0 1 1 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 1 2 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 2 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3\n",
            "  0 0 0 0 0 1 0 0 0 1 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 1 1 0 0 0 2 1 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
            "  0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
            "  0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import itertools\n",
        "\n",
        "# Label each sentence starting at 0, 1, 2, ...\n",
        "# Track distances as ((sentence 1, sentence 2), distance)\n",
        "distances = []\n",
        "for pair1_i, pair2_i in itertools.combinations(range(len(sentences)), 2):\n",
        "    cos_sim = cosine_similarity(embeddings[pair1_i], embeddings[pair2_i])[0][0]\n",
        "    dist = 2 * np.arccos(cos_sim) / np.pi\n",
        "    distances.append(((pair1_i, pair2_i), dist))\n",
        "\n",
        "for distance in distances:\n",
        "  print(\"Distance {} from [{}] to [{}]\".format(distance[1], sentences[distance[0][0]], sentences[distance[0][1]]))\n"
      ],
      "metadata": {
        "id": "qxTxwgOQLgso",
        "outputId": "e1cd4fb7-864a-4e43-9971-4e476eda23e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance 0.9130973832611151 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.]\n",
            "Distance 0.9445191586266647 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.]\n",
            "Distance 0.8610675931406382 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.]\n",
            "Distance 0.9077897659118525 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.]\n",
            "Distance 0.7836531040612146 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.]\n",
            "Distance 0.8293178290029904 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 0.9349119311394868 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.7322795271987699 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.9092073382602321 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.]\n",
            "Distance 0.9247988736812159 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.]\n",
            "Distance 0.8485219752737067 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.]\n",
            "Distance 0.9130973832611151 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.]\n",
            "Distance 0.9655587471065536 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 1.0 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.9291181087950799 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.8547828724160569 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.]\n",
            "Distance 0.9519674202754774 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.]\n",
            "Distance 0.9630388128688534 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.]\n",
            "Distance 0.9559288973655782 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 1.0 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.9547192330207546 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.7552854129217539 from [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.] to [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.]\n",
            "Distance 0.8767132968540401 from [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.] to [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.]\n",
            "Distance 0.8526369332410573 from [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 1.0 from [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.9247988736812159 from [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.8767132968540401 from [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.] to [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.]\n",
            "Distance 0.8899142424972396 from [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 1.0 from [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.9247988736812159 from [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.8293178290029904 from [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 1.0 from [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.8245203439081782 from [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 1.0 from [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.896268232977734 from [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 1.0 from [Finally, we use numerical simulations to confirm the validity of our experimental results.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This section generates and reformats the cosine similarity distances between\n",
        "# each pair of points and generates an array of all possible threshold values\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "n = len(embeddings.toarray()) # Number of data points\n",
        "cosSimDistances = np.zeros((n, n)) # preallocate pairwise distance matrix\n",
        "\n",
        "# Label each sentence starting at 0, 1, 2, ...\n",
        "# Track distance between sentence i and sentence j in (i,j) entry of matrix\n",
        "# Matrix will be upper triangular\n",
        "for pair1_i, pair2_i in itertools.combinations(range(len(sentences)), 2):\n",
        "    cos_sim = cosine_similarity(embeddings[pair1_i], embeddings[pair2_i])[0][0]\n",
        "    dist = 2 * np.arccos(cos_sim) / np.pi\n",
        "    cosSimDistances[pair1_i][pair2_i] = dist\n",
        "#print(cosSimDistances)\n",
        "thresholds = np.sort(np.unique(cosSimDistances))\n",
        "#print(thresholds)"
      ],
      "metadata": {
        "id": "_mJJSjn9kAmm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Helpers functions NOT based on publication\n",
        "\n",
        "# to find all the unique lists in a large list of lists\n",
        "def union_lists(lists):\n",
        "    # Convert each list to a tuple and package as a set\n",
        "    # (which automatically is unique)\n",
        "    unique_tuples = {tuple(a_list) for a_list in lists}\n",
        "    # Convert the tuples back to lists\n",
        "    unique_arrays = [list(t) for t in unique_tuples]\n",
        "    return unique_arrays"
      ],
      "metadata": {
        "id": "ZwV27MJbpkC-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Helper functions based on publication\n",
        "# The functions in this section are tailored implementations of algorithms\n",
        "# found in the following paper:\n",
        "\n",
        "# Zomorodian, A. (2010). Fast construction of the Vietoris-Rips complex.\n",
        "# Computers & Graphics, 34(3), 263–271.\n",
        "# https://doi.org/https://doi.org/10.1016/j.cag.2010.03.007\n",
        "\n",
        "# refer to: Article Section 4.2\n",
        "# inputs: both C0 and C1 from complex K, max dimension (3 = tetrahedra)\n",
        "def RipsComplex(K_C0, K_C1, k):\n",
        "  nu = [] # this will be expanded to hold all the simplices of all sizes\n",
        "  for i in range(len(K_C0)): # for each vertex in C0\n",
        "    # find the other, lower ordered vertices that have an edge connecting them\n",
        "    # to this vertex\n",
        "    [i_N, N] = LowerPairVertices(K_C0, K_C1, i)\n",
        "    # build all the cofaces\n",
        "    nu = AddCofaces(K_C0, K_C1, k, K_C0[i], i_N, N, nu)\n",
        "  return nu\n",
        "\n",
        "# refer to: Article Section 4.2\n",
        "# inputs: complex K (C0 and C1), max dimension (3 = tetrahedra), set\n",
        "# containing a vertex, set containing lower points paired with that vector,\n",
        "# and current built-up V-R complex\n",
        "def AddCofaces(K_C0, K_C1, k, tau, i_N, N, nu):\n",
        "  nu = union_lists(nu + [tau])\n",
        "  if len(tau) < k:  # if dim(tau) >= k (has k+1 or more points)\n",
        "    for i in range(len(N)):\n",
        "      sigma = N[i] + tau # element to be added to nu\n",
        "      [i_M, M] = LowerPairVertices(K_C0, K_C1, i_N[i])\n",
        "      M = N and M # intersection means triangle\n",
        "      nu = AddCofaces(K_C0, K_C1, k, sigma, i_M, M, nu)\n",
        "  return nu\n",
        "\n",
        "# refer to: Article Section 4.1\n",
        "# inputs: both C0 and C1 of complex K, index of the vertex for which to find\n",
        "# lower ordered points that are paired by an edge.\n",
        "def LowerPairVertices(K_C0, K_C1, i_u):\n",
        "  # get indices i_N of lower vertices paired with vertex u, which has index i_u\n",
        "  i_N = np.nonzero(K_C1[0:i_u,i_u])[0]\n",
        "  # get the set N of lower vertices v paired with vertex u\n",
        "  N = list(K_C0[i] for i in i_N)\n",
        "  return [i_N, N]"
      ],
      "metadata": {
        "id": "_1JSYehlN0RE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Driver\n",
        "from scipy.special import comb # for comb() (i.e. \"nChooseK\")\n",
        "\n",
        "# set max dimension to compute\n",
        "K_C0 = []\n",
        "for i in range(n):\n",
        "  K_C0.append([i])\n",
        "\n",
        "dims = 2 # 0 - points, 1 - edges, 2 - triangles, 3 - tetrahedra, etc.\n",
        "nPts = len(K_C0)\n",
        "# compute the total number of things that will be in the complex at the max\n",
        "# threshold, based on the selected # of dimensions\n",
        "totalSizeNu = nPts # the points will always be in the complex\n",
        "\n",
        "# compute the total # of simplices that will exist at the max threshold\n",
        "for i in range(dims):\n",
        "  # add # of ith dimension entries in the complex at max threshold\n",
        "  totalSizeNu = totalSizeNu + comb(nPts, i+1, exact=True)\n",
        "\n",
        "# preallocate big boundary matrix and an array to track the index of the\n",
        "# simplex in the full complex (and row in the boundary matrix)\n",
        "# corresponding to each column in the boundary matrix. Assume the boundary\n",
        "# matrix will have half as many columns as the number of simplices due to\n",
        "# removal of zero columns during each iteration\n",
        "boundaryMatrix = np.zeros((totalSizeNu, round(totalSizeNu/2)), dtype=bool)\n",
        "nuColIndexFromBoundColIndex = np.zeros(round(totalSizeNu/2), dtype=np.int32)\n",
        "w_bd = 0 # zero boundary matrix columns originally filled in\n",
        "# preallocate last iteration complex and reset to correct data type\n",
        "nu_prev = [None] * totalSizeNu\n",
        "# track number of actual items set in nu_prev\n",
        "L_prev = 0\n",
        "# preallocate epoch and dimension trackers to -1 for error checking later\n",
        "# birthEpoch = -1*ones(1,totalSizeNu,'int16')\n",
        "birthEpoch = -1*np.ones(totalSizeNu, dtype=np.int16)\n",
        "deathEpoch = -1*np.ones(totalSizeNu,dtype=np.int16)\n",
        "dimension = -1*np.ones(totalSizeNu,dtype=np.int8)\n",
        "# preallocate full complex buildup and reset to correct data type\n",
        "epochOrderedComplex = [None] * totalSizeNu\n",
        "\n",
        "# iterate through each threshold value, building up birthEpoch, deathEpoch,\n",
        "# and dimension arrays corresponding to the epochOrderedComplex and\n",
        "# allHomologies arrays. The reduced boundary matrix will also be an\n",
        "# output at each iteration\n",
        "for epoch in range(len(thresholds)):\n",
        "  # first determine which edges are in the complex based on threshold\n",
        "  K_C1 = cosSimDistances <= thresholds[epoch] # logical array of \"in\" edges\n",
        "  # compute the complex as a huge array of dot-delimited strings\n",
        "  nu = RipsComplex(K_C0, K_C1, dims)\n",
        "  print(epoch)\n",
        "  print(K_C1)\n",
        "  print(nu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXqPvSyKHRg2",
        "outputId": "1b91eb51-34b1-4c09-bc45-04f293f8840d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[[ True False False False False False False False False]\n",
            " [ True  True False False False False False False False]\n",
            " [ True  True  True False False False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[6], [2], [5], [8], [4], [1], [7], [0], [3]]\n",
            "1\n",
            "[[ True False False False False False False False  True]\n",
            " [ True  True False False False False False False False]\n",
            " [ True  True  True False False False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[6], [2], [5], [8], [4], [1], [7], [0], [0, 8], [3]]\n",
            "2\n",
            "[[ True False False False False False False False  True]\n",
            " [ True  True False False False False False False False]\n",
            " [ True  True  True False False False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[6], [2], [3, 4], [5], [8], [4], [1], [7], [0], [0, 8], [3]]\n",
            "3\n",
            "[[ True False False False False  True False False  True]\n",
            " [ True  True False False False False False False False]\n",
            " [ True  True  True False False False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[6], [2], [3, 4], [5], [8], [4], [1], [7], [0, 5], [0], [0, 8], [3]]\n",
            "4\n",
            "[[ True False False False False  True False False  True]\n",
            " [ True  True False False False False False False False]\n",
            " [ True  True  True False False False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True False False  True]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[6], [2], [3, 4], [5], [5, 8], [8], [4], [1], [7], [0, 5], [0], [0, 8], [3]]\n",
            "5\n",
            "[[ True False False False False  True  True False  True]\n",
            " [ True  True False False False False False False False]\n",
            " [ True  True  True False False False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[6], [2], [3, 4], [5], [5, 8], [8], [4], [0, 6], [1], [7], [5, 6], [0, 5], [0], [0, 8], [3]]\n",
            "6\n",
            "[[ True False False False False  True  True False  True]\n",
            " [ True  True False False  True False False False False]\n",
            " [ True  True  True False False False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[6], [2], [3, 4], [5], [5, 8], [8], [4], [1, 4], [0, 6], [1], [7], [5, 6], [0, 5], [0], [0, 8], [3]]\n",
            "7\n",
            "[[ True False False False False  True  True False  True]\n",
            " [ True  True False False  True False False False False]\n",
            " [ True  True  True False False False False False False]\n",
            " [ True  True  True  True  True False  True False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[6], [2], [3, 4], [5], [5, 8], [8], [4], [1, 4], [0, 6], [1], [7], [5, 6], [0, 5], [3, 6], [0], [0, 8], [3]]\n",
            "8\n",
            "[[ True False False False False  True  True False  True]\n",
            " [ True  True False False  True False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True False  True False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[6], [2], [3, 4], [5], [5, 8], [8], [4], [1, 4], [2, 3], [1], [0, 6], [7], [5, 6], [0, 5], [3, 6], [0], [0, 8], [3]]\n",
            "9\n",
            "[[ True False False  True False  True  True False  True]\n",
            " [ True  True False False  True False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True False  True False False]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [8], [0, 5], [0, 8], [4], [1], [7], [5, 6], [3, 6], [0], [3], [6], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "10\n",
            "[[ True False False  True False  True  True False  True]\n",
            " [ True  True False False  True False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [8], [0, 5], [0, 8], [4], [1], [4, 5], [7], [5, 6], [3, 6], [0], [3], [3, 5], [6], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "11\n",
            "[[ True False False  True False  True  True False  True]\n",
            " [ True  True False False  True False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 5], [0, 8], [4], [1], [4, 5], [7], [5, 6], [3, 6], [0], [3], [3, 5], [6], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "12\n",
            "[[ True False False  True False  True  True False  True]\n",
            " [ True  True False False  True False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 5], [0, 8], [6, 8], [4], [1], [4, 5], [7], [5, 6], [3, 6], [0], [3], [3, 5], [6], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "13\n",
            "[[ True False False  True  True  True  True False  True]\n",
            " [ True  True False False  True False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 5], [0, 8], [6, 8], [4], [1], [4, 5], [7], [5, 6], [3, 6], [0, 4], [0], [3], [3, 5], [6], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "14\n",
            "[[ True False False  True  True  True  True False  True]\n",
            " [ True  True  True False  True False False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 5], [0, 8], [6, 8], [4], [1], [4, 5], [7], [5, 6], [3, 6], [1, 2], [0, 4], [0], [3], [3, 5], [6], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "15\n",
            "[[ True  True False  True  True  True  True False  True]\n",
            " [ True  True  True False  True  True False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 5], [0, 8], [6, 8], [4], [1], [4, 5], [7], [5, 6], [3, 6], [0, 1], [1, 2], [0, 4], [1, 5], [0], [3], [3, 5], [6], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "16\n",
            "[[ True  True False  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True False False False]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 5], [0, 8], [1, 3], [6, 8], [4], [1], [4, 5], [7], [5, 6], [4, 8], [3, 6], [0, 1], [1, 2], [0, 4], [1, 5], [0], [3], [3, 5], [6], [3, 8], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "17\n",
            "[[ True  True False  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True False False  True]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 5], [0, 8], [1, 3], [6, 8], [4], [1], [4, 5], [7], [5, 6], [4, 8], [3, 6], [0, 1], [1, 2], [0, 4], [1, 5], [1, 8], [0], [3], [3, 5], [6], [3, 8], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "18\n",
            "[[ True  True False  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False False  True]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 5], [0, 8], [1, 3], [6, 8], [4], [1], [4, 5], [7], [5, 6], [4, 8], [3, 6], [0, 1], [0, 7], [1, 2], [0, 4], [1, 5], [1, 8], [0], [3], [3, 5], [6], [3, 8], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "19\n",
            "[[ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False False  True]\n",
            " [ True  True  True  True False False False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 2], [0, 5], [0, 8], [1, 3], [6, 8], [4], [1], [4, 5], [7], [5, 6], [4, 8], [3, 6], [0, 1], [0, 7], [1, 2], [0, 4], [1, 5], [1, 8], [0], [3], [3, 5], [6], [3, 8], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "20\n",
            "[[ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False False  True]\n",
            " [ True  True  True  True  True False False False False]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 2], [0, 5], [0, 8], [1, 3], [6, 8], [4], [1], [4, 5], [7], [5, 6], [4, 8], [3, 6], [0, 1], [0, 7], [2, 4], [1, 2], [0, 4], [1, 5], [1, 8], [0], [3], [3, 5], [6], [3, 8], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "21\n",
            "[[ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False False  True]\n",
            " [ True  True  True  True  True False False False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 2], [0, 5], [0, 8], [1, 3], [2, 8], [6, 8], [4], [1], [4, 5], [7], [5, 6], [4, 8], [3, 6], [0, 1], [0, 7], [2, 4], [1, 2], [0, 4], [1, 5], [1, 8], [0], [3], [3, 5], [6], [3, 8], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3]]\n",
            "22\n",
            "[[ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False False  True]\n",
            " [ True  True  True  True  True False  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 2], [0, 5], [0, 8], [1, 3], [2, 8], [6, 8], [4], [1], [4, 5], [7], [5, 6], [4, 8], [3, 6], [0, 1], [0, 7], [2, 4], [1, 2], [0, 4], [1, 5], [1, 8], [0], [3], [3, 5], [6], [3, 8], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3], [2, 6]]\n",
            "23\n",
            "[[ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 2], [0, 5], [0, 8], [2, 5], [1, 3], [2, 8], [6, 8], [4], [1], [4, 5], [7], [5, 6], [4, 8], [3, 6], [0, 1], [0, 7], [2, 4], [1, 2], [0, 4], [1, 5], [1, 8], [0], [3], [3, 5], [6], [3, 8], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3], [2, 6]]\n",
            "24\n",
            "[[ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True False  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [4, 6], [8], [0, 2], [0, 5], [1, 6], [0, 8], [2, 5], [1, 3], [2, 8], [6, 8], [4], [1], [4, 5], [7], [5, 6], [4, 8], [3, 6], [0, 1], [0, 7], [2, 4], [1, 2], [0, 4], [1, 5], [1, 8], [0], [3], [3, 5], [6], [3, 8], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3], [2, 6]]\n",
            "25\n",
            "[[ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[2], [3, 4], [5], [3, 7], [4, 6], [8], [5, 7], [0, 2], [0, 5], [1, 6], [0, 8], [2, 5], [1, 3], [2, 8], [6, 8], [4], [1], [4, 5], [7], [5, 6], [4, 8], [3, 6], [0, 1], [0, 7], [2, 4], [1, 2], [0, 4], [2, 7], [1, 5], [1, 8], [6, 7], [0], [3], [4, 7], [3, 5], [6], [3, 8], [5, 8], [0, 3], [1, 4], [0, 6], [2, 3], [1, 7], [2, 6], [7, 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# playground\n",
        "K_C1 = cosSimDistances <= thresholds[3] # logical array of \"in\" edges\n",
        "nu = []\n",
        "i = 6\n",
        "[i_N, N] = LowerPairVertices(K_C0, K_C1, i)\n",
        "nu = AddCofaces(K_C0, K_C1, 2, K_C0[i], i_N, N, nu)\n",
        "print(nu)\n",
        "i = 7\n",
        "[i_N, N] = LowerPairVertices(K_C0, K_C1, i)\n",
        "nu = AddCofaces(K_C0, K_C1, 2, K_C0[i], i_N, N, nu)\n",
        "print(nu)\n",
        "nu = RipsComplex(K_C0, K_C1, 2)\n",
        "print(nu)\n",
        "print(len(nu))\n",
        "print(len(union_lists(nu+nu)))"
      ],
      "metadata": {
        "id": "7qCwSIFVwwrh",
        "outputId": "76e7c3d8-95ef-4d8d-b8b1-1b7adc985c26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6]]\n",
            "[[6], [7]]\n",
            "[[6], [2], [3, 4], [5], [8], [4], [1], [7], [0, 5], [0], [0, 8], [3]]\n",
            "12\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# iterate through each threshold value, building up birthEpoch, deathEpoch,\n",
        "# and dimension arrays corresponding to the epochOrderedComplex and\n",
        "# allHomologies arrays. The reduced boundary matrix will also be an\n",
        "# output at each iteration\n",
        "for epoch = 1:length(thresholds)\n",
        "    # first determine which edges are in the complex based on threshold\n",
        "    K.C1 = eucMetrics <= thresholds(epoch) # logical array of \"in\" edges\n",
        "    # compute the complex as a huge array of dot-delimited strings\n",
        "    nu = RipsComplex(K,dims)\n",
        "\n",
        "    # find new complex items for this epoch\n",
        "    newInComplex = setdiff(nu, nu_prev)\n",
        "    L_new = length(newInComplex)\n",
        "    L_tot = L_prev + L_new\n",
        "    # order newInComplex by simplex size so that each simplex can possibly be\n",
        "    # destroyed by something to its right in its own birth epoch if needed\n",
        "    newInComplex = orderSimplices(newInComplex)\n",
        "    # update tracking of epoch number for new complex items\n",
        "    birthEpoch(L_prev+1:L_tot) = epoch\n",
        "    # add new items to the ordered list of items. These are used for\n",
        "    # columns and rows in the big boundary matrix and for naming in the\n",
        "    # persistence diagrams\n",
        "    epochOrderedComplex(L_prev+1:L_tot) = newInComplex\n",
        "\n",
        "    # preallocate temp array to convert to boundary matrix using newItems\n",
        "    temp = false(L_tot,L_new)\n",
        "    # fill temp in as boundary matrix of newInComplex\n",
        "    temp = findNewItemsBoundary(epochOrderedComplex, newInComplex, temp,...\n",
        "        L_tot, L_new)\n",
        "\n",
        "    # reduce the expanded boundary matrix\n",
        "    for newCol = 1:L_new\n",
        "        # put temp column into next open column of boundary matrix\n",
        "        boundaryMatrix(1:L_tot,w_bd+1) = temp(:,newCol)\n",
        "        # find the first column with the same lowest 1, if such exists\n",
        "        [matchCol, lowOneRow] = findFirstConflictColumn(boundaryMatrix,...\n",
        "            w_bd+1)\n",
        "        while matchCol\n",
        "            # add the conflicting/matching column to the check column, mod2\n",
        "            boundaryMatrix(:,w_bd+1) = mod(boundaryMatrix(:,w_bd+1) +...\n",
        "                boundaryMatrix(:,matchCol),2)\n",
        "            # add the element name for the matching column as a linear comb.\n",
        "            epochOrderedComplex{L_prev+newCol} =...\n",
        "                sprintf('#s+#s',...\n",
        "                epochOrderedComplex{nuColIndexFromBoundColIndex(matchCol)},...\n",
        "                epochOrderedComplex{L_prev+newCol})\n",
        "            # reset matchCol. Since the column has been modified, the match\n",
        "            # column will be different or nonexistent\n",
        "            [matchCol, lowOneRow] = findFirstConflictColumn(boundaryMatrix,...\n",
        "                w_bd+1)\n",
        "        end\n",
        "        if lowOneRow >= 0 # if so, it's a pivot\n",
        "            # set death epoch for the killed row\n",
        "            deathEpoch(lowOneRow) = epoch\n",
        "            # add one to the width of the boundary matrix\n",
        "            w_bd = w_bd+1\n",
        "            # add the index map to the index tracker\n",
        "            nuColIndexFromBoundColIndex(w_bd) = L_prev+newCol\n",
        "        end\n",
        "    end\n",
        "\n",
        "# latest complex is previous complex for next iteration\n",
        "nu_prev = nu\n",
        "L_prev = length(nu_prev)\n",
        "end\n",
        "toc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "qUmsjVtKFVPo",
        "outputId": "b22ea505-84a2-4669-b426-9a1479536a40"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-20-68e87f1596dd>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-68e87f1596dd>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for epoch = 1:length(thresholds)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jtIWsNHUAzap"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}