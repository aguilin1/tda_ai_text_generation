{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aguilin1/tda_ai_text_generation.git"
      ],
      "metadata": {
        "id": "rNoNDVYHKGF_",
        "outputId": "9a019312-30da-4e03-d582-e7fc5953b944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tda_ai_text_generation'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 18 (delta 7), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (18/18), 103.43 KiB | 3.13 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RnbbJceiiAO3",
        "outputId": "69a047df-1249-4012-8392-fdb6c403aecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements. The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances. However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood. Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field. Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields. We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes. Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation. Finally, we use numerical simulations to confirm the validity of our experimental results. Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.',\n",
              " 'In this paper, we investigate Weighted Solyanik Estimates for the Strong Maximal Function. The purpose of this study is to determine the optimal range of weights for which the Solyanik estimates hold true for the strong maximal function in both dyadic and non-dyadic contexts. Our work is motivated by recent developments in the area of harmonic analysis and Fourier analysis, which have demonstrated the importance of the strong maximal function in many areas of mathematics. We begin our investigation by defining the strong maximal function and introducing the weighted Solyanik estimates. We then analyze the properties of the strong maximal function and its relationship to weighted estimates. Our findings demonstrate that the range of suitable weights for the Solyanik estimates is significantly larger in the dyadic context than in the non-dyadic context. Moreover, we establish new estimates for the strong maximal function in the dyadic context, which improve upon existing results. Our study contributes to the development of more precise and accurate techniques for analyzing the strong maximal function, and may have potential applications in other areas of mathematics as well. In conclusion, our investigation of Weighted Solyanik Estimates for the Strong Maximal Function provides new insights into this important topic in harmonic analysis, and we expect our results to be of interest to researchers in this field and related areas of study.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "DATA_FILE = '/content/tda_ai_text_generation/research-abstracts-labeled-first-100.csv'\n",
        "\n",
        "human_texts = []\n",
        "ai_texts = []\n",
        "with open(DATA_FILE) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    next(csv_reader, None) # Skip header row\n",
        "    for row in csv_reader:\n",
        "      if row[1] == '0':\n",
        "        human_texts.append(row[2])\n",
        "      else:\n",
        "        ai_texts.append(row[2])\n",
        "# Print first 2 rows to sanity check\n",
        "ai_texts[:2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "x88OSoqsKghJ",
        "outputId": "418b3ee7-b6ee-4c56-baf4-9d2019ad08cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "text = ai_texts[0]\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "proceesed_sentences = []\n",
        "for sentence in sentences:\n",
        "  # Uncomment to remve punctuation if not doing sentence-level transform\n",
        "  sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  filtered_text = []\n",
        "\n",
        "  for word in word_tokenize(sentence):\n",
        "    if word not in stop_words:\n",
        "      filtered_text.append(wnl.lemmatize(word, pos=\"v\").lower())\n",
        "\n",
        "  post_filtered_text = ' '.join(filtered_text)\n",
        "  proceesed_sentences.append(post_filtered_text)\n",
        "\n",
        "proceesed_sentences"
      ],
      "metadata": {
        "id": "UuzdYItZKcti",
        "outputId": "473871ce-2518-4f83-826b-66b5bea0d644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in study investigate couple loss bicolumnar bsccoag tap use ac susceptibility measurements',\n",
              " 'the bicolumnar structure bscco tap know offer several advantage traditional tape configurations include increase tolerance magnetic field disturbances',\n",
              " 'however effect bi2212ag interface couple superconducting filaments bscco tape well understand',\n",
              " 'our experiment show couple loss dominate bi2212ag interface vary significantly orientation magnitude apply ac magnetic field',\n",
              " 'specifically couple loss find lower inplane magnetic field higher outofplane magnetic field',\n",
              " 'we also observe anneal tap significantly affect couple loss anneal tap exhibit lower loss value unannealed tap',\n",
              " 'furthermore find couple loss sensitive orientation ag matrix demonstrate measurements tap transverse longitudinal matrix orientation',\n",
              " 'finally use numerical simulations confirm validity experimental result',\n",
              " 'overall study provide important insights couple loss mechanisms bicolumnar bsccoag tap highly relevant development practical applications hightemperature superconductors']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "embeddings = vectorizer.fit_transform(proceesed_sentences)\n",
        "print(embeddings.toarray())"
      ],
      "metadata": {
        "id": "vbRKh5J0Ky98",
        "outputId": "d4d28230-c5fd-4a92-b1b6-9052cf79a681",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            "  0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
            "  0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
            "  0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1\n",
            "  1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
            "  0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            "  1 0 0 0 0 0 1 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 1 0 1 0 0 0 0 0 0 0\n",
            "  1 0 0 0 0 0 1 1 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 1 2 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 2 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3\n",
            "  0 0 0 0 0 1 0 0 0 1 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 1 1 0 0 0 2 1 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
            "  0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
            "  0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import itertools\n",
        "\n",
        "# Label each sentence starting at 0, 1, 2, ...\n",
        "# Track distances as ((sentence 1, sentence 2), distance)\n",
        "distances = []\n",
        "for pair1_i, pair2_i in itertools.combinations(range(len(sentences)), 2):\n",
        "    dist = cosine_similarity(embeddings[pair1_i], embeddings[pair2_i])[0][0]\n",
        "    distances.append(((pair1_i, pair2_i), dist))\n",
        "\n",
        "for distance in distances:\n",
        "  print(\"Distance {} from [{}] to [{}]\".format(distance[1], sentences[distance[0][0]], sentences[distance[0][1]]))\n"
      ],
      "metadata": {
        "id": "qxTxwgOQLgso",
        "outputId": "1a6d482e-231a-4243-bc18-98782e310ae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance 0.13608276348795437 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.]\n",
            "Distance 0.08703882797784893 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.]\n",
            "Distance 0.2165063509461097 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.]\n",
            "Distance 0.14433756729740646 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.]\n",
            "Distance 0.33333333333333337 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.]\n",
            "Distance 0.26490647141300877 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 0.10206207261596575 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.4082482904638631 from [In this study, we investigate the coupling loss on bi-columnar BSCCO/Ag tapes using a.c. susceptibility measurements.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.1421338109037403 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.]\n",
            "Distance 0.11785113019775793 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.]\n",
            "Distance 0.23570226039551587 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.]\n",
            "Distance 0.13608276348795434 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.]\n",
            "Distance 0.05407380704358751 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 0.0 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.11111111111111113 from [The bi-columnar structure of BSCCO tapes is known to offer several advantages over traditional tape configurations, including increased tolerance to magnetic field disturbances.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.22613350843332272 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.]\n",
            "Distance 0.07537783614444091 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.]\n",
            "Distance 0.05802588531856595 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.]\n",
            "Distance 0.06917144638660747 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 0.0 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.07106690545187015 from [However, the effects of the Bi-2212/Ag interface on the coupling between the superconducting filaments of the BSCCO tape is not well understood.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.375 from [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.] to [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.]\n",
            "Distance 0.19245008972987526 from [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.] to [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.]\n",
            "Distance 0.22941573387056174 from [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 0.0 from [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.11785113019775793 from [Our experiments show that the coupling loss is dominated by the Bi-2212/Ag interface and varies significantly with the orientation and magnitude of the applied a.c. magnetic field.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.19245008972987526 from [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.] to [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.]\n",
            "Distance 0.1720618004029213 from [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 0.0 from [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.11785113019775793 from [Specifically, coupling loss is found to be lower for in-plane magnetic fields and higher for out-of-plane magnetic fields.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.2649064714130087 from [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.] to [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.]\n",
            "Distance 0.0 from [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.2721655269759087 from [We also observe that the annealing of the tapes significantly affects the coupling loss, as annealed tapes exhibit lower loss values than unannealed tapes.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.0 from [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.] to [Finally, we use numerical simulations to confirm the validity of our experimental results.]\n",
            "Distance 0.16222142113076254 from [Furthermore, we find that the coupling loss is sensitive to the orientation of the Ag matrix, as demonstrated by measurements on tapes with both transverse and longitudinal matrix orientation.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n",
            "Distance 0.0 from [Finally, we use numerical simulations to confirm the validity of our experimental results.] to [Overall, this study provides important insights into the coupling loss mechanisms in bi-columnar BSCCO/Ag tapes, which are highly relevant for the development of practical applications of high-temperature superconductors.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This section generates and reformats the cosine similarity distances between\n",
        "# each pair of points and generates an array of all possible threshold values\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "n = len(embeddings.toarray()) # Number of data points\n",
        "cosSimDistances = np.zeros((n, n)) # preallocate pairwise distance matrix\n",
        "\n",
        "# Label each sentence starting at 0, 1, 2, ...\n",
        "# Track distance between sentence i and sentence j in (i,j) entry of matrix\n",
        "# Matrix will be upper triangular\n",
        "for pair1_i, pair2_i in itertools.combinations(range(len(sentences)), 2):\n",
        "    dist = cosine_similarity(embeddings[pair1_i], embeddings[pair2_i])[0][0]\n",
        "    cosSimDistances[pair1_i][pair2_i] = dist\n",
        "#print(cosSimDistances)\n",
        "thresholds = np.sort(np.unique(cosSimDistances))\n",
        "#print(thresholds)"
      ],
      "metadata": {
        "id": "_mJJSjn9kAmm",
        "outputId": "85fcc6ef-de6c-4334-d211-4dfeb9b78f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.13608276 0.08703883 0.21650635 0.14433757 0.33333333\n",
            "  0.26490647 0.10206207 0.40824829]\n",
            " [0.         0.         0.14213381 0.11785113 0.23570226 0.13608276\n",
            "  0.05407381 0.         0.11111111]\n",
            " [0.         0.         0.         0.22613351 0.07537784 0.05802589\n",
            "  0.06917145 0.         0.07106691]\n",
            " [0.         0.         0.         0.         0.375      0.19245009\n",
            "  0.22941573 0.         0.11785113]\n",
            " [0.         0.         0.         0.         0.         0.19245009\n",
            "  0.1720618  0.         0.11785113]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.26490647 0.         0.27216553]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.16222142]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]]\n",
            "[0.         0.05407381 0.05802589 0.06917145 0.07106691 0.07537784\n",
            " 0.08703883 0.10206207 0.11111111 0.11785113 0.13608276 0.13608276\n",
            " 0.14213381 0.14433757 0.16222142 0.1720618  0.19245009 0.21650635\n",
            " 0.22613351 0.22941573 0.23570226 0.26490647 0.26490647 0.27216553\n",
            " 0.33333333 0.375      0.40824829]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add(a, b): # <-- This is a helper function\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def main():\n",
        "    subtract = 10 - 9\n",
        "    multiply = 2 * 2\n",
        "    add(5, 4) # <-- Helper function is called here"
      ],
      "metadata": {
        "id": "zmmhwP92OJD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Helper functions based on publication\n",
        "# The functions in this section are tailored implementations of algorithms\n",
        "# found in the following paper:\n",
        "\n",
        "# Zomorodian, A. (2010). Fast construction of the Vietoris-Rips complex.\n",
        "# Computers & Graphics, 34(3), 263â€“271.\n",
        "# https://doi.org/https://doi.org/10.1016/j.cag.2010.03.007\n",
        "\n",
        "# ref: Article Section 4.2\n",
        "# inputs: both C0 and C1 from complex K, max dimension (3 = tetrahedra)\n",
        "def RipsComplex(K_C0, K_C1, k):\n",
        "  nu = [] # this will be expanded to hold all the simplices of all sizes\n",
        "  for i in range(len(K_C0)): # for each vertex in C0\n",
        "    # find the other, lower ordered vertices that have an edge connecting them\n",
        "    # to this vertex\n",
        "    [i_N, N] = LowerPairVertices(K_C0, K_C1, i)\n",
        "    # build all the cofaces\n",
        "    nu = AddCofaces(K_C0, K_C1, k, K_C0(i), i_N, N, nu)\n",
        "    return nu\n",
        "\n",
        "# ref: Article Section 4.2\n",
        "# inputs: complex K (C0 and C1), max dimension (3 = tetrahedra), set\n",
        "# containing a vertex, set containing lower points paired with that vector,\n",
        "# and current built-up V-R complex\n",
        "def AddCofaces(K_C0, K_C1, k, tau, i_N, N, nu):\n",
        "  nu = union(nu, tau)\n",
        "  # need some way to not count dots? # need some other way to express the\n",
        "  # set?\n",
        "  if count(tau{1},'.') >= k # if dim(tau) >= k (has k+1 or more points)\n",
        "      return\n",
        "  else\n",
        "      for i = 1:length(N)\n",
        "          sigma = {[N{i},'.', tau{1}]} # element to be added to nu\n",
        "          [i_M, M] = LowerPairVertices(K,i_N(i))\n",
        "          M = intersect(N, M) # intersection means triangle\n",
        "          nu = AddCofaces(K, k, sigma, i_M, M, nu)\n",
        "  end\n",
        "  return nu\n",
        "\n",
        "# ref: Article Section 4.1\n",
        "# inputs: both C0 and C1 of complex K, index of the vertex for which to find\n",
        "# lower ordered points that are paired by an edge.\n",
        "def LowerPairVertices(K_C0, K_C1, i_u):\n",
        "  # get indices i_N of lower vertices paired with vertex u, which has index i_u\n",
        "  i_N = np.nonzero(K_C1[0:i_u,i_u])[0]\n",
        "  # get the set N of lower vertices v paired with vertex u\n",
        "  N = list(K_C0[i] for i in i_N)\n",
        "  return [i_N, N]"
      ],
      "metadata": {
        "id": "_1JSYehlN0RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Driver\n",
        "from scipy.special import comb # for comb() (i.e. \"nChooseK\")\n",
        "\n",
        "# set max dimension to compute\n",
        "K_C0 = []\n",
        "for i in range(n):\n",
        "  K_C0.append([i])\n",
        "\n",
        "dims = 2 # 0 - points, 1 - edges, 2 - triangles, 3 - tetrahedra, etc.\n",
        "nPts = len(K_C0)\n",
        "# compute the total number of things that will be in the complex at the max\n",
        "# threshold, based on the selected # of dimensions\n",
        "totalSizeNu = nPts # the points will always be in the complex\n",
        "\n",
        "# compute the total # of simplices that will exist at the max threshold\n",
        "for i in range(dims):\n",
        "  # add # of ith dimension entries in the complex at max threshold\n",
        "  totalSizeNu = totalSizeNu + comb(nPts, i+1, exact=True)\n",
        "\n",
        "# preallocate big boundary matrix and an array to track the index of the\n",
        "# simplex in the full complex (and row in the boundary matrix)\n",
        "# corresponding to each column in the boundary matrix. Assume the boundary\n",
        "# matrix will have half as many columns as the number of simplices due to\n",
        "# removal of zero columns during each iteration\n",
        "boundaryMatrix = np.zeros((totalSizeNu, round(totalSizeNu/2)), dtype=bool)\n",
        "nuColIndexFromBoundColIndex = np.zeros(round(totalSizeNu/2), dtype=np.int32)\n",
        "w_bd = 0 # zero boundary matrix columns originally filled in\n",
        "# preallocate last iteration complex and reset to correct data type\n",
        "nu_prev = [None] * totalSizeNu\n",
        "# track number of actual items set in nu_prev\n",
        "L_prev = 0\n",
        "# preallocate epoch and dimension trackers to -1 for error checking later\n",
        "# birthEpoch = -1*ones(1,totalSizeNu,'int16')\n",
        "birthEpoch = -1*np.ones(totalSizeNu, dtype=np.int16)\n",
        "deathEpoch = -1*np.ones(totalSizeNu,dtype=np.int16)\n",
        "dimension = -1*np.ones(totalSizeNu,dtype=np.int8)\n",
        "# preallocate full complex buildup and reset to correct data type\n",
        "epochOrderedComplex = [None] * totalSizeNu\n",
        "\n",
        "# iterate through each threshold value, building up birthEpoch, deathEpoch,\n",
        "# and dimension arrays corresponding to the epochOrderedComplex and\n",
        "# allHomologies arrays. The reduced boundary matrix will also be an\n",
        "# output at each iteration\n",
        "for epoch in range(len(thresholds)):\n",
        "  # first determine which edges are in the complex based on threshold\n",
        "  K_C1 = cosSimDistances <= thresholds[epoch] # logical array of \"in\" edges\n",
        "  # compute the complex as a huge array of dot-delimited strings\n",
        "  nu = RipsComplex(K_C0, K_C1, dims)"
      ],
      "metadata": {
        "id": "mXqPvSyKHRg2",
        "outputId": "50b305ae-3847-4c61-fa25-a8395b0a3c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ True False False False False False False False False]\n",
            " [ True  True False False False False False  True False]\n",
            " [ True  True  True False False False False  True False]\n",
            " [ True  True  True  True False False False  True False]\n",
            " [ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True False False False False False False False False]\n",
            " [ True  True False False False False  True  True False]\n",
            " [ True  True  True False False False False  True False]\n",
            " [ True  True  True  True False False False  True False]\n",
            " [ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True False False False False False False False False]\n",
            " [ True  True False False False False  True  True False]\n",
            " [ True  True  True False False  True False  True False]\n",
            " [ True  True  True  True False False False  True False]\n",
            " [ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True False False False False False False False False]\n",
            " [ True  True False False False False  True  True False]\n",
            " [ True  True  True False False  True  True  True False]\n",
            " [ True  True  True  True False False False  True False]\n",
            " [ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True False False False False False False False False]\n",
            " [ True  True False False False False  True  True False]\n",
            " [ True  True  True False False  True  True  True  True]\n",
            " [ True  True  True  True False False False  True False]\n",
            " [ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True False False False False False False False False]\n",
            " [ True  True False False False False  True  True False]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True False]\n",
            " [ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True False  True False False False False False False]\n",
            " [ True  True False False False False  True  True False]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True False]\n",
            " [ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True False  True False False False False  True False]\n",
            " [ True  True False False False False  True  True False]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True False]\n",
            " [ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True False  True False False False False  True False]\n",
            " [ True  True False False False False  True  True  True]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True False]\n",
            " [ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True False  True False False False False  True False]\n",
            " [ True  True False  True False False  True  True  True]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True  True]\n",
            " [ True  True  True  True  True False False  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True False  True False False False False  True False]\n",
            " [ True  True False  True False  True  True  True  True]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True  True]\n",
            " [ True  True  True  True  True False False  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True False False False False  True False]\n",
            " [ True  True False  True False  True  True  True  True]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True  True]\n",
            " [ True  True  True  True  True False False  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True False False False False  True False]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True  True]\n",
            " [ True  True  True  True  True False False  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True False  True False False  True False]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True  True]\n",
            " [ True  True  True  True  True False False  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True False  True False False  True False]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True  True]\n",
            " [ True  True  True  True  True False False  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True False  True False False  True False]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False False False  True  True]\n",
            " [ True  True  True  True  True False  True  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True False  True False False  True False]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False  True False  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True False  True  True  True  True  True]\n",
            " [ True  True  True  True False  True False  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True False  True False  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True False  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True  True  True False False  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True  True  True False  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True  True  True False  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True False  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True  True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "[[ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True  True]]\n",
            "0.4082482904638631\n",
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# iterate through each threshold value, building up birthEpoch, deathEpoch,\n",
        "# and dimension arrays corresponding to the epochOrderedComplex and\n",
        "# allHomologies arrays. The reduced boundary matrix will also be an\n",
        "# output at each iteration\n",
        "for epoch = 1:length(thresholds)\n",
        "    # first determine which edges are in the complex based on threshold\n",
        "    K.C1 = eucMetrics <= thresholds(epoch) # logical array of \"in\" edges\n",
        "    # compute the complex as a huge array of dot-delimited strings\n",
        "    nu = RipsComplex(K,dims)\n",
        "\n",
        "    # find new complex items for this epoch\n",
        "    newInComplex = setdiff(nu, nu_prev)\n",
        "    L_new = length(newInComplex)\n",
        "    L_tot = L_prev + L_new\n",
        "    # order newInComplex by simplex size so that each simplex can possibly be\n",
        "    # destroyed by something to its right in its own birth epoch if needed\n",
        "    newInComplex = orderSimplices(newInComplex)\n",
        "    # update tracking of epoch number for new complex items\n",
        "    birthEpoch(L_prev+1:L_tot) = epoch\n",
        "    # add new items to the ordered list of items. These are used for\n",
        "    # columns and rows in the big boundary matrix and for naming in the\n",
        "    # persistence diagrams\n",
        "    epochOrderedComplex(L_prev+1:L_tot) = newInComplex\n",
        "\n",
        "    # preallocate temp array to convert to boundary matrix using newItems\n",
        "    temp = false(L_tot,L_new)\n",
        "    # fill temp in as boundary matrix of newInComplex\n",
        "    temp = findNewItemsBoundary(epochOrderedComplex, newInComplex, temp,...\n",
        "        L_tot, L_new)\n",
        "\n",
        "    # reduce the expanded boundary matrix\n",
        "    for newCol = 1:L_new\n",
        "        # put temp column into next open column of boundary matrix\n",
        "        boundaryMatrix(1:L_tot,w_bd+1) = temp(:,newCol)\n",
        "        # find the first column with the same lowest 1, if such exists\n",
        "        [matchCol, lowOneRow] = findFirstConflictColumn(boundaryMatrix,...\n",
        "            w_bd+1)\n",
        "        while matchCol\n",
        "            # add the conflicting/matching column to the check column, mod2\n",
        "            boundaryMatrix(:,w_bd+1) = mod(boundaryMatrix(:,w_bd+1) +...\n",
        "                boundaryMatrix(:,matchCol),2)\n",
        "            # add the element name for the matching column as a linear comb.\n",
        "            epochOrderedComplex{L_prev+newCol} =...\n",
        "                sprintf('#s+#s',...\n",
        "                epochOrderedComplex{nuColIndexFromBoundColIndex(matchCol)},...\n",
        "                epochOrderedComplex{L_prev+newCol})\n",
        "            # reset matchCol. Since the column has been modified, the match\n",
        "            # column will be different or nonexistent\n",
        "            [matchCol, lowOneRow] = findFirstConflictColumn(boundaryMatrix,...\n",
        "                w_bd+1)\n",
        "        end\n",
        "        if lowOneRow >= 0 # if so, it's a pivot\n",
        "            # set death epoch for the killed row\n",
        "            deathEpoch(lowOneRow) = epoch\n",
        "            # add one to the width of the boundary matrix\n",
        "            w_bd = w_bd+1\n",
        "            # add the index map to the index tracker\n",
        "            nuColIndexFromBoundColIndex(w_bd) = L_prev+newCol\n",
        "        end\n",
        "    end\n",
        "\n",
        "# latest complex is previous complex for next iteration\n",
        "nu_prev = nu\n",
        "L_prev = length(nu_prev)\n",
        "end\n",
        "toc"
      ],
      "metadata": {
        "id": "qUmsjVtKFVPo",
        "outputId": "0975c8af-6242-4401-a51c-eb72bc830c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-41-dcb4dbfc9e8e>, line 12)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-dcb4dbfc9e8e>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    for i = 1:dims\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# playground\n",
        "i_u = 4\n",
        "a = np.array([[0, 0, 0,1,1], [1, 1, 1,0,1], [1, 1, 0,1,0], [1,1,1,0,1], [1, 1, 0,1,0]])\n",
        "print(a)\n",
        "print(\"column of interest:\", i_u)\n",
        "print(a[0:i_u,i_u])\n",
        "\n",
        "# use [0] to get the array of non-zero locations\n",
        "c = np.nonzero(a[0:i_u,i_u])[0]\n",
        "print(c) # since we're not including the i_uth element, use \"i_u - 1\"\n",
        "N = list(K_C0[i] for i in c)\n",
        "#list( myBigList[i] for i in [87, 342, 217, 998, 500] )\n",
        "print(N)"
      ],
      "metadata": {
        "id": "jtIWsNHUAzap",
        "outputId": "f395ff32-90e1-455f-9b34-aff27d8d9010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 1 1]\n",
            " [1 1 1 0 1]\n",
            " [1 1 0 1 0]\n",
            " [1 1 1 0 1]\n",
            " [1 1 0 1 0]]\n",
            "column of interest: 4\n",
            "[1 1 0 1]\n",
            "[0 1 3]\n",
            "[[0], [1], [3]]\n"
          ]
        }
      ]
    }
  ]
}